<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Strongly Convex - Daniel Duckworth</title><link href="https://stronglyconvex.com/" rel="alternate"></link><link href="https://stronglyconvex.com/feeds/daniel-duckworth.atom.xml" rel="self"></link><id>https://stronglyconvex.com/</id><updated>2014-08-01T00:00:00-07:00</updated><entry><title>The Big Table of Convergence Rates</title><link href="https://stronglyconvex.com/blog/big-table-of-convergence-rates.html" rel="alternate"></link><published>2014-08-01T00:00:00-07:00</published><updated>2014-08-01T00:00:00-07:00</updated><author><name>Daniel Duckworth</name></author><id>tag:stronglyconvex.com,2014-08-01:/blog/big-table-of-convergence-rates.html</id><summary type="html">&lt;p&gt;In the past 50+ years of convex optimization research, a great many
algorithms have been developed, each with slight nuances to their assumptions,
implementations, and guarantees. In this article, I'll give a shorthand
comparison of these methods in terms of the number of iterations required
to reach a desired accuracy …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In the past 50+ years of convex optimization research, a great many
algorithms have been developed, each with slight nuances to their assumptions,
implementations, and guarantees. In this article, I'll give a shorthand
comparison of these methods in terms of the number of iterations required
to reach a desired accuracy &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; for convex and strongly convex objective
functions.&lt;/p&gt;
&lt;p&gt;Below, methods are grouped according to what "order" of information they
require about the objective function. In general, the more information you
have, the faster you can converge; but beware, you will also need more memory
and computation. Zeroth and first order methods are typically appropriate for
large scale problems, whereas second order methods are limited to
small-to-medium scale problems that require a high degree of precision.&lt;/p&gt;
&lt;p&gt;At the bottom, you will find algorithms aimed specifically at minimizing
supervised learning problems and other meta-algorithms useful for distributing
computation across multiple nodes.&lt;/p&gt;
&lt;p&gt;Unless otherwise stated, all objectives are assumed to be Lipschitz
continuous (though not necssarily differentiable) and the domain convex. The
variable being optimized is &lt;span class="math"&gt;\(x \in \mathbb{R}^n\)&lt;/span&gt;.&lt;/p&gt;
&lt;h1&gt;Zeroth Order Methods&lt;/h1&gt;
&lt;p&gt;Zeroth order methods are characterized by not requiring any gradients or
subgradients for their objective functions. In exchange, however, it is
assumed that the objective is "simple" in the sense that a subset of variables
(a "block") can be minimized exactly while holding all other variables fixed.&lt;/p&gt;
&lt;div style="overflow-x: auto"&gt;
  &lt;table markdown class="table table-bordered table-centered"&gt;
    &lt;colgroup&gt;
      &lt;col style="width:20%"&gt;
      &lt;col style="width:10%"&gt;
      &lt;col style="width:10%"&gt;
      &lt;col style="width:10%"&gt;
      &lt;col style="width:10%"&gt;
      &lt;col style="width:40%"&gt;
    &lt;/colgroup&gt;
    &lt;thead&gt;
      &lt;tr&gt;
        &lt;th&gt;Algorithm          &lt;/th&gt;
        &lt;th&gt;Problem Formulation&lt;/th&gt;
        &lt;th&gt;Convex             &lt;/th&gt;
        &lt;th&gt;Strongly Convex    &lt;/th&gt;
        &lt;th&gt;Per-Iteration Cost &lt;/th&gt;
        &lt;th&gt;Notes              &lt;/th&gt;
      &lt;/tr&gt;
    &lt;/thead&gt;

    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;!-- Algorithm          --&gt;
        &lt;td&gt;Randomized Block Coordinate Descent&lt;/td&gt;
        &lt;!-- Problem            --&gt;
        &lt;td&gt;$\displaystyle \min_{x \in \mathbb{R}^{n}} f(x) + g(x)$&lt;/td&gt;
        &lt;!-- Convex             --&gt;
        &lt;td&gt;$O(1 / \epsilon)$[^richtarik-2011]&lt;/td&gt;
        &lt;!-- Strongly Convex    --&gt;
        &lt;td&gt;$O(\log (1 / \epsilon))$[^richtarik-2011]&lt;/td&gt;
        &lt;!-- Per-Iteration Cost --&gt;
        &lt;td&gt;$O(1)$&lt;/td&gt;
        &lt;!-- Notes              --&gt;
        &lt;td&gt;
          Applicable when $f(x)$ is differentiable and $g(x)$ is separable in
          each block. $g(x)$ may be a barrier function.
        &lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;h1&gt;First Order Methods&lt;/h1&gt;
&lt;p&gt;First order methods typically require access to an objective function's
gradient or subgradient. The algorithms typically take the form &lt;span class="math"&gt;\(x^{(t+1)}
= x^{(t)} - \alpha^{(t)} g^{(t)}\)&lt;/span&gt; for some step size &lt;span class="math"&gt;\(\alpha^{(t)}\)&lt;/span&gt; and descent
direction &lt;span class="math"&gt;\(g^{(t)}\)&lt;/span&gt;. As such, each iteration takes approximately &lt;span class="math"&gt;\(O(n)\)&lt;/span&gt; time.&lt;/p&gt;
&lt;div style="overflow-x: auto"&gt;
  &lt;table markdown class="table table-bordered table-centered"&gt;
    &lt;colgroup&gt;
      &lt;col style="width:20%"&gt;
      &lt;col style="width:10%"&gt;
      &lt;col style="width:10%"&gt;
      &lt;col style="width:10%"&gt;
      &lt;col style="width:10%"&gt;
      &lt;col style="width:40%"&gt;
    &lt;/colgroup&gt;

    &lt;thead&gt;
      &lt;tr&gt;
        &lt;th&gt;Algorithm          &lt;/th&gt;
        &lt;th&gt;Problem Formulation&lt;/th&gt;
        &lt;th&gt;Convex             &lt;/th&gt;
        &lt;th&gt;Strongly Convex    &lt;/th&gt;
        &lt;th&gt;Per-Iteration Cost &lt;/th&gt;
        &lt;th&gt;Notes              &lt;/th&gt;
      &lt;/tr&gt;
    &lt;/thead&gt;

    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;!-- Algorithm          --&gt;
        &lt;td&gt;Subgradient Descent&lt;/td&gt;
        &lt;!-- Problem            --&gt;
        &lt;td&gt;$\displaystyle  \min_{x \in \mathbb{R}^n} f(x)$&lt;/td&gt;
        &lt;!-- Convex             --&gt;
        &lt;td&gt;$O(1 / \epsilon^{2})$[^blog-sd]&lt;/td&gt;
        &lt;!-- Strongly Convex    --&gt;
        &lt;td&gt;...&lt;/td&gt;
        &lt;!-- Per-Iteration Cost --&gt;
        &lt;td&gt;$O(n)$&lt;/td&gt;
        &lt;!-- Notes              --&gt;
        &lt;td&gt;
          Cannot be improved upon without further assumptions.
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;!-- Algorithm          --&gt;
        &lt;td&gt;Mirror Descent&lt;/td&gt;
        &lt;!-- Problem            --&gt;
        &lt;td&gt;$\displaystyle \min_{x \in \mathcal{C}} f(x)$&lt;/td&gt;
        &lt;!-- Convex             --&gt;
        &lt;td&gt;$O(1 / \epsilon^{2} )$[^ee381-md]&lt;/td&gt;
        &lt;!-- Strongly Convex    --&gt;
        &lt;td&gt;$O(1 / \epsilon )$[^nedich-2013]&lt;/td&gt;
        &lt;!-- Per-Iteration Cost --&gt;
        &lt;td&gt;$O(n)$&lt;/td&gt;
        &lt;!-- Notes              --&gt;
        &lt;td&gt;
          Different parameterizations result in gradient descent and
          exponentiated gradient descent.
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;!-- Algorithm          --&gt;
        &lt;td&gt;Dual Averaging&lt;/td&gt;
        &lt;!-- Problem            --&gt;
        &lt;td&gt;$\displaystyle  \min_{x \in \mathcal{C}} f(x)$&lt;/td&gt;
        &lt;!-- Convex             --&gt;
        &lt;td&gt;$O(1 / \epsilon^{2})$[^nesterov-2007]&lt;/td&gt;
        &lt;!-- Strongly Convex    --&gt;
        &lt;td&gt;...&lt;/td&gt;
        &lt;!-- Per-Iteration Cost --&gt;
        &lt;td&gt;$O(n)$&lt;/td&gt;
        &lt;!-- Notes              --&gt;
        &lt;td&gt;
          Cannot be improved upon without further assumptions.
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;!-- Algorithm          --&gt;
        &lt;td&gt;Gradient Descent&lt;/td&gt;
        &lt;!-- Problem            --&gt;
        &lt;td&gt;$\displaystyle \min_{x \in \mathbb{R}^n} f(x)$&lt;/td&gt;
        &lt;!-- Convex             --&gt;
        &lt;td&gt;$O(1 / \epsilon)$[^blog-gd]&lt;/td&gt;
        &lt;!-- Strongly Convex    --&gt;
        &lt;td&gt;$O(\log (1 / \epsilon))$[^ee381-gd]&lt;/td&gt;
        &lt;!-- Per-Iteration Cost --&gt;
        &lt;td&gt;$O(n)$&lt;/td&gt;
        &lt;!-- Notes              --&gt;
        &lt;td&gt;
          Applicable when $f(x)$ is differentiable.
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;!-- Algorithm          --&gt;
        &lt;td&gt;Accelerated Gradient Descent&lt;/td&gt;
        &lt;!-- Problem            --&gt;
        &lt;td&gt;$\displaystyle \min_{x \in \mathbb{R}^n} f(x)$&lt;/td&gt;
        &lt;!-- Convex             --&gt;
        &lt;td&gt;$O(1 / \sqrt{\epsilon})$[^blog-agd]&lt;/td&gt;
        &lt;!-- Strongly Convex    --&gt;
        &lt;td&gt;$O(\log (1 / \epsilon))$[^bubeck-agd]&lt;/td&gt;
        &lt;!-- Per-Iteration Cost --&gt;
        &lt;td&gt;$O(n)$&lt;/td&gt;
        &lt;!-- Notes              --&gt;
        &lt;td&gt;
          Applicable when $f(x)$ is differentiable.
          Cannot be improved upon without further assumptions.
          Has better constants than Gradient Descent for "Strongly Convex" case.
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;!-- Algorithm          --&gt;
        &lt;td&gt;Proximal Gradient Descent&lt;/td&gt;
        &lt;!-- Problem            --&gt;
        &lt;td&gt;$\displaystyle \min_{x \in \mathcal{C}} f(x) + g(x)$&lt;/td&gt;
        &lt;!-- Convex             --&gt;
        &lt;td&gt;$O(1 / \epsilon)$[^blog-pgd]&lt;/td&gt;
        &lt;!-- Strongly Convex    --&gt;
        &lt;td&gt;$O(\log (1 / \epsilon))$[^mairal-2013]&lt;/td&gt;
        &lt;!-- Per-Iteration Cost --&gt;
        &lt;td&gt;$O(n)$&lt;/td&gt;
        &lt;!-- Notes              --&gt;
        &lt;td&gt;
          Applicable when $f(x)$ is differentiable and
          $\text{prox}_{\tau_t g}(x)$ is easily computable.
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;!-- Algorithm          --&gt;
        &lt;td&gt;Proximal Accelerated Gradient Descent&lt;/td&gt;
        &lt;!-- Problem            --&gt;
        &lt;td&gt;$\displaystyle \min_{x \in \mathcal{C}} f(x) + g(x)$&lt;/td&gt;
        &lt;!-- Convex             --&gt;
        &lt;td&gt;$O(1 / \sqrt{\epsilon})$[^blog-apgd]&lt;/td&gt;
        &lt;!-- Strongly Convex    --&gt;
        &lt;td&gt;$O(\log (1 / \epsilon))$[^mairal-2013]&lt;/td&gt;
        &lt;!-- Per-Iteration Cost --&gt;
        &lt;td&gt;$O(n)$&lt;/td&gt;
        &lt;!-- Notes              --&gt;
        &lt;td&gt;
          Applicable when $f(x)$ is differentiable and
          $\text{prox}_{\tau_t g}(x)$ is easily computable.
          Has better constants than Proximal Gradient Descent for "Strongly
          Convex" case.
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;!-- Algorithm          --&gt;
        &lt;td&gt;Frank-Wolfe Algorithm / Conditional Gradient Algorithm&lt;/td&gt;
        &lt;!-- Problem            --&gt;
        &lt;td&gt;$\displaystyle \min_{x \in \mathcal{C}} f(x)$&lt;/td&gt;
        &lt;!-- Convex             --&gt;
        &lt;td&gt;$O(1/\epsilon)$[^blog-fw]&lt;/td&gt;
        &lt;!-- Strongly Convex    --&gt;
        &lt;td&gt;$O(1/\sqrt{\epsilon})$[^garber-2014]&lt;/td&gt;
        &lt;!-- Per-Iteration Cost --&gt;
        &lt;td&gt;$O(n)$&lt;/td&gt;
        &lt;!-- Notes              --&gt;
        &lt;td&gt;
          Applicable when $\mathcal{C}$ is bounded and $h_{g}(x) = \arg\min_{x \in
          \mathcal{C}} \langle g, x \rangle$ is easily computable. Most useful
          when $\mathcal{C}$ is a polytope in a very high dimensional space with
          sparse extrema.
        &lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;h1&gt;Second Order Methods&lt;/h1&gt;
&lt;p&gt;Second order methods either use or approximate the hessian (&lt;span class="math"&gt;\(\nabla^2 f(x)\)&lt;/span&gt;)
of the objective function to result in better-than-linear rates of convergence.
As such, each iteration typically requires &lt;span class="math"&gt;\(O(n^2)\)&lt;/span&gt; memory and between &lt;span class="math"&gt;\(O(n^2)\)&lt;/span&gt;
and &lt;span class="math"&gt;\(O(n^3)\)&lt;/span&gt; computation per iteration.&lt;/p&gt;
&lt;div style="overflow-x: auto"&gt;
  &lt;table markdown class="table table-bordered table-centered"&gt;
    &lt;colgroup&gt;
      &lt;col style="width:20%"&gt;
      &lt;col style="width:10%"&gt;
      &lt;col style="width:10%"&gt;
      &lt;col style="width:10%"&gt;
      &lt;col style="width:10%"&gt;
      &lt;col style="width:40%"&gt;
    &lt;/colgroup&gt;

    &lt;thead&gt;
      &lt;tr&gt;
        &lt;th&gt;Algorithm          &lt;/th&gt;
        &lt;th&gt;Problem Formulation&lt;/th&gt;
        &lt;th&gt;Convex             &lt;/th&gt;
        &lt;th&gt;Strongly Convex    &lt;/th&gt;
        &lt;th&gt;Per-Iteration Cost &lt;/th&gt;
        &lt;th&gt;Notes              &lt;/th&gt;
      &lt;/tr&gt;
    &lt;/thead&gt;

    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;!-- Algorithm          --&gt;
        &lt;td&gt;Newton's Method&lt;/td&gt;
        &lt;!-- Problem            --&gt;
        &lt;td&gt;$\displaystyle \min_{x \in \mathbb{R}^n} f(x)$&lt;/td&gt;
        &lt;!-- Convex             --&gt;
        &lt;td&gt;...&lt;/td&gt;
        &lt;!-- Strongly Convex    --&gt;
        &lt;td&gt;$O(\log \log (1/\epsilon))$[^ee364a-unconstrained]&lt;/td&gt;
        &lt;!-- Per-Iteration Cost --&gt;
        &lt;td&gt;$O(n^3)$&lt;/td&gt;
        &lt;!-- Notes              --&gt;
        &lt;td&gt;
          Only applicable when $f(x)$ is twice differentiable. Constraints can be
          incorporated via interior point methods.
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;!-- Algorithm          --&gt;
        &lt;td&gt;Conjugate Gradient Descent&lt;/td&gt;
        &lt;!-- Problem            --&gt;
        &lt;td&gt;$\displaystyle \min_{x \in \mathbb{R}^n} f(x)$&lt;/td&gt;
        &lt;!-- Convex             --&gt;
        &lt;td&gt;...&lt;/td&gt;
        &lt;!-- Strongly Convex    --&gt;
        &lt;td&gt;$O(n)$&lt;/td&gt;
        &lt;!-- Per-Iteration Cost --&gt;
        &lt;td&gt;$O(n^2)$&lt;/td&gt;
        &lt;!-- Notes              --&gt;
        &lt;td&gt;
          Converges in exactly $n$ steps for quadratic $f(x)$. May fail to
          converge for non-quadratic objectives.
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;!-- Algorithm          --&gt;
        &lt;td&gt;L-BFGS&lt;/td&gt;
        &lt;!-- Problem            --&gt;
        &lt;td&gt;$\displaystyle \min_{x \in \mathbb{R}^n} f(x)$&lt;/td&gt;
        &lt;!-- Convex             --&gt;
        &lt;td&gt;...&lt;/td&gt;
        &lt;!-- Strongly Convex    --&gt;
        &lt;td&gt;Between $O(\log (1/\epsilon))$ and $O(\log \log (1/\epsilon))$[^ee236c-qnewton]&lt;/td&gt;
        &lt;!-- Per-Iteration Cost --&gt;
        &lt;td&gt;$O(n^2)$&lt;/td&gt;
        &lt;!-- Notes              --&gt;
        &lt;td&gt;
          Applicable when $f(x)$ is differentiable, but works best when twice
          differentiable. Convergence rate is not guaranteed.
        &lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;h1&gt;Stochastic Methods&lt;/h1&gt;
&lt;p&gt;The following algorithms are specifically designed for supervised machine
learning where the objective can be decomposed into independent "loss"
functions and a regularizer,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \min_{x} \frac{1}{N} \sum_{i=1}^{N} f_{i}(x) + \lambda g(x)
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;The intuition is that finding the optimal solution to this problem is
unnecessary as the goal is to minimize the "risk" (read: error) with respect to
a set of &lt;em&gt;samples&lt;/em&gt; from the true distribution of potential loss functions.
Thus, the following algorithms' convergence rates are for the &lt;em&gt;expected&lt;/em&gt; rate
of convergence (as opposed to the above algorithms which upper bound the &lt;em&gt;true&lt;/em&gt;
rate of convergence).&lt;/p&gt;
&lt;div style="overflow-x: auto"&gt;
  &lt;table markdown class="table table-bordered table-centered"&gt;
    &lt;colgroup&gt;
      &lt;col style="width:20%"&gt;
      &lt;col style="width:10%"&gt;
      &lt;col style="width:10%"&gt;
      &lt;col style="width:10%"&gt;
      &lt;col style="width:10%"&gt;
      &lt;col style="width:40%"&gt;
    &lt;/colgroup&gt;

    &lt;thead&gt;
      &lt;tr&gt;
        &lt;th&gt;Algorithm          &lt;/th&gt;
        &lt;th&gt;Problem Formulation&lt;/th&gt;
        &lt;th&gt;Convex             &lt;/th&gt;
        &lt;th&gt;Strongly Convex    &lt;/th&gt;
        &lt;th&gt;Per-Iteration Cost &lt;/th&gt;
        &lt;th&gt;Notes              &lt;/th&gt;
      &lt;/tr&gt;
    &lt;/thead&gt;

    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;!-- Algorithm          --&gt;
        &lt;td&gt;Stochastic Gradient Descent (SGD)&lt;/td&gt;
        &lt;!-- Problem            --&gt;
        &lt;td&gt;$\displaystyle \min_{x \in \mathbb{R}^n} \sum_{i} f_{i}(x) + \lambda g(x)$&lt;/td&gt;
        &lt;!-- Convex             --&gt;
        &lt;td&gt;$O(n/\epsilon^2)$[^bach-2012]&lt;/td&gt;
        &lt;!-- Strongly Convex    --&gt;
        &lt;td&gt;$O(n/\epsilon)$[^bach-2012]&lt;/td&gt;
        &lt;!-- Per-Iteration Cost --&gt;
        &lt;td&gt;$O(n)$&lt;/td&gt;
        &lt;!-- Notes              --&gt;
        &lt;td&gt;
          Assumes objective is differentiable.
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;!-- Algorithm          --&gt;
        &lt;td&gt;Stochastic Dual Coordinate Ascent (SDCA)&lt;/td&gt;
        &lt;!-- Problem            --&gt;
        &lt;td&gt;$\displaystyle \min_{x \in \mathbb{R}^n} \sum_{i} f_{i}(x) + \frac{\lambda}{2} \norm{x}_2^2$&lt;/td&gt;
        &lt;!-- Convex             --&gt;
        &lt;td&gt;$O(\frac{1}{\lambda \epsilon})$[^shalevshwartz-2012]&lt;/td&gt;
        &lt;!-- Strongly Convex    --&gt;
        &lt;td&gt;$O(( \frac{1}{\lambda} ) \log ( \frac{1}{\lambda \epsilon} ))$[^shalevshwartz-2012]&lt;/td&gt;
        &lt;!-- Per-Iteration Cost --&gt;
        &lt;td&gt;$O(n)$&lt;/td&gt;
        &lt;!-- Notes              --&gt;
        &lt;td&gt;
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;!-- Algorithm          --&gt;
        &lt;td&gt;Accelerated Proximal Stochastic Dual Coordinate Ascent (APSDCA)&lt;/td&gt;
        &lt;!-- Problem            --&gt;
        &lt;td&gt;$\displaystyle \min_{x \in \mathbb{C}} \sum_{i} f_{i}(x) + \lambda g(x)$&lt;/td&gt;
        &lt;!-- Convex             --&gt;
        &lt;td&gt;$O(\min (\frac{1}{\lambda \epsilon}, \sqrt{\frac{N}{\lambda \epsilon}} ))$[^shalevshwartz-2013]&lt;/td&gt;
        &lt;!-- Strongly Convex    --&gt;
        &lt;td&gt;$O(\min (\frac{1}{\lambda}, \sqrt{\frac{N}{\lambda}}) \log ( \frac{1}{\epsilon} ))$[^shalevshwartz-2013]&lt;/td&gt;
        &lt;!-- Per-Iteration Cost --&gt;
        &lt;td&gt;$O(n)$&lt;/td&gt;
        &lt;!-- Notes              --&gt;
        &lt;td&gt;
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;!-- Algorithm          --&gt;
        &lt;td&gt;Stochastic Average Gradient (SAG)&lt;/td&gt;
        &lt;!-- Problem            --&gt;
        &lt;td&gt;$\displaystyle \min_{x \in \mathbb{R}^n} \sum_{i} f_{i}(x) + \lambda g(x)$&lt;/td&gt;
        &lt;!-- Convex             --&gt;
        &lt;td&gt;$O(1 / \epsilon)$[^schmidt-2013]&lt;/td&gt;
        &lt;!-- Strongly Convex    --&gt;
        &lt;td&gt;$O(\log (1/\epsilon))$[^schmidt-2013]&lt;/td&gt;
        &lt;!-- Per-Iteration Cost --&gt;
        &lt;td&gt;$O(n)$&lt;/td&gt;
        &lt;!-- Notes              --&gt;
        &lt;td&gt;
          Applicable when $f_{i}(x)$ is differentiable.
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;!-- Algorithm          --&gt;
        &lt;td&gt;Stochastic Variance Reduced Gradient (SVRG)&lt;/td&gt;
        &lt;!-- Problem            --&gt;
        &lt;td&gt;$\displaystyle \min_{x \in \mathbb{R}^n} \sum_{i} f_{i}(x) + \lambda g(x)$&lt;/td&gt;
        &lt;!-- Convex             --&gt;
        &lt;td&gt;$O(1 / \epsilon)$[^johnson-2013]&lt;/td&gt;
        &lt;!-- Strongly Convex    --&gt;
        &lt;td&gt;$O(\log (1/\epsilon))$[^johnson-2013]&lt;/td&gt;
        &lt;!-- Per-Iteration Cost --&gt;
        &lt;td&gt;$O(n)$&lt;/td&gt;
        &lt;!-- Notes              --&gt;
        &lt;td&gt;
          Applicable when $f_{i}(x)$ is differentiable.
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;!-- Algorithm          --&gt;
        &lt;td&gt;MISO&lt;/td&gt;
        &lt;!-- Problem            --&gt;
        &lt;td&gt;$\displaystyle \min_{x \in \mathbb{R}^n} \sum_{i} f_{i}(x) + \lambda g(x)$&lt;/td&gt;
        &lt;!-- Convex             --&gt;
        &lt;td&gt;$O(1 / \epsilon)$[^mairal-2013]&lt;/td&gt;
        &lt;!-- Strongly Convex    --&gt;
        &lt;td&gt;$O(\log (1/\epsilon))$[^mairal-2013]&lt;/td&gt;
        &lt;!-- Per-Iteration Cost --&gt;
        &lt;td&gt;$O(n)$&lt;/td&gt;
        &lt;!-- Notes              --&gt;
        &lt;td&gt;
          Applicable when $f_{i}(x)$ is differentiable. $g(x)$ may be used as
          a barrier function.
        &lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;h1&gt;Other Methods&lt;/h1&gt;
&lt;p&gt;The following methods do not fit well into any of the preceding categories.
Included are meta-algorithms like ADMM, which are good for distributing
computation across machines, and methods whose per-iteration complexity depends
on iteration count &lt;span class="math"&gt;\(t\)&lt;/span&gt;.&lt;/p&gt;
&lt;div style="overflow-x: auto"&gt;
  &lt;table markdown class="table table-bordered table-centered"&gt;
    &lt;colgroup&gt;
      &lt;col style="width:20%"&gt;
      &lt;col style="width:10%"&gt;
      &lt;col style="width:10%"&gt;
      &lt;col style="width:10%"&gt;
      &lt;col style="width:10%"&gt;
      &lt;col style="width:40%"&gt;
    &lt;/colgroup&gt;

    &lt;thead&gt;
      &lt;tr&gt;
        &lt;th&gt;Algorithm          &lt;/th&gt;
        &lt;th&gt;Problem Formulation&lt;/th&gt;
        &lt;th&gt;Convex             &lt;/th&gt;
        &lt;th&gt;Strongly Convex    &lt;/th&gt;
        &lt;th&gt;Per-Iteration Cost &lt;/th&gt;
        &lt;th&gt;Notes              &lt;/th&gt;
      &lt;/tr&gt;
    &lt;/thead&gt;

    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;!-- Algorithm          --&gt;
        &lt;td&gt;Alternating Direction Method of Multipliers (ADMM)&lt;/td&gt;
        &lt;!-- Problem            --&gt;
        &lt;td&gt;
          $$
            \begin{align*}
              \min_{x,z} \quad
                &amp; f(x) + g(z) \\
              \text{s.t.} \quad
                &amp; Ax + Bz = c
            \end{align*}
          $$
        &lt;/td&gt;
        &lt;!-- Convex             --&gt;
        &lt;td&gt;$O(1/\epsilon)$[^blog-admm]&lt;/td&gt;
        &lt;!-- Strongly Convex    --&gt;
        &lt;td&gt;$O(\log (1/\epsilon))$[^hong-2012]&lt;/td&gt;
        &lt;!-- Per-Iteration Cost --&gt;
        &lt;td&gt;$O(n)$&lt;/td&gt;
        &lt;!-- Notes              --&gt;
        &lt;td&gt;
          The stated convergence rate for "Strongly Convex" only requires $f(x)$ to
          be strongly convex, not $g(x)$. This same rate can also be applied to
          the "Convex" case under several non-standard assumptions[^hong-2012].
          Matrices $A$ and $B$ may also need to be full column rank[^deng-2012] .
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;!-- Algorithm          --&gt;
        &lt;td&gt;Bundle Method&lt;/td&gt;
        &lt;!-- Problem            --&gt;
        &lt;td&gt;$\displaystyle \min_{x \in \mathcal{C}} f(x)$&lt;/td&gt;
        &lt;!-- Convex             --&gt;
        &lt;td&gt;$O(1/\epsilon)$[^smola-2007]&lt;/td&gt;
        &lt;!-- Strongly Convex    --&gt;
        &lt;td&gt;$O(\log (1 / \epsilon))$[^smola-2007]&lt;/td&gt;
        &lt;!-- Per-Iteration Cost --&gt;
        &lt;td&gt;$O(tn)$&lt;/td&gt;
        &lt;!-- Notes              --&gt;
        &lt;td&gt;
        &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;!-- Algorithm          --&gt;
        &lt;td&gt;Center of Gravity Algorithm&lt;/td&gt;
        &lt;!-- Problem            --&gt;
        &lt;td&gt;$\displaystyle \min_{x \in \mathcal{C}} f(x)$&lt;/td&gt;
        &lt;!-- Convex             --&gt;
        &lt;td&gt;$O(\log (1 / \epsilon))$[^ee236c-localization]&lt;/td&gt;
        &lt;!-- Strongly Convex    --&gt;
        &lt;td&gt;$O(\log (1 / \epsilon))$[^ee236c-localization]&lt;/td&gt;
        &lt;!-- Per-Iteration Cost --&gt;
        &lt;td&gt;At least $O(tn)$&lt;/td&gt;
        &lt;!-- Notes              --&gt;
        &lt;td&gt;
          Applicable when $\mathcal{C}$ is bounded. Each iteration requires
          finding a near-central point in a convex set; this may be
          computationally expensive.
        &lt;/td&gt;
      &lt;/tr&gt;

    &lt;/tbody&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;!-- Footnotes --&gt;
&lt;!-- References --&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:blog-gd"&gt;
&lt;p&gt;&lt;a href="https://stronglyconvex.com/blog/gradient-descent.html"&gt;Gradient Descent&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:blog-gd" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:blog-sd"&gt;
&lt;p&gt;&lt;a href="https://stronglyconvex.com/blog/subgradient-descent.html"&gt;Subgradient Descent&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:blog-sd" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:blog-agd"&gt;
&lt;p&gt;&lt;a href="https://stronglyconvex.com/blog/accelerated-gradient-descent.html"&gt;Accelerated Gradient Descent&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:blog-agd" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:blog-pgd"&gt;
&lt;p&gt;&lt;a href="https://stronglyconvex.com/blog/proximal-gradient-descent.html"&gt;Proximal Gradient Descent&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:blog-pgd" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:blog-apgd"&gt;
&lt;p&gt;&lt;a href="https://stronglyconvex.com/blog/accelerated-proximal-gradient-descent.html"&gt;Accelerated Proximal Gradient Descent&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:blog-apgd" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:blog-fw"&gt;
&lt;p&gt;&lt;a href="https://stronglyconvex.com/blog/frank-wolfe.html"&gt;Franke-Wolfe Algorithm&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:blog-fw" title="Jump back to footnote 6 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:blog-admm"&gt;
&lt;p&gt;&lt;a href="https://stronglyconvex.com/blog/admm-revisited.html"&gt;Alternating Direction Method of Multipliers&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:blog-admm" title="Jump back to footnote 7 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:richtarik-2011"&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/abs/1107.2848"&gt;Richtarik and Takac, 2011&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:richtarik-2011" title="Jump back to footnote 8 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:ee381-md"&gt;
&lt;p&gt;&lt;a href="http://users.ece.utexas.edu/~cmcaram/EE381V_2012F/Lecture_24_Scribe_Notes.final.pdf"&gt;EE381 Slides on Mirror Descent&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:ee381-md" title="Jump back to footnote 9 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:ee381-gd"&gt;
&lt;p&gt;&lt;a href="http://users.ece.utexas.edu/~cmcaram/EE381V_2012F/Lecture_4_Scribe_Notes.final.pdf"&gt;EE381 Slides on Gradient Descent&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:ee381-gd" title="Jump back to footnote 10 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:bubeck-agd"&gt;
&lt;p&gt;&lt;a href="https://blogs.princeton.edu/imabandit/2014/03/06/nesterovs-accelerated-gradient-descent-for-smooth-and-strongly-convex-optimization/"&gt;Sebastien Bubeck's article on Accelerated Gradient Descent for Smooth and Strongly Convex objectives&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:bubeck-agd" title="Jump back to footnote 11 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:garber-2014"&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/abs/1406.1305"&gt;Garber and Hazan, 2014&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:garber-2014" title="Jump back to footnote 12 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:mairal-2013"&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/abs/1305.3120"&gt;Mairal, 2013&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:mairal-2013" title="Jump back to footnote 13 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:ee364a-unconstrained"&gt;
&lt;p&gt;&lt;a href="http://web.stanford.edu/class/ee364a/lectures/unconstrained.pdf"&gt;EE364a Slides on Unconstrained Optimization Algorithms&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:ee364a-unconstrained" title="Jump back to footnote 14 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:ee236c-qnewton"&gt;
&lt;p&gt;&lt;a href="http://www.seas.ucla.edu/~vandenbe/236C/lectures/qnewton.pdf"&gt;EE236c Slides on Quasi-Newton Methods&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:ee236c-qnewton" title="Jump back to footnote 15 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:bach-2012"&gt;
&lt;p&gt;&lt;a href="http://www.ann.jussieu.fr/~plc/bach2012.pdf"&gt;Bach's slides on Stochastic Methods&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:bach-2012" title="Jump back to footnote 16 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:shalevshwartz-2012"&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/abs/1209.1873"&gt;Shalev-Shwartz and Zhang, 2012&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:shalevshwartz-2012" title="Jump back to footnote 17 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:shalevshwartz-2013"&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/abs/1309.2375"&gt;Shalev-Shwartz and Zhang, 2013&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:shalevshwartz-2013" title="Jump back to footnote 18 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:schmidt-2013"&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/abs/1309.2388"&gt;Schmidt et al, 2013&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:schmidt-2013" title="Jump back to footnote 19 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:deng-2012"&gt;
&lt;p&gt;&lt;a href="ftp://ftp.math.ucla.edu/pub/camreport/cam12-52.pdf"&gt;Deng and Yin, 2012&lt;/a&gt;, Table 1.1&amp;#160;&lt;a class="footnote-backref" href="#fnref:deng-2012" title="Jump back to footnote 20 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:hong-2012"&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/abs/1208.3922"&gt;Hong and Luo, 2012&lt;/a&gt;, Section 2&amp;#160;&lt;a class="footnote-backref" href="#fnref:hong-2012" title="Jump back to footnote 21 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:johnson-2013"&gt;
&lt;p&gt;&lt;a href="http://papers.nips.cc/paper/4937-accelerating-stochastic-gradient-descent-using-predictive-variance-reduction.pdf"&gt;Johnson and Zhang, 2013&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:johnson-2013" title="Jump back to footnote 22 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:smola-2007"&gt;
&lt;p&gt;&lt;a href="http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2007_470.pdf"&gt;Smola and Zhang, 2007&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:smola-2007" title="Jump back to footnote 23 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:ee236c-localization"&gt;
&lt;p&gt;&lt;a href="http://www.seas.ucla.edu/~vandenbe/236C/lectures/localization.pdf"&gt;EE236c Slides on Cutting Planes&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:ee236c-localization" title="Jump back to footnote 24 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:nesterov-2007"&gt;
&lt;p&gt;&lt;a href="http://ium.mccme.ru/postscript/s12/GS-Nesterov%20Primal-dual.pdf"&gt;Nesterov, 2007&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:nesterov-2007" title="Jump back to footnote 25 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:nedich-2013"&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/abs/1307.1879"&gt;Nedich and Lee, 2013&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:nedich-2013" title="Jump back to footnote 26 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="optimization"></category><category term="optimization"></category><category term="convergence"></category><category term="reference"></category></entry><entry><title>From ADMM to Proximal Gradient Descent</title><link href="https://stronglyconvex.com/blog/admm-to-prox-grad.html" rel="alternate"></link><published>2014-07-26T00:00:00-07:00</published><updated>2014-07-26T00:00:00-07:00</updated><author><name>Daniel Duckworth</name></author><id>tag:stronglyconvex.com,2014-07-26:/blog/admm-to-prox-grad.html</id><summary type="html">&lt;p&gt;At first blush, &lt;a href="https://stronglyconvex.com/blog/admm.html"&gt;ADMM&lt;/a&gt; and &lt;a href="https://stronglyconvex.com/blog/proximal-gradient-descent.html"&gt;Proximal Gradient Descent&lt;/a&gt;
(ProxGrad) appear to have very little in common. The convergence analyses for
these two methods are unrelated, and the former operates on an Augmented
Lagrangian while the latter directly minimizes the primal objective. In this
post, we'll show that after a slight …&lt;/p&gt;</summary><content type="html">&lt;p&gt;At first blush, &lt;a href="https://stronglyconvex.com/blog/admm.html"&gt;ADMM&lt;/a&gt; and &lt;a href="https://stronglyconvex.com/blog/proximal-gradient-descent.html"&gt;Proximal Gradient Descent&lt;/a&gt;
(ProxGrad) appear to have very little in common. The convergence analyses for
these two methods are unrelated, and the former operates on an Augmented
Lagrangian while the latter directly minimizes the primal objective. In this
post, we'll show that after a slight modification to ADMM, we recover the
proximal gradient algorithm applied to Lagrangian &lt;em&gt;dual&lt;/em&gt; of the ADMM objective.&lt;/p&gt;
&lt;p&gt;To be precise, we'll first make a slight modification to ADMM to construct
another algorithm known as the &lt;a href="http://dspace.mit.edu/bitstream/handle/1721.1/3103/P-1836-19477130.pdf"&gt;Alternating Minimization Algorithm&lt;/a&gt; (AMA).
We'll then show this algorithm is an instance of a more general technique for
&lt;a href="http://supernet.isenberg.umass.edu/austria_lectures/fvisli.pdf"&gt;Variational Inequality problems&lt;/a&gt; called
&lt;a href="http://machinelearning.wustl.edu/mlpapers/paper_files/jmlr10_duchi09a.pdf"&gt;Forward-Backward Splitting&lt;/a&gt; (FOBOS). Finally, we'll show that ProxGrad
is also an instance of FOBOS with the exact same form. We conclude that these
two algorithms are equivalent.&lt;/p&gt;
&lt;h1&gt;&lt;a name="ama" href="#ama"&gt;Alternating Minimization Algorithm&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;The &lt;a href="http://dspace.mit.edu/bitstream/handle/1721.1/3103/P-1836-19477130.pdf"&gt;Alternating Minimization Algorithm&lt;/a&gt; (AMA), originally proposed by
Paul Tseng in 1988, is an algorithm very similar to ADMM. In fact, the only
difference between these two methods is in the first step of each iteration.
Recall the pseudocode for ADMM; whereas ADMM minimizes the &lt;em&gt;Augmented&lt;/em&gt;
Lagrangian with respect to &lt;span class="math"&gt;\(x\)&lt;/span&gt;, AMA minimizes the &lt;em&gt;Non-Augmented&lt;/em&gt; Lagrangian,&lt;/p&gt;
&lt;div class="pseudocode"&gt;
&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt; Step size &lt;span class="math"&gt;\(\rho\)&lt;/span&gt;, initial primal iterates &lt;span class="math"&gt;\(x^{(0)}\)&lt;/span&gt; and &lt;span class="math"&gt;\(z^{(0)}\)&lt;/span&gt;,
            initial dual iterate &lt;span class="math"&gt;\(y^{(0)}\)&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;For &lt;span class="math"&gt;\(t = 0, 1, \ldots\)&lt;/span&gt;&lt;ol&gt;
&lt;li&gt;Let &lt;span class="math"&gt;\(x^{(t+1)} = \underset{x}{\text{argmin}} \quad L_{   0}( x        , z^{(t)}, y^{(t)} )\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Let &lt;span class="math"&gt;\(z^{(t+1)} = \underset{z}{\text{argmin}} \quad L_{\rho}( x^{(t+1)}, z      , y^{(t)} )\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Let &lt;span class="math"&gt;\(y^{(t+1)} = y^{(t)} + \rho ( Ax^{(t+1)} + Bz^{(t+1)} - c )\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;p&gt;Notice the &lt;span class="math"&gt;\(0\)&lt;/span&gt; instead of &lt;span class="math"&gt;\(\rho\)&lt;/span&gt; in the definition of &lt;span class="math"&gt;\(x^{(t+1)}\)&lt;/span&gt;. This tiny
change, we'll see, is all that's necessary to turn ADMM into ProxGrad.&lt;/p&gt;
&lt;h1&gt;&lt;a name="vi" href="#vi"&gt;Variational Inequalties&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;To show the similarity between AMA and ProxGrad, we'll show that both
algorithms are instances of Forward-Backward Splitting (FOBOS). Unlike other
algorithms we've considered, FOBOS isn't about minimizing a real-valued
objective function subject to constraints. Instead, FOBOS solves Variational
Inequality problems, which we'll now describe.&lt;/p&gt;
&lt;p&gt;Variational Inequality (VI) problems involve a vector-to-vector function
&lt;span class="math"&gt;\(F: \mathbb{R}^n \rightarrow \mathbb{R}^n\)&lt;/span&gt; and a convex set &lt;span class="math"&gt;\(\mathcal{C}\)&lt;/span&gt;. The
goal is to find an input &lt;span class="math"&gt;\(w^{*}\)&lt;/span&gt; such that,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{equation*}
  \forall w \in \mathcal{C} \quad
  \langle F(w^{*}), w - w^{*} \rangle \ge 0
\end{equation*}
$$&lt;/div&gt;
&lt;p&gt;If &lt;span class="math"&gt;\(\mathcal{C} = \mathcal{R}^n\)&lt;/span&gt;, then this inequality can only hold when
&lt;span class="math"&gt;\(F(w^{*}) = 0\)&lt;/span&gt;. For example, if &lt;span class="math"&gt;\(F = \nabla f\)&lt;/span&gt; for a differentiable convex
objective function &lt;span class="math"&gt;\(f\)&lt;/span&gt;, then finding &lt;span class="math"&gt;\(F(w^{*}) = 0\)&lt;/span&gt; is the same as a finding
&lt;span class="math"&gt;\(f\)&lt;/span&gt;'s unconstrained global minimum. Incorporating constraints is as simple as
letting &lt;span class="math"&gt;\(F(w) = [\nabla_x L(x,y); -\nabla_y L(x,y)]\)&lt;/span&gt; for Lagrangian &lt;span class="math"&gt;\(L(x,y)\)&lt;/span&gt;
with primal variable &lt;span class="math"&gt;\(x\)&lt;/span&gt; and dual variable &lt;span class="math"&gt;\(y\)&lt;/span&gt; and &lt;span class="math"&gt;\(w = [x; y]\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;What is not covered in this setup, however, is the case when &lt;span class="math"&gt;\(L\)&lt;/span&gt; is not
differentiable with respect to all parameters. We can expand on the concept of
Variational Inequalties a bit by letting &lt;span class="math"&gt;\(F(w)\)&lt;/span&gt; be a &lt;em&gt;subset&lt;/em&gt; of
&lt;span class="math"&gt;\(\mathcal{R}^{n}\)&lt;/span&gt; instead of a single value (that is,
&lt;span class="math"&gt;\(F: \mathcal{R}^n \rightarrow 2^{\mathcal{R}^{n}}\)&lt;/span&gt;). We'll say that &lt;span class="math"&gt;\(F\)&lt;/span&gt; is
a &lt;em&gt;monotone operator&lt;/em&gt; if,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \forall w,w' \in \mathcal{C}; \,
  \forall u \in F(w);           \,
  \forall v \in F(w')           \quad
  \langle u-v, w-w' \rangle \ge 0
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Now if &lt;span class="math"&gt;\(\mathcal{C} = \mathcal{R}^n\)&lt;/span&gt; and
&lt;span class="math"&gt;\(F = [\partial_x L(x,y); -\partial_y L(x,y)]\)&lt;/span&gt;, we can see that finding
&lt;span class="math"&gt;\(0 \in F(w^{*})\)&lt;/span&gt; is the same as solving the optimization described by &lt;span class="math"&gt;\(L\)&lt;/span&gt; for
non-smooth objective and constraint functions.&lt;/p&gt;
&lt;h1&gt;&lt;a name="fobos" href="#fobos"&gt;Forward-Backward Splitting&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;a href="http://machinelearning.wustl.edu/mlpapers/paper_files/jmlr10_duchi09a.pdf"&gt;Forward-Backward Splitting&lt;/a&gt; FOBOS is an algorithm for finding
a &lt;span class="math"&gt;\(w^{*}\)&lt;/span&gt; that solves VI problems for particular choices of &lt;span class="math"&gt;\(F\)&lt;/span&gt;. Namely,
we'll make the following assumptions.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;span class="math"&gt;\(F(w) = \Psi(w) + \Theta(w)\)&lt;/span&gt; for &lt;a href="http://web.stanford.edu/class/ee364b/lectures/monotone_slides.pdf"&gt;monotone operators&lt;/a&gt; &lt;span class="math"&gt;\(\Psi\)&lt;/span&gt; and
  &lt;span class="math"&gt;\(\Theta\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\Psi(w)\)&lt;/span&gt; has exactly one value for each &lt;span class="math"&gt;\(w\)&lt;/span&gt; in its domain.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Given this, FOBOS will converge to a &lt;span class="math"&gt;\(w^{*}\)&lt;/span&gt; such that &lt;span class="math"&gt;\(0 \in F(w^{*})\)&lt;/span&gt;. The
algorithm itself is,&lt;/p&gt;
&lt;div class="pseudocode"&gt;
&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt; Step sizes &lt;span class="math"&gt;\(\{ \rho_t \}_{t=1}^{\infty}\)&lt;/span&gt;, initial iterate &lt;span class="math"&gt;\(w^{(0)}\)&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;For &lt;span class="math"&gt;\(t = 0, 1, \ldots\)&lt;/span&gt;&lt;ol&gt;
&lt;li&gt;Let &lt;span class="math"&gt;\(w^{(t+1/2)} = w^{(t)} - \rho_t \Psi(w^{(t)})\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Let &lt;span class="math"&gt;\(w^{(t+1)}\)&lt;/span&gt; be such that &lt;span class="math"&gt;\(w^{(t+1)} + \rho_t \Theta(w^{(t+1)}) = w^{(t+1/2)}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;p&gt;An equivalent, more concise way to describe FOBOS is with
&lt;span class="math"&gt;\(w^{(t+1)} = (I + \rho_t \Theta)^{-1} (I - \rho_t \Psi) (w^{(t)})\)&lt;/span&gt;. With this
formulation in mind, we'll now show that both AMA and ProxGrad are instances of
FOBOS performing the same set of operations.&lt;/p&gt;
&lt;h1&gt;&lt;a name="reductions" href="#reductions"&gt;Reductions to FOBOS&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;We'll now show that for the specific optimization problem tackled by ADMM,
AMA is the same as Proximal Gradient Descent on the dual problem. First, recall
the problem ADMM is solving,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align}
\begin{split}
  \underset{x,z}{\text{minimize}} \qquad
    &amp;amp; f(x) + g(z) \\
  \text{s.t.}                     \qquad
    &amp;amp; Ax + Bz = c \\
\end{split} \label{eqn:primal}
\end{align}
$$&lt;/div&gt;
&lt;p&gt;The dual problem to this is then,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align}
\begin{split}
  - \underset{y}{\text{minimize}} \qquad
    &amp;amp; f^{*}(A^{T} y) + g^{*}(B^{T} z) - \langle y, c \rangle \\
\end{split} \label{eqn:dual}
\end{align}
$$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(f^{*}\)&lt;/span&gt; and &lt;span class="math"&gt;\(g^{*}\)&lt;/span&gt; are the &lt;a href="http://en.wikipedia.org/wiki/Convex_conjugate"&gt;convex conjugates&lt;/a&gt; to
&lt;span class="math"&gt;\(f\)&lt;/span&gt; and &lt;span class="math"&gt;\(g\)&lt;/span&gt;, respectively. We'll now show that both AMA and Proximal Gradient
Descent are optimizing this same dual.&lt;/p&gt;
&lt;h2&gt;&lt;a name="prox-grad-to-fobos" href="#prox-grad-to-fobos"&gt;Proximal Gradient Descent to FOBOS&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Suppose we want to minimize &lt;span class="math"&gt;\(f^{*}(A^T y) + g^{*}(B^T y)\)&lt;/span&gt;. If the problem is
unconstrained, this is equivalent to finding&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  0 \in F(y)
  &amp;amp;= \partial_y \left( f^{*}(A^T y) + g(B^T y) - \langle y, c \rangle \right) \\
  &amp;amp;= A (\nabla_y f^{*})(A^T y) + B (\partial_y g^{*})(B^T y) - c
  \end{align*}
$$&lt;/div&gt;
&lt;p&gt;Let's now define,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align}
  \Psi(y)   &amp;amp;= A (\nabla_y   f^{*})(A^T y)     &amp;amp;
  \Theta(y) &amp;amp;= B (\partial_y g^{*})(B^T y) - c
  \label{eqn:fobos-def}
\end{align}
$$&lt;/div&gt;
&lt;p&gt;Clearly, &lt;span class="math"&gt;\((I - \rho_{t} \Psi)(y) = y - \rho_{t} A (\nabla_y f^{*})(A^T y)\)&lt;/span&gt;
matches the first part of FOBOS and the "gradient step" part of ProxGrad, but
we also need to show that,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \text{prox}_{\rho_t g^{*}(B^T \cdot) - \langle \cdot, c \rangle}(y)
  &amp;amp; = (I + \rho_{t} \Theta)^{-1}(y)
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;To do this, let's recall the definition of the prox operator,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \bar{y}
  &amp;amp; = \text{prox}_{\rho_t g^{*}(B^T \cdot) - \langle \cdot, c \rangle}(y) \\
  &amp;amp; = \argmin_{y'}  g^{*}(B^T y')
                    - \langle y', c \rangle
                    + \frac{1}{2\rho_t}\norm{y'-y}_2^2
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Since this is an unconstrained minimization problem, we know that &lt;span class="math"&gt;\(0\)&lt;/span&gt; must be
in the subgradient of this expression at &lt;span class="math"&gt;\(\bar{y}\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  0
  &amp;amp; \in B (\partial_{\bar{y}} g^{*})(B^T \bar{y}) - c + \frac{1}{\rho_t} (\bar{y}-y)  \\
  y
  &amp;amp; \in \bar{y} + \rho_t \left( B (\partial_{\bar{y}} g^{*})(B^T \bar{y}) - c \right) \\
  &amp;amp; = (I + \rho_t \Theta)(\bar{y})
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Apply &lt;span class="math"&gt;\((I + \rho_t \Theta)^{-1}\)&lt;/span&gt; to both sides gives us the desired result,
We now have that for the above choices of &lt;span class="math"&gt;\(\Psi\)&lt;/span&gt; and &lt;span class="math"&gt;\(\Theta\)&lt;/span&gt;, ProxGrad can
be reframed as identical to FOBOS,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  y^{(t+1)} = (I + \rho_t \Theta)^{-1} (I - \rho_t \Psi) (y^{(t)})
\end{align*}
$$&lt;/div&gt;
&lt;h2&gt;&lt;a name="ama-to-fobos" href="#ama-to-fobos"&gt;AMA to FOBOS&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;We'll now show that AMA as applied to the ADMM objective is
simply an instance of FOBOS. Similar to the &lt;a href="#prox-grad-to-fobos"&gt;ProxGrad
reduction&lt;/a&gt;, we'll use the following definitions for
&lt;span class="math"&gt;\(\Psi\)&lt;/span&gt; and &lt;span class="math"&gt;\(\Theta\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \Psi(y)   &amp;amp;= A (\nabla   f^{*})(A^T y)      &amp;amp;
  \Theta(y) &amp;amp;= B (\partial g^{*})(B^T y) - c
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;First, recall the subgradient optimality condition as applied to Step B of
ADMM (same as AMA). In particular, for &lt;span class="math"&gt;\(z^{(t+1)}\)&lt;/span&gt; to be the argmin of
&lt;span class="math"&gt;\(L(x^{(t+1)}, z, y^{(t)})\)&lt;/span&gt;, it must be the case that,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  0
  &amp;amp;\in \partial g(z^{(t+1)}) - B^T y^{(t)} - \rho B^T (c - Ax^{(t+1)} - Bz^{(t+1)}) \\
  B^T ( y^{(t)} + \rho (c - Ax^{(t+1)} - Bz^{(t+1)}) )
  &amp;amp;\in \partial g(z^{(t+1)})
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Using &lt;span class="math"&gt;\(y \in \partial f(x) \Rightarrow x \in \partial f^{*}(y)\)&lt;/span&gt;, we obtain,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  z^{(t+1)}
  &amp;amp; \in \partial g^{*}(B^T ( y^{(t)} + \rho (c - Ax^{(t+1)} - Bz^{(t+1)}) ))
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;We now left-multiply by &lt;span class="math"&gt;\(B\)&lt;/span&gt;, subtract &lt;span class="math"&gt;\(c\)&lt;/span&gt; from both sides to obtain, and use
the definition of &lt;span class="math"&gt;\(\Theta\)&lt;/span&gt; to obtain,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  B z^{(t+1)} - c
  &amp;amp; \in \Theta( y^{(t)} + \rho (c - Ax^{(t+1)} - Bz^{(t+1)}) )
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Now we multiply both sides by &lt;span class="math"&gt;\(\rho\)&lt;/span&gt; and add,
&lt;span class="math"&gt;\(y^{(t)} + \rho (c - Ax^{(t+1)} - Bz^{(t+1)})\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  y^{(t)} - \rho Ax^{(t+1)}
  &amp;amp; \in (I + \rho \Theta)( y^{(t)} + \rho (c - Ax^{(t+1)} - Bz^{(t+1)}) )
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;We can invert &lt;span class="math"&gt;\(I + \rho \Theta\)&lt;/span&gt; and notice that the other side is
single-valued to obtain,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align}
  (I + \rho \Theta)^{-1} (y^{(t)} - \rho Ax^{(t+1)})
  &amp;amp; = y^{(t)} + \rho (c - Ax^{(t+1)} - Bz^{(t+1)})   \notag \\
  (I + \rho \Theta)^{-1} (y^{(t)} - \rho Ax^{(t+1)})
  &amp;amp; = y^{(t+1)}                                                 \label{eqn:ama1} \\
\end{align}
$$&lt;/div&gt;
&lt;p&gt;Now, let's apply the same subgradient optimality to Step A of AMA.&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  0
  &amp;amp;\in \partial f(x^{(t+1)}) - A^T y^{(t)} \\
  A^T y^{(t)}
  &amp;amp;= \nabla f(x^{(t+1)})
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Using &lt;span class="math"&gt;\(y = \nabla f(x) \Rightarrow x = \nabla f^{*}(y)\)&lt;/span&gt; for strongly convex
&lt;span class="math"&gt;\(f\)&lt;/span&gt; and multiplying both sides by &lt;span class="math"&gt;\(A\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align}
  A f^{*} (A^T y^{(t)}) &amp;amp;= A f(x^{(t+1)}) \notag            \\
  \Psi(y^{(t)})         &amp;amp;= A x^{(t+1)}    \label{eqn:ama2}
\end{align}
$$&lt;/div&gt;
&lt;p&gt;Substituting in equation &lt;span class="math"&gt;\(\ref{eqn:ama2}\)&lt;/span&gt; into &lt;span class="math"&gt;\(\ref{eqn:ama1}\)&lt;/span&gt;, we obtain,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  y^{(t+1)} = (I + \rho \Theta)^{-1} (I - \rho \Psi) (y^{(t)})
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Notice that this is exactly the same thing we concluded in the reduction from
ProxGrad to FOBOS. Thus, we have shown that both AMA and ProxGrad are the same
algorithm for the ADMM objective.&lt;/p&gt;
&lt;h1&gt;&lt;a name="references" href="#references"&gt;References&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Proximal Gradient Descent and ADMM&lt;/strong&gt; I was first made aware of the
relationship between AMA and ADMM in &lt;a href="http://arxiv.org/abs/1304.0499"&gt;Chi&lt;/a&gt;'s article on
convex clustering via ADMM and AMA. The relationship between Proximal Gradient
Descent and FoBoS is taken from &lt;a href="http://www.eecs.berkeley.edu/~elghaoui/Teaching/EE227A/lecture18.pdf"&gt;Berkeley's EE227a slides&lt;/a&gt; and
the relationship between FoBoS and AMA from &lt;a href="ftp://ftp.math.ucla.edu/pub/camreport/cam12-35.pdf"&gt;Goldstein et
al&lt;/a&gt;'s work on Accelerated ADMM and AMA.&lt;/p&gt;
&lt;!-- internal references --&gt;
&lt;!-- papers --&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="optimization"></category><category term="optimization"></category><category term="fobos"></category><category term="admm"></category><category term="ama"></category><category term="proximal"></category></entry><entry><title>ADMM revisited</title><link href="https://stronglyconvex.com/blog/admm-revisited.html" rel="alternate"></link><published>2014-07-20T00:00:00-07:00</published><updated>2014-07-20T00:00:00-07:00</updated><author><name>Daniel Duckworth</name></author><id>tag:stronglyconvex.com,2014-07-20:/blog/admm-revisited.html</id><summary type="html">&lt;p&gt;When I originally wrote about the &lt;a href="https://stronglyconvex.com/blog/admm.html"&gt;Alternating Direction Method of
Multipliers&lt;/a&gt; algorithm, the community's understanding of its
convergence properties was light to say the least. While it has long been
known (See &lt;a href="http://web.stanford.edu/~boyd/papers/pdf/admm_distr_stats.pdf"&gt;Boyd's excellent article&lt;/a&gt;, Appendix A) that ADMM &lt;em&gt;will&lt;/em&gt;
converge, it is only recently that the community has begun …&lt;/p&gt;</summary><content type="html">&lt;p&gt;When I originally wrote about the &lt;a href="https://stronglyconvex.com/blog/admm.html"&gt;Alternating Direction Method of
Multipliers&lt;/a&gt; algorithm, the community's understanding of its
convergence properties was light to say the least. While it has long been
known (See &lt;a href="http://web.stanford.edu/~boyd/papers/pdf/admm_distr_stats.pdf"&gt;Boyd's excellent article&lt;/a&gt;, Appendix A) that ADMM &lt;em&gt;will&lt;/em&gt;
converge, it is only recently that the community has begun to establish &lt;em&gt;how
fast&lt;/em&gt; it converges (e.g. &lt;a href="http://arxiv.org/abs/1208.3922"&gt;Hong&lt;/a&gt;, &lt;a href="ftp://ftp.math.ucla.edu/pub/camreport/cam12-52.pdf"&gt;Deng&lt;/a&gt;, &lt;a href="http://iqua.ece.toronto.edu/~cfeng/notes/cfeng-admm12.pdf"&gt;Feng&lt;/a&gt;, &lt;a href="http://www.math.hkbu.edu.hk/~xmyuan/Paper/HeYuan-SecondRevision.pdf"&gt;He&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;In this article, we'll explore one way to establish an &lt;span class="math"&gt;\(O(1 / \epsilon)\)&lt;/span&gt; rate
of convergence. Unlike previous convergence proofs presented in this blog, we
won't directly show that the primal objective value alone converges to its
optimal value; instead, we'll show that a particular function involving the
primal objective and a &lt;a href="http://supernet.isenberg.umass.edu/austria_lectures/fvisli.pdf"&gt;Variational Inequality&lt;/a&gt;
converges at the desired rate.&lt;/p&gt;
&lt;h1&gt;&lt;a name="implementation" href="#implementation"&gt;How does it work?&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Let's begin by introducing the optimization problem ADMM solves,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align}
\begin{split}
  \underset{x,z}{\text{minimize}} \qquad
    &amp;amp; f(x) + g(z) \\
  \text{s.t.}                     \qquad
    &amp;amp; Ax + Bz = c \\
\end{split} \label{eqn:objective}
\end{align}
$$&lt;/div&gt;
&lt;p&gt;This problem is characterized by 2 primal variables, &lt;span class="math"&gt;\(x\)&lt;/span&gt; and &lt;span class="math"&gt;\(z\)&lt;/span&gt;, which are
related by a linear equation. In machine learning, a common scenario is to
choose &lt;span class="math"&gt;\(A\)&lt;/span&gt;, &lt;span class="math"&gt;\(B\)&lt;/span&gt;, and &lt;span class="math"&gt;\(c\)&lt;/span&gt; such that &lt;span class="math"&gt;\(x = z\)&lt;/span&gt;, making the setup particularly
simple. For the rest of this article, we'll assume that &lt;span class="math"&gt;\(Ax + Bz = c\)&lt;/span&gt; is the
only constraint we consider -- other constraints can be incorporated into
&lt;span class="math"&gt;\(f\)&lt;/span&gt; and &lt;span class="math"&gt;\(g\)&lt;/span&gt; by letting them be infinite when constraints are broken.&lt;/p&gt;
&lt;p&gt;The ADMM algorithm then finds the "saddle point" of the Augmented
Lagrangian for the corresponding problem,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align} \label{eqn:lagrangian}
  L_{\rho}(x, z, y) = f(x) + g(z) + \langle y, Ax + Bz - c \rangle
                      + \frac{\rho}{2} || Ax + Bz - c ||_2^2
\end{align}
$$&lt;/div&gt;
&lt;p&gt;Note that we say &lt;em&gt;Augmented&lt;/em&gt; Lagrangian, as the typical Lagrangian does not
include the final quadratic term. It's easy to see, however, that the quadratic
does not affect the problem's optimal solution, as the constraint &lt;span class="math"&gt;\(Ax + Bz = c\)&lt;/span&gt;
holds for all valid solutions.&lt;/p&gt;
&lt;p&gt;The ADMM algorithm iteratively minimizes &lt;span class="math"&gt;\(L_{\rho}\)&lt;/span&gt; with respect to &lt;span class="math"&gt;\(x\)&lt;/span&gt; for
fixed &lt;span class="math"&gt;\(z\)&lt;/span&gt; and &lt;span class="math"&gt;\(y\)&lt;/span&gt;, then minimizes &lt;span class="math"&gt;\(z\)&lt;/span&gt; for fixed &lt;span class="math"&gt;\(x\)&lt;/span&gt; and &lt;span class="math"&gt;\(y\)&lt;/span&gt;, and finally
takes a gradient step with respect to &lt;span class="math"&gt;\(y\)&lt;/span&gt; for fixed &lt;span class="math"&gt;\(x\)&lt;/span&gt; and &lt;span class="math"&gt;\(z\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="pseudocode"&gt;
&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt; Step size &lt;span class="math"&gt;\(\rho\)&lt;/span&gt;, initial primal iterates &lt;span class="math"&gt;\(x^{(0)}\)&lt;/span&gt; and &lt;span class="math"&gt;\(z^{(0)}\)&lt;/span&gt;,
            initial dual iterate &lt;span class="math"&gt;\(y^{(0)}\)&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;For &lt;span class="math"&gt;\(t = 0, 1, \ldots\)&lt;/span&gt;&lt;ol&gt;
&lt;li&gt;Let &lt;span class="math"&gt;\(x^{(t+1)} = \underset{x}{\text{argmin}} \quad L_{\rho}( x        , z^{(t)}, y^{(t)} )\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Let &lt;span class="math"&gt;\(z^{(t+1)} = \underset{z}{\text{argmin}} \quad L_{\rho}( x^{(t+1)}, z      , y^{(t)} )\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Let &lt;span class="math"&gt;\(y^{(t+1)} = y^{(t)} + \rho ( Ax^{(t+1)} + Bz^{(t+1)} - c )\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;p&gt;Intuitively, the extra quadratic term prevents each iteration of the
algorithm from stepping "too far" from the last iteration, an idea that's also
at the core of &lt;a href="https://stronglyconvex.com/blog/proximal-gradient-descent.html"&gt;Proximal Gradient Descent&lt;/a&gt;.&lt;/p&gt;
&lt;div class="img-center"&gt;
&lt;p&gt;&lt;img src="/assets/img/admm/convergence.gif"&gt;&lt;/img&gt;
  &lt;span class="caption"&gt;
    Animation of &lt;span class="math"&gt;\(x_t\)&lt;/span&gt; and &lt;span class="math"&gt;\(z_t\)&lt;/span&gt; converging to the minimum of the sum of
    2 quadratics.
  &lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In the remainder of the article, we'll often use the following notation for
conciseness,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  w    &amp;amp;= \begin{bmatrix}
            x \\
            z \\
            y
          \end{bmatrix} \\
  h(w) &amp;amp;= f(x) + g(z) \\
  F(w) &amp;amp;= \begin{bmatrix}
            A^T y \\
            B^T y \\
            - (Ax + Bz - c)
          \end{bmatrix}
\end{align*}
$$&lt;/div&gt;
&lt;h1&gt;&lt;a name="proof" href="#proof"&gt;Why does it work?&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Unlike other convergence proofs presented on this website, we won't directly
show that the objective converges to its minimum as &lt;span class="math"&gt;\(t \rightarrow \infty\)&lt;/span&gt;.
Indeed, limiting ourselves to analysis of the objective completely ignores the
constraint &lt;span class="math"&gt;\(Ax + Bz = c\)&lt;/span&gt;. Instead, we'll use the following variational
inequality condition to describe an optimal solution. In particular, a solution
&lt;span class="math"&gt;\(w^{*}\)&lt;/span&gt; is optimal if,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align} \label{vi}
  \forall w \in \mathbb{R}^{n} \qquad
    h(w) - h(w^{*}) + \langle w - w^{*}, F(w^{*}) \rangle &amp;amp;\ge 0
\end{align}
$$&lt;/div&gt;
&lt;div class="img-center"&gt;
&lt;p&gt;&lt;img src="/assets/img/admm/vi.jpg"&gt;&lt;/img&gt;
  &lt;span class="caption"&gt;
    Geometric interpretation of a the optimality condition for a variational
    inequality when ignoring &lt;span class="math"&gt;\(h(w)\)&lt;/span&gt; from &lt;a href="http://supernet.isenberg.umass.edu/austria_lectures/fvisli.pdf"&gt;Anna Nagurney&lt;/a&gt;.
  &lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;For the following proof, we'll replace &lt;span class="math"&gt;\(w^{*}\)&lt;/span&gt; with
&lt;span class="math"&gt;\(\bar{w}_t = (1/t) \sum_{\tau=1}^{t} w_{\tau}\)&lt;/span&gt; and &lt;span class="math"&gt;\(0\)&lt;/span&gt; on the right hand side
with &lt;span class="math"&gt;\(-\epsilon_t\)&lt;/span&gt; where &lt;span class="math"&gt;\(\epsilon_t = O(1/t)\)&lt;/span&gt;. By showing that we can
approximately satisfy this inequality at a rate &lt;span class="math"&gt;\(O(1/t)\)&lt;/span&gt;, we establish the
desired convergence rate.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assumptions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The assumptions on ADMM are almost as light as we can imagine. This is
largely due to the fact that we needn't use gradients or subgradients for
&lt;span class="math"&gt;\(h(z)\)&lt;/span&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;span class="math"&gt;\(f(x) + g(z)\)&lt;/span&gt; is convex.&lt;/li&gt;
&lt;li&gt;There exists a solution &lt;span class="math"&gt;\([ x^{*}; z^{*} ]\)&lt;/span&gt; that minimizes &lt;span class="math"&gt;\(f(x) + g(z)\)&lt;/span&gt;
  while respecting the constraint &lt;span class="math"&gt;\(Ax + Bz = c\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Proof Outline&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The proof presented hereafter is a particularly simple if unintuitive one.
Theoretically, the only tools necessary are the linear lower bound definition
of a convex function, the subgradient condition for optimality in an
unconstrained optimization problem, and Jensen's Inequality. Steps 1 and
2 below rely purely on the first 2 of these tools. Step 3 merely massages
a preceding equation into a simpler form via completing squares. Step 4 closes
by exploiting a telescoping sum and Jensen's Inequality to obtain the desired
result,&lt;/p&gt;
&lt;div class="math"&gt;$$
\forall w \qquad
h(\bar{w}_t) - h(w) + \langle
  F(\bar{w}^{(t)}),
  \bar{w}^{(t)} - w
\rangle
\le \frac{1}{t} \left(
  \frac{\rho}{2} \norm{Ax-c}_2^2 + \frac{1}{2\rho} \norm{y}_2^2
\right)
$$&lt;/div&gt;
&lt;p&gt;As &lt;span class="math"&gt;\(t \rightarrow \infty\)&lt;/span&gt;, the right hand side of this equation goes to 0,
rendering the same statement as the variational inequality optimality condition
in Equation &lt;span class="math"&gt;\(\ref{vi}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1&lt;/strong&gt; Optimality conditions for Step A. In this portion of the proof,
we'll use the fact that &lt;span class="math"&gt;\(x^{(t+1)}\)&lt;/span&gt; is defined as the solution of an
optimization problem to derive a subgradient for &lt;span class="math"&gt;\(f\)&lt;/span&gt; at &lt;span class="math"&gt;\(x^{(t+1)}\)&lt;/span&gt;. We'll then
substitute this into &lt;span class="math"&gt;\(f\)&lt;/span&gt;'s definition of convexity. Finally, terms are
rearranged and the contents of Step C of the algorithm are used to derive
a final expression.&lt;/p&gt;
&lt;p&gt;We begin by recognizing that &lt;span class="math"&gt;\(x^{(t+1)}\)&lt;/span&gt; minimizes
&lt;span class="math"&gt;\(L_{\rho}(x, z^{(t)}, y^{(t)})\)&lt;/span&gt; as a function of &lt;span class="math"&gt;\(x\)&lt;/span&gt;. As &lt;span class="math"&gt;\(x\)&lt;/span&gt; is unconstrained,
zero must be a valid subgradient for &lt;span class="math"&gt;\(L_{\rho}\)&lt;/span&gt; evaluated at &lt;span class="math"&gt;\(x^{(t+1)},
z^{(t)}, y^{(t)}\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  0
  &amp;amp;\in \partial_x L_{\rho}(x^{(t+1)}, z^{(t)}, y^{(t)})                               \\
  &amp;amp;= \partial_{x} f(x^{(t+1)}) + A^T y^{(t)} + \rho A^T (Ax^{(t+1)} + Bz^{(t)} - c)   \\
  - A^T \left( y^{(t)} + \rho (Ax^{(t+1)} + Bz^{(t)} - c) \right)
  &amp;amp;\in \partial_x f(x^{(t+1)})
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;As &lt;span class="math"&gt;\(f\)&lt;/span&gt; is convex, we further know that it is lower bounded by its linear
approximation everywhere,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \forall x \qquad
    f(x) &amp;amp;\ge f(x^{(t+1)}) + \langle
      \partial_x f(x^{(t+1)}),
      x - x^{(t+1)}
    \rangle
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Substituting in our subgradient for &lt;span class="math"&gt;\(\partial_x f(x^{(t+1)})\)&lt;/span&gt; and subtracting
the contents of the right hand side from both sides, we obtain,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \forall x \qquad
    0 &amp;amp;\le f(x) - f(x^{(t+1)}) + \langle
      A^T (y^{(t)} + \rho (A x^{(t+1)} + B z^{(t)} - c ),
      x - x^{(t+1)}
    \rangle
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Now recall Step C of the algorithm:
&lt;span class="math"&gt;\(y^{(t+1)} = y^{(t)} + \rho (A x^{(t+1)} + Bz^{(t+1)} - c)\)&lt;/span&gt;. The left side of
the inner product looks very similar to this, so we'll substitute it in as best
we can,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \forall x \qquad
    0 &amp;amp;\le f(x) - f(x^{(t+1)}) + \langle
      A^T (y^{(t+1)} + \rho Bz^{(t)} - \rho Bz^{(t+1)}),
      x - x^{(t+1)}
    \rangle
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;We finish by moving everything &lt;em&gt;not&lt;/em&gt; multiplied by &lt;span class="math"&gt;\(\rho\)&lt;/span&gt; to the opposite
side of the inequality,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align} \label{eqn:36}
  \forall x \qquad
    f(x^{(t+1)}) - f(x) + \langle
      x^{(t+1)} - x,
      A^T y^{(t+1)}
    \rangle
    &amp;amp;\le \rho \langle
      Bz^{(t)} - Bz^{(t+1)},
      A x - A x^{(t+1)}
    \rangle
\end{align}
$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Step 2&lt;/strong&gt; Optimality conditions for Step B. Similar to Step 1, we'll use the
fact that &lt;span class="math"&gt;\(z^{(t+1)}\)&lt;/span&gt; is the solution to an unconstrained optimization problem
and will substitute in Step C's definition for &lt;span class="math"&gt;\(y^{(t+1)}\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  0
  &amp;amp;\in \partial_z L(x^{(t+1)}, z, y^{(t)})                                          \\
  &amp;amp;= \partial_z g(z^{(t+1)}) + B^T y^{(t)} + \rho B^T (Ax^{(t+1)} + Bz^{(t+1)} - c) \\
  - B^T \left( y^{(t)} + \rho (Ax^{(t+1)} + Bz^{(t+1)} - c) \right)
  &amp;amp;\in \partial_z g(z^{(t+1)})
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;As &lt;span class="math"&gt;\(g\)&lt;/span&gt; is convex, it is lower bounded by its linear approximation,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \forall z \qquad
    g(z) &amp;amp;\ge g(z^{(t+1)}) + \langle
      \partial_z g(z^{(t+1)}),
      z - z^{(t+1)}
    \rangle
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Substituting in the previously derived subgradient and moving all terms to
the left side, we obtain,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \forall z \qquad
    0 &amp;amp;\le g(z) - g(z^{(t+1)}) + \langle
      B^T (y^{(t)} + \rho (A x^{(t+1)} + B z^{(t+1)} - c )),
      z - z^{(t+1)}
    \rangle
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Substituting in Step C's definition for &lt;span class="math"&gt;\(y^{(t+1)}\)&lt;/span&gt; again and moving
everything to the opposite side of the inequality, we conclude that,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align} \label{eqn:37}
  \forall z \qquad
    g(z^{(t+1)}) - g(z) + \langle
      B^T y^{(t+1)},
      z^{(t+1)} - z
    \rangle
    &amp;amp;\le 0
\end{align}
$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Step 3&lt;/strong&gt; We now sum Equation &lt;span class="math"&gt;\(\ref{eqn:36}\)&lt;/span&gt; with Equation &lt;span class="math"&gt;\(\ref{eqn:37}\)&lt;/span&gt;.
We'll end up with an expression that is not easy to understand initially, but
by factoring several of its terms into quadratic forms and substituting them
back in, we obtain a simpler expression that can be described as a sum of
squared 2-norms.&lt;/p&gt;
&lt;p&gt;We begin by summing equations &lt;span class="math"&gt;\(\ref{eqn:36}\)&lt;/span&gt; and &lt;span class="math"&gt;\(\ref{eqn:37}\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  &amp;amp; f(x^{(t+1)}) + g(z^{(t+1)}) - f(x) - g(z) + \langle
    B^T y^{(t+1)},
    z^{(t+1)} - z
  \rangle + \langle
    A^T y^{(t+1)},
    x^{(t+1)} - x
  \rangle \\
  &amp;amp; \qquad \le \rho \langle
    Ax - Ax^{(t+1)},
    Bz^{(t)} - Bz^{(t+1)}
  \rangle
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Next, we use the definitions of &lt;span class="math"&gt;\(h(w)\)&lt;/span&gt; and &lt;span class="math"&gt;\(F(w)\)&lt;/span&gt; on the left hand side,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  &amp;amp; h(w^{(t+1)}) - h(w) + \langle
    F(w^{(t+1)}),
    w^{(t+1)} - w
  \rangle + \langle
    Ax^{(t+1)} + Bz^{(t+1)} - c,
    y^{(t+1)} - y
  \rangle \\
  &amp;amp; \qquad \le \rho \langle
    Ax - Ax^{(t+1)},
    Bz^{(t)} - Bz^{(t+1)}
  \rangle
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Then, moving the last term on the left side of the inequality over and
observing that Step C implies
&lt;span class="math"&gt;\((1/\rho) (y^{(t+1)} - y^{(t)}) = Ax^{(t+1)} + Bz^{(t+1)} - c\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align}
\begin{split}
  &amp;amp; h(w^{(t+1)}) - h(w) + \langle
    F(w^{(t+1)}),
    w^{(t+1)} - w
  \rangle  \\
  &amp;amp; \qquad \le \rho \langle
    Ax - Ax^{(t+1)},
    Bz^{(t)} - Bz^{(t+1)}
  \rangle + \frac{1}{\rho} \langle
    y^{(t+1)} - y^{(t)},
    y - y^{(t+1)}
  \rangle
\end{split} \label{eqn:38}
\end{align}
$$&lt;/div&gt;
&lt;p&gt;We will now tackle the two components on the right hand side of the
inequality in isolation. Our goal is to rewrite these inner products in terms
of sums of &lt;span class="math"&gt;\(\norm{\cdot}_2^2\)&lt;/span&gt; terms.&lt;/p&gt;
&lt;p&gt;We'll start with &lt;span class="math"&gt;\(\langle Ax - Ax^{(t+1)}, Bz^{(t)} - Bz^{(t+1)} \rangle\)&lt;/span&gt;. In
the next equations, we'll add many terms that will cancel themselves out, then
we'll group them together into a sum of 4 terms,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align}
  &amp;amp;
  \begin{split}
    2 \langle Ax - Ax^{(t+1)}, Bz^{(t)} - Bz^{(t+1)} \rangle
  \end{split} \notag \\
  &amp;amp;
  \begin{split}
  = &amp;amp; + \norm{Ax        -c}_2^2 &amp;amp; + 2 \langle Ax         - c, B z^{(t  )} \rangle &amp;amp; + \norm{Bz^{(t  )}}_2^2 \\
    &amp;amp; - \norm{Ax        -c}_2^2 &amp;amp; - 2 \langle Ax         - c, B z^{(t+1)} \rangle &amp;amp; - \norm{Bz^{(t+1)}}_2^2 \\
    &amp;amp; + \norm{Ax^{(t+1)}-c}_2^2 &amp;amp; + 2 \langle Ax^{(t+1)} - c, B z^{(t+1)} \rangle &amp;amp; + \norm{Bz^{(t+1)}}_2^2 \\
    &amp;amp; - \norm{Ax^{(t+1)}-c}_2^2 &amp;amp; - 2 \langle Ax^{(t+1)} - c, B z^{(t  )} \rangle &amp;amp; - \norm{Bz^{(t  )}}_2^2
  \end{split} \notag \\
  &amp;amp;
  \begin{split}
  = &amp;amp; + \norm{Ax         + Bz^{(t)}   - c}_2^2 &amp;amp; - \norm{Ax         + Bz^{(t+1)} - c}_2^2 \\
    &amp;amp; + \norm{Ax^{(t+1)} + Bz^{(t+1)} - c}_2^2 &amp;amp; - \norm{Ax^{(t+1)} + Bz^{(t  )} - c}_2^2
  \end{split} \label{eqn:39}
\end{align}
$$&lt;/div&gt;
&lt;p&gt;We'll do the same for &lt;span class="math"&gt;\(\langle y^{(t+1)} - y^{(t)}, y - y^{(t+1)} \rangle\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align}
  &amp;amp;
  \begin{split}
    2 \langle y^{(t+1)} - y^{(t)}, y - y^{(t+1)} \rangle
  \end{split} \notag \\
  &amp;amp;
  \begin{split}
  = &amp;amp; + \norm{y      }_2^2 &amp;amp; + 2 \langle y      , - y^{(t  )} \rangle &amp;amp; + \norm{y^{(t  )}}_2^2 \\
    &amp;amp; - \norm{y      }_2^2 &amp;amp; - 2 \langle y      , - y^{(t+1)} \rangle &amp;amp; - \norm{y^{(t+1)}}_2^2 \\
    &amp;amp; - \norm{y^{(t)}}_2^2 &amp;amp; - 2 \langle y^{(t)}, - y^{(t+1)} \rangle &amp;amp; - \norm{y^{(t+1)}}_2^2 \\
  \end{split} \notag \\
  &amp;amp;
  \begin{split}
  = &amp;amp; + \norm{y       - y^{(t  )}}_2^2
      - \norm{y       - y^{(t+1)}}_2^2
      - \norm{y^{(t)} - y^{(t+1)}}_2^2
  \end{split} \label{eqn:40}
\end{align}
$$&lt;/div&gt;
&lt;p&gt;Finally, let's plug equations &lt;span class="math"&gt;\(\ref{eqn:39}\)&lt;/span&gt; and &lt;span class="math"&gt;\(\ref{eqn:40}\)&lt;/span&gt; into
&lt;span class="math"&gt;\(\ref{eqn:38}\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align}
\begin{split}
  &amp;amp; h(w^{(t+1)}) - h(w) + \langle
    F(w^{(t+1)}),
    w^{(t+1)} - w
  \rangle  \\
  &amp;amp; \qquad \le \frac{\rho}{2} \left( \begin{split}
    &amp;amp; + \norm{Ax         + Bz^{(t  )} - c}_2^2 &amp;amp; - \norm{Ax         + Bz^{(t+1)} - c}_2^2 \\
    &amp;amp; + \norm{Ax^{(t+1)} + Bz^{(t+1)} - c}_2^2 &amp;amp; - \norm{Ax^{(t+1)} + Bz^{(t  )} - c}_2^2
  \end{split} \right) \\
  &amp;amp; \qquad + \frac{1}{2\rho} \left( \begin{split}
    &amp;amp; + \norm{y       - y^{(t  )}}_2^2 \\
    &amp;amp; - \norm{y       - y^{(t+1)}}_2^2 \\
    &amp;amp; - \norm{y^{(t)} - y^{(t+1)}}_2^2
  \end{split} \right)
\end{split}
\end{align}
$$&lt;/div&gt;
&lt;p&gt;Recall that &lt;span class="math"&gt;\((1/\rho)(y^{(t+1)} - y^{(t)}) = Ax^{(t+1)} + Bz^{(t+1)} - c\)&lt;/span&gt;. Then,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \frac{\rho}{2} \norm{ Ax^{(t+1)} + Bz^{(t+1)} - c }
  &amp;amp;= \frac{\rho}{2}  \norm{ \frac{1}{\rho} (y^{(t+1)} - y^{(t  )}) } \\
  &amp;amp;= \frac{1}{2\rho} \norm{                 y^{(t  )} - y^{(t+1)}  }
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;We can substitute that into the right hand side of the preceding equation to
cancel out a couple terms,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  = &amp;amp;
  \frac{\rho}{2} \left( \begin{split}
    &amp;amp; + \norm{Ax + Bz^{(t)} - c}_2^2 &amp;amp;             - \norm{Ax         + Bz^{(t+1)} - c}_2^2 \\
    &amp;amp;                                &amp;amp; \underbrace{- \norm{Ax^{(t+1)} + Bz^{(t  )} - c}_2^2}_{ \text{ always $\le 0$ } }
  \end{split} \right) \\
  &amp;amp; + \frac{1}{2\rho} \left( \begin{split}
    &amp;amp; + \norm{y - y^{(t  )}}_2^2 \\
    &amp;amp; - \norm{y - y^{(t+1)}}_2^2
  \end{split} \right)
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Finally dropping the portion of the equation that's always non-positive
(doing so doesn't affect the validity of the inequality), we obtain a concise
inequality in terms of sums of &lt;span class="math"&gt;\(\norm{\cdot}_2^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  &amp;amp; h(w^{(t+1)}) - h(w) + \langle
    F(w^{(t+1)}),
    w^{(t+1)} - w
  \rangle  \\
  &amp;amp; \qquad \le \frac{\rho}{2} \left(
      \norm{Ax + Bz^{(t  )} - c}_2^2
    - \norm{Ax + Bz^{(t+1)} - c}_2^2
  \right) \\
  &amp;amp; \qquad + \frac{1}{2\rho} \left(
      \norm{y - y^{(t  )}}_2^2
    - \norm{y - y^{(t+1)}}_2^2
  \right)
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Step 4&lt;/strong&gt; Averaging across iterations. We're now in the home stretch. In this
step, we'll sum the previous equation across &lt;span class="math"&gt;\(t\)&lt;/span&gt;. The sum will "telescope",
crossing out terms until we're left only with the initial and final conditions.
A quick application of Jensen's inequality will get us the desired result.&lt;/p&gt;
&lt;p&gt;We begin by summing the previous equation across iterations,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  &amp;amp; \sum_{\tau=0}^{t-1} h(w^{(\tau+1)}) - h(w) + \langle
    F(w^{(\tau+1)}),
    w^{(\tau+1)} - w
  \rangle  \\
  &amp;amp; \qquad \le \frac{\rho}{2} \left(
                  \norm{Ax + Bz^{(0)} - c}_2^2
    \underbrace{- \norm{Ax + Bz^{(t)} - c}_2^2}_{\le 0}
  \right) + \frac{1}{2\rho} \left(
                  \norm{y - y^{(0)}}_2^2
    \underbrace{- \norm{y - y^{(t)}}_2^2}_{\le 0}
  \right)
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;For convenience, we'll choose &lt;span class="math"&gt;\(z^{(0)}\)&lt;/span&gt; and &lt;span class="math"&gt;\(y^{(0)}\)&lt;/span&gt; equal to zero. We'll
also drop the terms &lt;span class="math"&gt;\(-\norm{Ax + Bz^{(t)} - c}_2^2\)&lt;/span&gt; and
&lt;span class="math"&gt;\(-\norm{y - y^{(t)}}_2^2\)&lt;/span&gt; from the expression, as both terms are always
non-positive. This gives us,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \sum_{\tau=0}^{t-1} h(w^{(\tau+1)}) - h(w) + \langle
    F(w^{(\tau+1)}),
    w^{(\tau+1)} - w
  \rangle
  \le \frac{\rho}{2}  \norm{Ax - c}_2^2
             + \frac{1}{2\rho} \norm{ y    }_2^2
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Finally, recall that for a convex function &lt;span class="math"&gt;\(h(w)\)&lt;/span&gt;, Jensen's Inequality states that&lt;/p&gt;
&lt;div class="math"&gt;$$
  h(\bar{w}_t)
  = h \left( \frac{1}{t} \sum_{\tau=1}^{t} w_{\tau} \right)
  \le \frac{1}{t} \sum_{\tau=1}^{t} h(w_{\tau})
$$&lt;/div&gt;
&lt;p&gt;The same is true for each of &lt;span class="math"&gt;\(F(w)\)&lt;/span&gt;'s components (they're linear in &lt;span class="math"&gt;\(w\)&lt;/span&gt;).
Thus, we can apply this statement to the left hand side of the preceding
equation after multiplying by &lt;span class="math"&gt;\(1/t\)&lt;/span&gt; to obtain,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  h(\bar{w}^{(t)}) - h(w) + \langle
    F(\bar{w}^{(t)}),
    \bar{w}^{(t)} - w
  \rangle
  \le \frac{1}{t} \left(
      \frac{\rho}{2}  \norm{Ax - c}_2^2
    + \frac{1}{2\rho} \norm{ y    }_2^2
  \right)
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;The right hand side decreases as &lt;span class="math"&gt;\(O(1/t)\)&lt;/span&gt;, thus ADMM converges at a rate of
at least &lt;span class="math"&gt;\(O(1/\epsilon)\)&lt;/span&gt; as desired.&lt;/p&gt;
&lt;h1&gt;&lt;a name="usage" href="#usage"&gt;When should I use it?&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Similar to the proximal methods presented on this website, ADMM is only
efficient if we can perform each of its steps efficiently. Solving
2 optimization problems at each iteration may be very fast or very slow,
depending on if a closed form solution exists for &lt;span class="math"&gt;\(x^{(t+1)}\)&lt;/span&gt; and &lt;span class="math"&gt;\(z^{(t+1)}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;ADMM has been particularly useful in supervised machine learning, where &lt;span class="math"&gt;\(A\)&lt;/span&gt;,
&lt;span class="math"&gt;\(B\)&lt;/span&gt;, and &lt;span class="math"&gt;\(c\)&lt;/span&gt; are chosen such that &lt;span class="math"&gt;\(x = z\)&lt;/span&gt;. In this scenario, &lt;span class="math"&gt;\(f\)&lt;/span&gt; is taken to be
the prediction loss on the training set, and &lt;span class="math"&gt;\(g\)&lt;/span&gt; an appropriate regularizer,
typically a norm such as &lt;span class="math"&gt;\(\ell_1\)&lt;/span&gt; or a &lt;a href="http://arxiv.org/pdf/1104.1872.pdf"&gt;group sparsity norm&lt;/a&gt;.
&lt;a href="http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Martins_150.pdf"&gt;ADMM also lends&lt;/a&gt; itself to inferring the most likely setting for
settings for latent variables in a factor graph. The primary benefit of ADMM in
both of these cases is not its rate of convergence but how &lt;a href="http://www.ece.umn.edu/users/alfonso/pubs/jmlr2010.pdf"&gt;easily it
lends itself to distributed computation&lt;/a&gt;. &lt;a href="http://arxiv.org/pdf/1009.1128.pdf"&gt;Applications in
Compressed Sensing&lt;/a&gt; see similar benefits.&lt;/p&gt;
&lt;p&gt;All in all, ADMM is &lt;em&gt;not&lt;/em&gt; a quick method, but it is a scalable one. ADMM is
best suited when data is too large to fit on a single machine or when
&lt;span class="math"&gt;\(x^{(t+1)}\)&lt;/span&gt; and &lt;span class="math"&gt;\(z^{(t+1)}\)&lt;/span&gt; can be solved for in closed form. While very
interesting in its own right, ADMM should rarely your algorithm of choice.&lt;/p&gt;
&lt;h1&gt;&lt;a name="extensions" href="#extensions"&gt;Extensions&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Accelerated&lt;/strong&gt; As ADMM is so closely related to Proximal Gradient-based
methods, one might ask if there exists an accelerated variant with a better
convergence rate. The answer is a resounding yes, as shown by &lt;a href="ftp://ftp.math.ucla.edu/pub/camreport/cam12-35.pdf"&gt;Goldstein et
al.&lt;/a&gt;, though care must be taken for non-strongly convex
objectives. In their article, Goldstein et al. show that a convergence rate of
&lt;span class="math"&gt;\(O(1/\sqrt{\epsilon})\)&lt;/span&gt; can be guaranteed if both &lt;span class="math"&gt;\(f\)&lt;/span&gt; and &lt;span class="math"&gt;\(g\)&lt;/span&gt; are strongly
convex. If this isn't the case, only a rate of &lt;span class="math"&gt;\(O(1/\epsilon)\)&lt;/span&gt; is shown.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Online&lt;/strong&gt; In online learning, one is interested in solving a series of
supervised machine learning instances in sequence with minimal error. At each
iteration, the algorithm is presented with an input &lt;span class="math"&gt;\(x_t\)&lt;/span&gt;, to which it responds
with a prediction &lt;span class="math"&gt;\(\hat{y}_t\)&lt;/span&gt;. The world then presents the algorithm with the
correct answer &lt;span class="math"&gt;\(y_t\)&lt;/span&gt;, and the algorithm suffers loss &lt;span class="math"&gt;\(l_t(y_t, \hat{y}_t)\)&lt;/span&gt;. The
goal of the algorithm is to minimize the sum of errors &lt;span class="math"&gt;\(\sum_{t} l_t(y_t,
\hat{y}_t)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In this setting, &lt;a href="http://icml.cc/2012/papers/577.pdf"&gt;Wang&lt;/a&gt; has shown that an online variant to ADMM
can achieve regret competitive with the best possible (&lt;span class="math"&gt;\(O(\sqrt{T})\)&lt;/span&gt; for
convex loss functions, &lt;span class="math"&gt;\(O(\log(T))\)&lt;/span&gt; for strongly convex loss functions).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stochastic&lt;/strong&gt; In a stochastic setting, one is interested in minimizing the
&lt;em&gt;average&lt;/em&gt; value of &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; via a series of samples. In &lt;a href="http://arxiv.org/pdf/1211.0632.pdf"&gt;Ouyang et
al&lt;/a&gt;, convergence rates for a linearized variant of ADMM when
&lt;span class="math"&gt;\(f\)&lt;/span&gt; can only be accessed through samples.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Multi Component&lt;/strong&gt; Traditional ADMM considers an objective with only
2 components &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; and &lt;span class="math"&gt;\(g(z)\)&lt;/span&gt;. While applying the same logic to 3 or more is
straightforward, proving convergence for this scenario is more difficult. This
was the task taken by &lt;a href="http://www.optimization-online.org/DB_FILE/2010/12/2871.pdf"&gt;He et al&lt;/a&gt;. In particular, they showed that
a special variant of ADMM using "Gaussian back substitution" is ensured to
converge.&lt;/p&gt;
&lt;h1&gt;&lt;a name="references" href="#references"&gt;References&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;ADMM&lt;/strong&gt; While ADMM has existed for decades, it has only recently been brought
to light by &lt;a href="https://stronglyconvex.com/blog/admm.html"&gt;Boyd&lt;/a&gt;'s article describing its applications for statistical
machine learning. It is from this work from which I initially learned of ADMM.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof of Convergence&lt;/strong&gt; The proof of convergence presented here is a verbose
expansion of that presented in &lt;a href="http://icml.cc/2012/papers/577.pdf"&gt;Wang&lt;/a&gt;'s paper on Online ADMM.&lt;/p&gt;
&lt;!-- internal references --&gt;
&lt;!-- papers --&gt;
&lt;!-- convergence proofs --&gt;
&lt;!-- extensions --&gt;
&lt;!-- uses --&gt;
&lt;h1&gt;&lt;a name="reference-impl" href="#reference-impl"&gt;Reference Implementation&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Using the &lt;a href="https://github.com/duckworthd/optim"&gt;&lt;code&gt;optim&lt;/code&gt;&lt;/a&gt; Python package, we can generate the animation above,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;Example usage of ADMM solver.&lt;/span&gt;

&lt;span class="sd"&gt;A gif is generated showing the iterates as they converge.&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;matplotlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;animation&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;optim.admm&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;optim.tests.test_admm&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;quadratic1&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;itertools&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;it&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt;     &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pylab&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pl&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;


&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Usage: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt; OUTPUT&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],))&lt;/span&gt;
  &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;prob&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;quadratic1&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;admm&lt;/span&gt;        &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ADMM&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rho&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;iterates&lt;/span&gt;    &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;it&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;islice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;admm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;solve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prob&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;_&lt;/span&gt;   &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;xs&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;asarray&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;iterates&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;zs&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;asarray&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;iterates&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;xs2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;prob&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;primal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;State&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;zs2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;prob&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;primal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;State&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;zs&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;animate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;iteration:&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;
  &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cla&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
  &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Iteration #&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;prob&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;prob&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;k-&amp;#39;&lt;/span&gt; &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;f(x)+g(z)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;prob&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;             &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;g--&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;f(x)&amp;#39;&lt;/span&gt;     &lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;   &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;            &lt;span class="n"&gt;prob&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;b--&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;     &lt;span class="s1"&gt;&amp;#39;g(z)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;xs2&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;g&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;x&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;zs2&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;b&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;z&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;anim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;animation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FuncAnimation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gcf&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;animate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;frames&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iterates&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;anim&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;writer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;imagemagick&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fps&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="optimization"></category><category term="optimization"></category><category term="distributed"></category><category term="admm"></category></entry><entry><title>Frank-Wolfe Algorithm</title><link href="https://stronglyconvex.com/blog/frank-wolfe.html" rel="alternate"></link><published>2013-05-04T00:00:00-07:00</published><updated>2013-05-04T00:00:00-07:00</updated><author><name>Daniel Duckworth</name></author><id>tag:stronglyconvex.com,2013-05-04:/blog/frank-wolfe.html</id><summary type="html">&lt;p&gt;In this post, we'll take a look at the &lt;a href="http://en.wikipedia.org/wiki/Frank%E2%80%93Wolfe_algorithm"&gt;Frank-Wolfe Algorithm&lt;/a&gt;
also known as the Conditional Gradient Method, an algorithm particularly suited
for solving problems with compact domains. Like the &lt;a href="https://stronglyconvex.com/blog/proximal-gradient-descent.html"&gt;Proximal
Gradient&lt;/a&gt; and &lt;a href="https://stronglyconvex.com/blog/accelerated-proximal-gradient-descent.html"&gt;Accelerated Proximal
Gradient&lt;/a&gt; algorithms, Frank-Wolfe requires we
exploit problem structure to quickly solve a mini-optimization problem. Our …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this post, we'll take a look at the &lt;a href="http://en.wikipedia.org/wiki/Frank%E2%80%93Wolfe_algorithm"&gt;Frank-Wolfe Algorithm&lt;/a&gt;
also known as the Conditional Gradient Method, an algorithm particularly suited
for solving problems with compact domains. Like the &lt;a href="https://stronglyconvex.com/blog/proximal-gradient-descent.html"&gt;Proximal
Gradient&lt;/a&gt; and &lt;a href="https://stronglyconvex.com/blog/accelerated-proximal-gradient-descent.html"&gt;Accelerated Proximal
Gradient&lt;/a&gt; algorithms, Frank-Wolfe requires we
exploit problem structure to quickly solve a mini-optimization problem. Our
reward for doing so is a converge rate of &lt;span class="math"&gt;\(O(1/\epsilon)\)&lt;/span&gt; and the potential for
&lt;em&gt;extremely sparse solutions&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Returning to my &lt;a href="https://stronglyconvex.com/blog/gradient-descent.html"&gt;valley-finding metaphor&lt;/a&gt;, Frank-Wolfe is a
bit like this,&lt;/p&gt;
&lt;div class="pseudocode"&gt;
&lt;ol&gt;
&lt;li&gt;Look around you and see which way points the most downwards&lt;/li&gt;
&lt;li&gt;Walk as far as possible in that direction until you hit a wall&lt;/li&gt;
&lt;li&gt;Go back in the direction you started, stop part way along the path, then
     repeat.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;h1&gt;&lt;a name="implementation" href="#implementation"&gt;How does it work?&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Frank-Wolfe is designed to solve problems of the form,&lt;/p&gt;
&lt;div class="math"&gt;$$
  \min_{x \in D} f(x)
$$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(D\)&lt;/span&gt; is compact and &lt;span class="math"&gt;\(f\)&lt;/span&gt; is differentiable. For example, in &lt;span class="math"&gt;\(R^n\)&lt;/span&gt; any
closed and bounded set is compact. The algorithm for Frank-Wolfe is then,&lt;/p&gt;
&lt;div class="pseudocode"&gt;
&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt;: Initial iterate &lt;span class="math"&gt;\(x^{(0)}\)&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;For &lt;span class="math"&gt;\(t = 0, 1, 2, \ldots\)&lt;/span&gt;&lt;ol&gt;
&lt;li&gt;Let &lt;span class="math"&gt;\(s^{(t+1)} = \arg\min_{s \in D} \langle \nabla f(x^{(t)}), s \rangle\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;If &lt;span class="math"&gt;\(g(x) = \langle \nabla f(x^{(t)}), x - s^{(t+1)} \rangle \le \epsilon\)&lt;/span&gt;, break&lt;/li&gt;
&lt;li&gt;Let &lt;span class="math"&gt;\(x^{(t+1)} = (1 - \alpha^{(t)}) x^{(t)} + \alpha^{(t)} s^{(t+1)}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;p&gt;The proof relies on &lt;span class="math"&gt;\(\alpha^{(t)} = 2 / (t+2)\)&lt;/span&gt;, but line search works as
well.  The intuition for the algorithm is that at each iteration, we minimize
a linear approximation to &lt;span class="math"&gt;\(f\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
  s^{(t+1)} = \arg\min_{s \in D} f(x^{(t)}) + \nabla f(x^{(t)})^T (s - x^{(t)})
$$&lt;/div&gt;
&lt;p&gt;then take a step in that direction. We can immediately see that if &lt;span class="math"&gt;\(D\)&lt;/span&gt;
weren't compact, &lt;span class="math"&gt;\(s^{(t)}\)&lt;/span&gt; would go off to infinity.&lt;/p&gt;
&lt;p&gt;&lt;a id="upper_bound"&gt;&lt;/a&gt;
  &lt;strong&gt;Upper Bound&lt;/strong&gt; One nice property of Frank-Wolfe is that it comes with its
own upper bound on &lt;span class="math"&gt;\(f(x^{(t)}) - f(x^{*})\)&lt;/span&gt; calculated during the course of
the algorithm. Recall the linear upper bound on &lt;span class="math"&gt;\(f\)&lt;/span&gt; due to convexity,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  f(x^{*})
  &amp;amp; \ge f(x) + \nabla f(x)^T (x^{*} - x) \\
  f(x) - f(x^{*})
  &amp;amp; \le \nabla f(x)^T (x - x^{*}) \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Since,&lt;/p&gt;
&lt;div class="math"&gt;$$
  s^{(t+1)}
  = \arg\min_{s} \nabla f(x^{(t)})^T s
  = \arg\max_{s} \nabla f(x^{(t)})^T (x^{(t)} - s)
$$&lt;/div&gt;
&lt;p&gt;
  we know that &lt;span class="math"&gt;\(\nabla f(x^{(t)})^T (x^{(t)} - x^{*}) \le \nabla f(x^{(t)})^T
(x^{(t)} - s^{(t+1)})\)&lt;/span&gt; and thus,&lt;/p&gt;
&lt;div class="math"&gt;$$
  f(x) - f(x^{*}) \le \nabla f(x^{(t)})^T (x^{(t)} - s^{(t+1)})
$$&lt;/div&gt;
&lt;p&gt;&lt;a id="example"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a name="example" href="#example"&gt;A Small Example&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;For this example, we'll minimize a simple univariate quadratic function
constrained to lie in an interval,&lt;/p&gt;
&lt;div class="math"&gt;$$
  \min_{x \in [-1,2]} (x-0.5)^2 + 2x
$$&lt;/div&gt;
&lt;p&gt;Its derivative is given by &lt;span class="math"&gt;\(2(x-0.5) + 2\)&lt;/span&gt;, and since we are dealing with real
numbers, the minimizers of the linear approximation must be either &lt;span class="math"&gt;\(-1\)&lt;/span&gt; or
&lt;span class="math"&gt;\(2\)&lt;/span&gt; if the gradient is positive or negative, respectively. We'll use a stepsize
of &lt;span class="math"&gt;\(\alpha^{(t)} = 2 / (t+2)\)&lt;/span&gt; as prescribed by the convergence proof in the
next section.&lt;/p&gt;
&lt;div class="img-center"&gt;
  &lt;img src="/assets/img/frank_wolfe/animation.gif"&gt;&lt;/img&gt;
  &lt;span class="caption"&gt;
    Frank-Wolfe in action. The red circle is the current value for
    $f(x^{(t)})$, and the green diamond is $f(x^{(t+1)})$. The dotted line is
    the linear approximation to $f$ at $x^{(t)}$. Notice that at each step,
    Frank-Wolfe stays closer and closer to $x^{(t)}$ when moving in the
    direction of $s^{(t+1)}$.
  &lt;/span&gt;
&lt;/div&gt;

&lt;div class="img-center"&gt;
  &lt;img src="/assets/img/frank_wolfe/convergence.png"&gt;&lt;/img&gt;
  &lt;span class="caption"&gt;
    This plot shows how quickly the objective function decreases as the
    number of iterations increases. Notice that it does not monotonically
    decrease, as with Gradient Descent.
  &lt;/span&gt;
&lt;/div&gt;

&lt;div class="img-center"&gt;
  &lt;img src="/assets/img/frank_wolfe/iterates.png"&gt;&lt;/img&gt;
  &lt;span class="caption"&gt;
    This plot shows the actual iterates and the objective function evaluated at
    those points. More red indicates a higher iteration number. Since
    Frank-Wolfe uses linear combinations of $s^{(t+1)}$ and $x^{(t)}$, it
    tends to "bounce around" a lot, especially in earlier iterations.
  &lt;/span&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a id="proof"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a name="proof" href="#proof"&gt;Why does it work?&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;We begin by making the two assumptions given earlier,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;span class="math"&gt;\(f\)&lt;/span&gt; is convex, differentiable, and finite for all &lt;span class="math"&gt;\(x \in D\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(D\)&lt;/span&gt; is compact&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Assumptions&lt;/strong&gt; First, notice that we never needed to assume that a solution
&lt;span class="math"&gt;\(x^{*}\)&lt;/span&gt; exists. This is because &lt;span class="math"&gt;\(D\)&lt;/span&gt; is compact and &lt;span class="math"&gt;\(f\)&lt;/span&gt; is finite, meaning &lt;span class="math"&gt;\(x\)&lt;/span&gt;
cannot get bigger and bigger to make &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; arbitrarily small.&lt;/p&gt;
&lt;p&gt;Secondly, we never made a Lipschitz assumption on &lt;span class="math"&gt;\(f\)&lt;/span&gt; or its gradient. Since
&lt;span class="math"&gt;\(D\)&lt;/span&gt; is compact, we don't have to -- instead, we get the following for free.
Define &lt;span class="math"&gt;\(C_f\)&lt;/span&gt; as,&lt;/p&gt;
&lt;div class="math"&gt;$$
  C_f = \max_{\substack{
                x,s \in D \\
                \alpha \in [0,1] \\
                y = x + \alpha (s-x)
              }}
          \frac{2}{\alpha^2} \left(
            f(y) - f(x) - \langle \nabla f(x), y - x \rangle
          \right)
$$&lt;/div&gt;
&lt;p&gt;This immediate implies the following upper bound on &lt;span class="math"&gt;\(f\)&lt;/span&gt; for all &lt;span class="math"&gt;\(x, y \in
D\)&lt;/span&gt; and &lt;span class="math"&gt;\(\alpha \in [0,1]\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
  f(y) \le f(x) + \langle \nabla f(x), y-x \rangle + \frac{\alpha^2}{2} C_f
$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Proof Outline&lt;/strong&gt; The proof for Frank-Wolfe is surprisingly simple. The idea
is to first upper bound &lt;span class="math"&gt;\(f(x^{(t+1)})\)&lt;/span&gt; in terms of &lt;span class="math"&gt;\(f(x^{(t)})\)&lt;/span&gt;, &lt;span class="math"&gt;\(g(x^{(t)})\)&lt;/span&gt;,
and &lt;span class="math"&gt;\(C_f\)&lt;/span&gt;. We then transform this per-iteration bound into a bound on
&lt;span class="math"&gt;\(f(x^{(t)}) - f(x^{*})\)&lt;/span&gt; depending on &lt;span class="math"&gt;\(t\)&lt;/span&gt; using induction. That's it!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1&lt;/strong&gt; Upper bound &lt;span class="math"&gt;\(f(x^{(t+1)})\)&lt;/span&gt;. As usual, we'll denote &lt;span class="math"&gt;\(x^{+} \triangleq
x^{(t+1)}\)&lt;/span&gt;, &lt;span class="math"&gt;\(x \triangleq x^{(t)}\)&lt;/span&gt;, &lt;span class="math"&gt;\(s^{+} \triangleq s^{(t+1)}\)&lt;/span&gt;, and &lt;span class="math"&gt;\(\alpha
\triangleq \alpha^{(t)}\)&lt;/span&gt;. We begin by using the upper bound we just obtained for
&lt;span class="math"&gt;\(f\)&lt;/span&gt; in terms of &lt;span class="math"&gt;\(C_f\)&lt;/span&gt;, substituting &lt;span class="math"&gt;\(x^{+} = (1 - \alpha) x + \alpha s^{+}\)&lt;/span&gt; and
then &lt;span class="math"&gt;\(g(x) = \nabla f(x)^T (x - s^{+})\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  f(x^{+}) 
  &amp;amp; \le f(x) + \nabla f(x)^T (x^{+} - x) + \frac{\alpha^2}{2} C_f \\
  &amp;amp; = f(x) + \nabla f(x)^T ( (1-\alpha) x + \alpha s^{+} - x ) + \frac{\alpha^2}{2} C_f \\
  &amp;amp; = f(x) + \nabla f(x)^T ( \alpha s^{+} - \alpha x ) + \frac{\alpha^2}{2} C_f \\
  &amp;amp; = f(x) - \alpha \nabla f(x)^T ( x - s^{+} ) + \frac{\alpha^2}{2} C_f \\
  &amp;amp; = f(x) - \alpha g(x) + \frac{\alpha^2}{2} C_f \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Step 2&lt;/strong&gt; Use induction on &lt;span class="math"&gt;\(t\)&lt;/span&gt;. First, recall the upper bound on &lt;span class="math"&gt;\(f(x) -
f(x^{*}) \le g(x)\)&lt;/span&gt; &lt;a href="#upper_bound"&gt;we derived above&lt;/a&gt;. Let's add &lt;span class="math"&gt;\(-f(x^{*})\)&lt;/span&gt; into
what we got from Step 1, then use the upper bound on &lt;span class="math"&gt;\(f(x) - f(x^{*})\)&lt;/span&gt; to get,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  f(x^{+}) - f(x^{*})
  &amp;amp; \le f(x) - f(x^{*}) - \alpha g(x) + \frac{\alpha^2}{2} C_f \\
  &amp;amp; \le f(x) - f(x^{*}) - \alpha ( f(x) - f(x^{*}) ) + \frac{\alpha^2}{2} C_f \\
  &amp;amp; = (1 - \alpha) (f(x) - f(x^{*})) + \frac{\alpha^2}{2} C_f \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Now, we employ induction on &lt;span class="math"&gt;\(t\)&lt;/span&gt; to show that,&lt;/p&gt;
&lt;div class="math"&gt;$$
  f(x^{(t)}) - f(x^{*}) \le \frac{4 C_f / 2}{t+2}
$$&lt;/div&gt;
&lt;p&gt;We'll assume that the step size is &lt;span class="math"&gt;\(\alpha^{(t)} = \frac{2}{t+2}\)&lt;/span&gt;, giving us
&lt;span class="math"&gt;\(\alpha^{(0)} = 2 / (0+2) = 1\)&lt;/span&gt; and the base case,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  f(x^{(1)} - f(x^{*})
  &amp;amp; \le (1 - \alpha^{(0)}) ( f(x^{(0)}) - f(x^{*}) ) + \frac{\alpha^2}{2} C_f \\
  &amp;amp; = (1 - 1) ( f(x^{(0)}) - f(x^{*}) ) + \frac{1}{2} C_f \\
  &amp;amp; \le \frac{4 C_f / 2}{(0 + 1) + 2}
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Next, for the recursive case, we use the inductive assumption on &lt;span class="math"&gt;\(f(x) - f(x^{*})\)&lt;/span&gt;, the definition of &lt;span class="math"&gt;\(\alpha^{(t)}\)&lt;/span&gt;, and some algebra,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  f(x^{+}) - f(x^{*})
  &amp;amp; \le (1 - \alpha) ( f(x) - f(x^{*}) ) + \frac{ \alpha^2}{2} C_f \\
  &amp;amp; \le \left(1 - \frac{2}{t+2} \right) \frac{4 C_f / 2}{t + 2} + \left( \frac{2}{t+2} \right)^2 C_f / 2 \\
  &amp;amp; \le \frac{4 C_f / 2}{t + 2} \left( 1 - \frac{2}{t+2} + \frac{1}{t+2} \right) \\
  &amp;amp; = \frac{4 C_f / 2}{t + 2} \left( \frac{t+1}{t+2} \right) \\
  &amp;amp; \le \frac{4 C_f / 2}{t + 2} \left( \frac{t+2}{t+3} \right) \\
  &amp;amp; = \frac{4 C_f / 2}{(t + 1) + 2} \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Thus, if we want an error tolerance of &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt;, we need
&lt;span class="math"&gt;\(O(\frac{1}{\epsilon})\)&lt;/span&gt; iterations to find it. This matches the convergence
rate of Gradient Descent an Proximal Gradient Descent, but falls short of their
accelerated brethren.&lt;/p&gt;
&lt;h1&gt;&lt;a name="usage" href="#usage"&gt;When should I use it?&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Like Proximal Gradient, efficient use of Frank-Wolfe requires solving a
mini-optimization problem at each iteration. Unlike Proximal Gradient, however,
this mini-problem will lead to unbounded iterates if the input space is not
compact -- in other words, Frank-Wolfe cannot directly be applied when your
domain is all of &lt;span class="math"&gt;\(R^{n}\)&lt;/span&gt;. However, there is a very special case wherein
Frank-Wolfe shines.&lt;/p&gt;
&lt;p&gt;&lt;a id="sparsity"&gt;&lt;/a&gt;
  &lt;strong&gt;Sparsity&lt;/strong&gt; The primary reason machine learning researchers have recently
taken an interest in Frank-Wolfe is because in certain problems the iterates
&lt;span class="math"&gt;\(x^{(t)}\)&lt;/span&gt; will be extremely sparse.  Suppose that &lt;span class="math"&gt;\(D\)&lt;/span&gt; is a polyhedron defined
by a set of linear constraints. Then &lt;span class="math"&gt;\(s^{(t)}\)&lt;/span&gt; is a solution to a Linear
Program, meaning that each &lt;span class="math"&gt;\(s^{(t)}\)&lt;/span&gt; lies on one of the vertices of the
polyhedron. If these vertices have only a few non-zero entries, then &lt;span class="math"&gt;\(x^{(t)}\)&lt;/span&gt;
will too, as &lt;span class="math"&gt;\(x^{(t)}\)&lt;/span&gt; is a linear combination of &lt;span class="math"&gt;\(s^{(1)} \ldots s^{(t)}\)&lt;/span&gt;.
This is in direct contrast to gradient and proximal based methods, wherein
&lt;span class="math"&gt;\(x^{(t)}\)&lt;/span&gt; is the linear combination of a set of non-sparse &lt;em&gt;gradients&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Atomic Norms&lt;/strong&gt; One particular case where Frank-Wolfe shines is when
minimizing &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; subject to &lt;span class="math"&gt;\(||x|| \le c\)&lt;/span&gt; where &lt;span class="math"&gt;\(|| \cdot ||\)&lt;/span&gt; is an "atomic
norm". We say that &lt;span class="math"&gt;\(||\cdot||\)&lt;/span&gt; is an atomic norm if &lt;span class="math"&gt;\(||x||\)&lt;/span&gt; is the smallest &lt;span class="math"&gt;\(t\)&lt;/span&gt;
such that &lt;span class="math"&gt;\(x/t\)&lt;/span&gt; is in the convex hull of a finite set of points &lt;span class="math"&gt;\(\mathcal{A}\)&lt;/span&gt;,
that is,&lt;/p&gt;
&lt;div class="math"&gt;$$
  ||x|| = \inf \{ t : x \in t \, \text{Conv}(\mathcal{A}) \}
$$&lt;/div&gt;
&lt;p&gt;For example, &lt;span class="math"&gt;\(||x||_1\)&lt;/span&gt; is an atomic norm with &lt;span class="math"&gt;\(\mathcal{A}\)&lt;/span&gt; being the set of
all vectors with only one &lt;span class="math"&gt;\(+1\)&lt;/span&gt; or one &lt;span class="math"&gt;\(-1\)&lt;/span&gt; entry. In these cases, finding
&lt;span class="math"&gt;\(\arg\min_{||s|| \le c} \langle \nabla f(x), s \rangle\)&lt;/span&gt; is tantamount to
finding which element of &lt;span class="math"&gt;\(\mathcal{A}\)&lt;/span&gt; minimizes &lt;span class="math"&gt;\(\langle \nabla f(x), s
\rangle\)&lt;/span&gt; (since &lt;span class="math"&gt;\(\text{Conv}(\mathcal{A})\)&lt;/span&gt; defines a polyhedron). For a whole
lot more on Atomic Norms, see &lt;a href="http://pages.cs.wisc.edu/~brecht/papers/2010-crpw_inverse_problems.pdf"&gt;this tome&lt;/a&gt; by
Chandrasekaranm et al.&lt;/p&gt;
&lt;h1&gt;&lt;a name="extensions" href="#extensions"&gt;Extensions&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Step Size&lt;/strong&gt; The proof above relied on a step size of &lt;span class="math"&gt;\(\alpha^{(t)} =
\frac{2}{t+2}\)&lt;/span&gt;, but as usual &lt;a href="/blog/gradient-descent.html#line_search"&gt;Line Search&lt;/a&gt; can be applied to
accelerate convergence.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Approximate Linear Solutions&lt;/strong&gt; Though not stated in the proof above,
another cool point about Frank-Wolfe is that you don't actually need to solve
the linear mini-problem exactly, but you will still converge to the optimal
solution (albet at a slightly slower rate). In particular, assume that each
mini-problem can be solved approximately with additive error &lt;span class="math"&gt;\(\frac{\delta
C_f}{t+2}\)&lt;/span&gt; at iteration &lt;span class="math"&gt;\(t\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
  \langle s^{(t+1)}, \nabla f(x^{(t)}) \rangle
  \le \min_{s} \langle s, \nabla f(x^{(t)}) \rangle + \frac{\delta C_f}{t+2}
$$&lt;/div&gt;
&lt;p&gt;then Frank-Wolfe's rate of convergence is&lt;/p&gt;
&lt;div class="math"&gt;$$
  f(x^{(t)}) - f(x^{*}) \le \frac{2 C_f}{t+2} (1 + \delta)
$$&lt;/div&gt;
&lt;p&gt;The proof for this can be found in the supplement to &lt;a href="http://jmlr.csail.mit.edu/proceedings/papers/v28/jaggi13-supp.pdf"&gt;Jaggi's&lt;/a&gt;
excellent survey on Frank-Wolfe for machine learning.&lt;/p&gt;
&lt;h1&gt;&lt;a name="invariance" href="#invariance"&gt;Linear Invariance&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Another cool fact about Frank-Wolfe is that it's &lt;em&gt;linearly invariant&lt;/em&gt; -- that
is, if you rotate and scale the space, nothing changes about the convergence
rate. This is in direct contrast to many other methods which depend on the
&lt;a href="http://en.wikipedia.org/wiki/Condition_number"&gt;condition number&lt;/a&gt; of a function (for functions with
Hessians, this is the ratio between the largest and smallest eigenvalues,
&lt;span class="math"&gt;\(\sigma_{\max} / \sigma_{\min})\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Suppose we transform our input space with a surjective (that is, onto) linear
transformation &lt;span class="math"&gt;\(M: \hat{D} \rightarrow D\)&lt;/span&gt;. Let's now try to solve the problem,&lt;/p&gt;
&lt;div class="math"&gt;$$
  \min_{\hat{x} \in \hat{D}} \hat{f}(\hat{x}) = f(M \hat{x}) = f(x)
$$&lt;/div&gt;
&lt;p&gt;Let's look at the solution to the per-iteration mini-problem we need to solve
for Frank-Wolfe,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \min_{\hat{s} \in \hat{D}} \langle \nabla \hat{f}(\hat{x}), \hat{s} \rangle
  = \min_{\hat{s} \in \hat{D}} \langle M^T \nabla f( M \hat{x}), \hat{s} \rangle
  = \min_{\hat{s} \in \hat{D}} \langle \nabla f( x ), M \hat{s} \rangle
  = \min_{s \in D} \langle \nabla f( x ), s \rangle
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;In other words, we will find the same &lt;span class="math"&gt;\(s\)&lt;/span&gt; if we solve in the original space,
or if we find &lt;span class="math"&gt;\(\hat{s}\)&lt;/span&gt; and then map it back to &lt;span class="math"&gt;\(s\)&lt;/span&gt;. No matter how &lt;span class="math"&gt;\(M\)&lt;/span&gt; warps
the space, Frank-Wolfe will do the same thing. This also means that if there's
a linear transformation you can do to make the points of your polyhedron
sparse, you can do it with no penalty!&lt;/p&gt;
&lt;h1&gt;&lt;a name="references" href="#references"&gt;References&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Proof of Convergence, Linear Invariance&lt;/strong&gt; Pretty much everything in this
article comes from &lt;a href="http://jmlr.csail.mit.edu/proceedings/papers/v28/jaggi13-supp.pdf"&gt;Jaggi's&lt;/a&gt; fantastic article on Frank-Wolfe for
machine learning.&lt;/p&gt;
&lt;h1&gt;&lt;a name="reference-impl" href="#reference-impl"&gt;Reference Implementation&lt;/a&gt;&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;frank_wolfe&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;minisolver&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Frank-Wolfe Algorithm&lt;/span&gt;

&lt;span class="sd"&gt;  Parameters&lt;/span&gt;
&lt;span class="sd"&gt;  ----------&lt;/span&gt;
&lt;span class="sd"&gt;  minisolver : function&lt;/span&gt;
&lt;span class="sd"&gt;      minisolver(x) = argmin_{s \in D} &amp;lt;x, s&amp;gt;&lt;/span&gt;
&lt;span class="sd"&gt;  gradient : function&lt;/span&gt;
&lt;span class="sd"&gt;      gradient(x) = gradient[f](x)&lt;/span&gt;
&lt;span class="sd"&gt;  alpha : function&lt;/span&gt;
&lt;span class="sd"&gt;      learning rate&lt;/span&gt;
&lt;span class="sd"&gt;  x0 : array&lt;/span&gt;
&lt;span class="sd"&gt;      initial value for x&lt;/span&gt;
&lt;span class="sd"&gt;  epsilon : float&lt;/span&gt;
&lt;span class="sd"&gt;      desired accuracy&lt;/span&gt;
&lt;span class="sd"&gt;  &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
  &lt;span class="n"&gt;xs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="n"&gt;iteration&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
  &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;s_next&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;minisolver&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;s_next&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="k"&gt;break&lt;/span&gt;
    &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;direction&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;s_next&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;x_next&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;s_next&lt;/span&gt;
    &lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_next&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;iteration&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;xs&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;default_learning_rate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mf"&gt;2.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iteration&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mf"&gt;2.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;

  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pylab&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pl&lt;/span&gt;
  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;yannopt.plotting&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plotting&lt;/span&gt;

  &lt;span class="c1"&gt;### FRANK WOLFE ALGORITHM ###&lt;/span&gt;

  &lt;span class="c1"&gt;# problem definition&lt;/span&gt;
  &lt;span class="n"&gt;function&lt;/span&gt;    &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;
  &lt;span class="n"&gt;gradient&lt;/span&gt;    &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
  &lt;span class="n"&gt;minisolver&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="c1"&gt;# D = [-1, 2]&lt;/span&gt;
  &lt;span class="n"&gt;x0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;

  &lt;span class="c1"&gt;# run gradient descent&lt;/span&gt;
  &lt;span class="n"&gt;iterates&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;frank_wolfe&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;minisolver&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_learning_rate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="c1"&gt;### PLOTTING ###&lt;/span&gt;

  &lt;span class="n"&gt;plotting&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot_iterates_vs_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iterates&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                     &lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;figures/iterates.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_star&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;plotting&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot_iteration_vs_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iterates&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                      &lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;figures/convergence.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_star&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="c1"&gt;# make animation&lt;/span&gt;
  &lt;span class="n"&gt;iterates&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;asarray&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iterates&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;makedirs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;figures/animation&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;OSError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;pass&lt;/span&gt;

  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iterates&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;iterates&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;x_plus&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;iterates&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;s_plus&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;minisolver&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;
    &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gradient&lt;/span&gt;
    &lt;span class="n"&gt;f_hat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;xmin&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xmax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plotting&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;limits&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;ymin&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ymax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;

    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xmin&lt;/span&gt; &lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;xmax&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xmin&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xmax&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;xmin&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xmax&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;ymin&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ymax&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;x&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;f(x)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;xmin&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xmax&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;f_hat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xmin&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;f_hat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xmax&lt;/span&gt;&lt;span class="p"&gt;)],&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;--&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vlines&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;ymin&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ymax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;linestyle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;solid&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;marker&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;o&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_plus&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_plus&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;marker&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;D&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vlines&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_plus&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f_hat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_plus&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_plus&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;linestyle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;dotted&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s_plus&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f_hat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s_plus&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.35&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;marker&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;x&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;figures/animation/&lt;/span&gt;&lt;span class="si"&gt;%02d&lt;/span&gt;&lt;span class="s1"&gt;.png&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="optimization"></category><category term="optimization"></category><category term="first-order"></category><category term="sparsity"></category></entry><entry><title>Variational Inference</title><link href="https://stronglyconvex.com/blog/variational-inference.html" rel="alternate"></link><published>2013-04-28T00:00:00-07:00</published><updated>2013-04-28T00:00:00-07:00</updated><author><name>Daniel Duckworth</name></author><id>tag:stronglyconvex.com,2013-04-28:/blog/variational-inference.html</id><summary type="html">&lt;p&gt;&lt;a href="http://www.orchid.ac.uk/eprints/40/1/fox_vbtut.pdf"&gt;Variational Inference&lt;/a&gt; and Monte Carlo Sampling are
currently the two chief ways of doing approximate Bayesian inference. In the
Bayesian setting, we typically have some observed variables &lt;span class="math"&gt;\(x\)&lt;/span&gt; and
unobserved variables &lt;span class="math"&gt;\(z\)&lt;/span&gt;, and our goal is to calculate &lt;span class="math"&gt;\(P(z|x)\)&lt;/span&gt;. In all but
the simplest cases, calculating &lt;span class="math"&gt;\(P(z …&lt;/span&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="http://www.orchid.ac.uk/eprints/40/1/fox_vbtut.pdf"&gt;Variational Inference&lt;/a&gt; and Monte Carlo Sampling are
currently the two chief ways of doing approximate Bayesian inference. In the
Bayesian setting, we typically have some observed variables &lt;span class="math"&gt;\(x\)&lt;/span&gt; and
unobserved variables &lt;span class="math"&gt;\(z\)&lt;/span&gt;, and our goal is to calculate &lt;span class="math"&gt;\(P(z|x)\)&lt;/span&gt;. In all but
the simplest cases, calculating &lt;span class="math"&gt;\(P(z|x)\)&lt;/span&gt; for all values of &lt;span class="math"&gt;\(z\)&lt;/span&gt; in closed form
is impossible, so approximations must be made.&lt;/p&gt;
&lt;p&gt;Variational Inference's approximation is made by choosing a family of
distributions &lt;span class="math"&gt;\(q(z|\eta)\)&lt;/span&gt; parameterized by &lt;span class="math"&gt;\(\eta\)&lt;/span&gt; and choosing a setting for
&lt;span class="math"&gt;\(\eta\)&lt;/span&gt; that brings &lt;span class="math"&gt;\(q(z|\eta)\)&lt;/span&gt; "close" to &lt;span class="math"&gt;\(P(z|x)\)&lt;/span&gt;.  In particular,
Variational Inference is about finding,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  &amp;amp; \arg\min_{\eta} KL \left[ q(z|\eta) || P(z|x) \right] \\
  &amp;amp; = \arg\min_{\eta} \sum_{z} q(z|\eta) \log \frac{ q(z|\eta) }{ P(z|x) }
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Looking at this formulation, the first thing you should be thinking is, "We
don't even know how to calculate &lt;span class="math"&gt;\(P(z|x)\)&lt;/span&gt; much less take an expectation with
respect to it. How can I possibly solve this problem?" The key is to restrict
&lt;span class="math"&gt;\(q(z|\eta)\)&lt;/span&gt; to decompose into a product of independent distributions, 1 for
each hidden variable &lt;span class="math"&gt;\(z_i\)&lt;/span&gt;. In other words,&lt;/p&gt;
&lt;div class="math"&gt;$$
  q(z|\eta) = \prod_{i} q(z_i | \eta_i)
$$&lt;/div&gt;
&lt;p&gt;This is the "mean field approximation" and will allow us to optimize each
&lt;span class="math"&gt;\(\eta_i\)&lt;/span&gt; one at a time. The final key &lt;span class="math"&gt;\(P(z_i|z_{-i},x)\)&lt;/span&gt; must lie in the
exponential family, and that &lt;span class="math"&gt;\(q(z_i|\eta_i)\)&lt;/span&gt; be of the same form. For example,
if the former is a Dirichlet distribution, so should the latter. When this is
the case, we can solve the Coordinate Ascent update in closed form.&lt;/p&gt;
&lt;p&gt;When all 3 conditions are met -- the mean field approximation, the univariate
posteriors lie in the exponential family, and that the individual variational
distributions match -- we can apply Coordinate Ascent to minimize the
KL-divergence between the mean field distribution and the posterior.&lt;/p&gt;
&lt;h1&gt;&lt;a name="derivation" href="#derivation"&gt;Derivation of the Objective&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;The original intuition for Variational Inference stems from lower bounding
the marginal likelihood of the observed variables &lt;span class="math"&gt;\(P(x)\)&lt;/span&gt;, then maximizing that
lower bound. For many choices of &lt;span class="math"&gt;\(q(z|\eta)\)&lt;/span&gt; doing this will be computationally
infeasible, but we'll see that if we make the mean field approximation and
choose the right variational distributions, then we can efficiently do
Coordinate Ascent.&lt;/p&gt;
&lt;p&gt;First, let's derive a lower bound on the likelihood of the observed
variables,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \log P(x)
  &amp;amp; = \log \left(
    \sum_{z} P(x, z) \frac{ q(z | \eta) } { q(z | \eta) }
  \right) \\
  &amp;amp; = \log \left(
    P(x)  \sum_{z} q(z | \eta) \frac{ P(z | x) } { q(z | \eta) }
  \right) \\
  &amp;amp; = \log \left(
    \sum_{z} q(z | \eta) \frac{ P(z | x) } { q(z | \eta) }
  \right) + \log P(x) \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Since &lt;span class="math"&gt;\(\log\)&lt;/span&gt; is a concave function, we can apply Jensen's inequality to see
that &lt;span class="math"&gt;\(\log(p x + (1-p)y) \ge p \log(x) + (1-p) \log y\)&lt;/span&gt; for any &lt;span class="math"&gt;\(p \in [0,
1]\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \log P(x)
  &amp;amp; = \log \left(
    \sum_{z} q(z | \eta) \frac{ P(z | x) } { q(z | \eta) }
  \right) + \log P(x) \\
  &amp;amp; \ge \sum_{z} q(z | \eta) \log \left(
    \frac{ P(z | x) } { q(z | \eta) }
  \right) + \log P(x) \\
  &amp;amp; = - \sum_{z} q(z | \eta) \log \left(
    \frac{ q(z | \eta) } { P(z | x) }
  \right) + \log P(x) \\
  &amp;amp; = - \text{KL}[ q(z | \eta) || P(z | x) ] + \log P(x) \\
  &amp;amp; = - \text{KL}[ q(z | \eta) || P(z , x) ] \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;From this expression, we can see that minimizing the KL divergence over
&lt;span class="math"&gt;\(\eta\)&lt;/span&gt;, we're lower bounding the likelihood of the observed variables.
In addition, if &lt;span class="math"&gt;\(q(z|\eta)\)&lt;/span&gt; has the same form as &lt;span class="math"&gt;\(P(z|x)\)&lt;/span&gt;, then the best choice
for &lt;span class="math"&gt;\(\eta\)&lt;/span&gt; is one that lets &lt;span class="math"&gt;\(q(z|\eta) = P(z|x)\)&lt;/span&gt; for all &lt;span class="math"&gt;\(z\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;At this point, we still have an intractable problem. Even evaluating the KL
divergence requires taking an expectation over all settings for &lt;span class="math"&gt;\(z\)&lt;/span&gt; (an
exponential number in &lt;span class="math"&gt;\(z\)&lt;/span&gt;'s length!), so applying an iterative algorithm to
choose &lt;span class="math"&gt;\(\eta\)&lt;/span&gt; is right out. However, we'll soon see that by restricting the
form of &lt;span class="math"&gt;\(q(z|\eta)\)&lt;/span&gt;, we can potentially decompose the KL divergence into more
easily manageable bits.&lt;/p&gt;
&lt;h1&gt;&lt;a name="mean-field" href="#mean-field"&gt;The Mean Field Approximation&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;The key to avoiding the massive sum of the previous equation is to assume that
&lt;span class="math"&gt;\(q(z|\eta)\)&lt;/span&gt; decomposes into a product of independent distributions. This is
known as the "Mean Field Approximation". Mathematically, the approximation
means that,&lt;/p&gt;
&lt;div class="math"&gt;$$
  q(z|\eta) = \prod_{i} q(z_i | \eta_i)
$$&lt;/div&gt;
&lt;p&gt;Suppose we make this assumption and that we want to perform coordinate ascent
on a single index &lt;span class="math"&gt;\(\eta_k\)&lt;/span&gt;. By factoring &lt;span class="math"&gt;\(P(z|x) = \prod_{i=1}^{k} P(z_i |
z_{1:i-1}, x)\)&lt;/span&gt; and dropping all terms that are constant with respect to
&lt;span class="math"&gt;\(\eta_k\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  &amp;amp; \arg\max_{\eta_k} -KL \left[ q(z|\eta) || p(z|x) \right] + \underbrace{\log P(x)}_{\text{constant wrt $\eta_k$}} \\
  &amp;amp; = \arg\max_{\eta_k} \sum_{z} q(z|\eta) \log P(z|x) - \sum_{z} q(z|\eta) \log q(z|\eta) \\
  &amp;amp; = \arg\max_{\eta_k} \sum_{z} q(z|\eta) \log \left( \prod_{i} P(z_{i}|z_{1:i-1},x) \right)
    - \sum_{z} \left( \prod_{i} q(z_i|\eta_i) \right) \log \left( \prod_{i} q(z_i|\eta_i) \right) \\
  &amp;amp; = \arg\max_{\eta_k} \sum_{j} \sum_{z} q(z|\eta)\log P(z_{j}|z_{1:j-1},x)
    - \underbrace{ \sum_{j} \sum_{z_j} q(z_j|\eta_j) \log q(z_j|\eta_j) }_{\text{only $j=k$ not const wrt. $\eta_k$}} \\
  &amp;amp; = \arg\max_{\eta_k} \underbrace{ \sum_{j} \sum_{z_{1:j}} \left( \prod_{i \le j} q(z_i|\eta_i) \right) \log P(z_{j}|z_{1:j-1},x) }_{\text{only last $j$ contains $q(z_k|\eta_k)$}}
    - \sum_{z_k} q(z_k|\eta_k) \log q(z_k|\eta_k)  \\
  &amp;amp; = \arg\max_{\eta_k} \sum_{z} q(z_k|\eta_k) \underbrace{ \left( \prod_{i \ne k} q(z_i|\eta_i) \right) }_{\text{fixed wrt $\eta_k$}} \log P(z_k | z_{-k}, x)
    - \sum_{z_k} q(z_k|\eta_k) \log q(z_k|\eta_k)  \\
  &amp;amp; = \arg\max_{\eta_k} \mathbb{E}_{q(z|\eta)} \left[ \log P(z_k | z_{-k}, x) \right]
    - \mathbb{E}_{ q(z_k|\eta_k) } \left[ \log q(z_k|\eta_k) \right] \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;At this point, we'll make the assumption that &lt;span class="math"&gt;\(P(z_k|z_{-k},x)\)&lt;/span&gt; is an
exponential family distribution (&lt;span class="math"&gt;\(z_{-k}\)&lt;/span&gt; is all &lt;span class="math"&gt;\(z_i\)&lt;/span&gt; with &lt;span class="math"&gt;\(i \ne k\)&lt;/span&gt;), and
moreover that &lt;span class="math"&gt;\(q(z_k|\eta_k)\)&lt;/span&gt; and &lt;span class="math"&gt;\(P(z_k|z_{-k},x)\)&lt;/span&gt; lie in the same exponential
family.  Mathematically, this means that,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  q(z_k|\eta_k)
  &amp;amp;= h(z_k) \exp( \eta_i^T t(z_k) - A(\eta_k) \\
  P(z_k|z_{-k},x)
  &amp;amp;= h(z_k) \exp( g(z_{-k},x)^T t(z_k) - A(g(z_{-k},x)) \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Here &lt;span class="math"&gt;\(t(\cdot)\)&lt;/span&gt; are sufficient statistics, &lt;span class="math"&gt;\(A(\cdot)\)&lt;/span&gt; is the log of the
normalizing constant, &lt;span class="math"&gt;\(g(\cdot)\)&lt;/span&gt; is a function of all other variables that
determines the parameters for &lt;span class="math"&gt;\(P(z_k|z_{-k},x)\)&lt;/span&gt;, and &lt;span class="math"&gt;\(h(\cdot)\)&lt;/span&gt; is some
function that doesn't depend on the parameters of the distribution.&lt;/p&gt;
&lt;p&gt;Plugging this back into the previous equation (we define it to be
&lt;span class="math"&gt;\(L(\eta_k)\)&lt;/span&gt;), applying the &lt;span class="math"&gt;\(\log\)&lt;/span&gt;, and using the linearity property of the
expectation,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
&amp;amp; \arg\max_{\eta_k} &amp;amp;&amp;amp; L(\eta_k) \\
= &amp;amp; \arg\max_{\eta_k} &amp;amp;&amp;amp; \mathbb{E}_{q(z|\eta)} \left[ \log P(z_k | z_{-k}, x) \right]
    - \mathbb{E}_{ q(z_k|\eta_k) } \left[ \log q(z_k|\eta_k) \right] \\
= &amp;amp; \arg\max_{\eta_k} &amp;amp;&amp;amp;\mathbb{E}_{q(z|\eta)} \left[
    \log h(z_k) + g(z_{-k},x)^T t(z_k) - A(g(z_{-k},x)
  \right]
  - \mathbb{E}_{q(z_k|\eta_k)} \left[ \log q(z_k|\eta_k) \right]  \\
= &amp;amp; \arg\max_{\eta_k} &amp;amp;&amp;amp;\left(
    \underbrace{ \mathbb{E}_{q(z_k|\eta_k)} \left[ \log h(z_k) \right] }_{\text{cancels out}}
    + \underbrace{
      \mathbb{E}_{q(z_{-k}|\eta_{-k})} \left[ g(z_{-k},x) \right]^T \mathbb{E}_{q(z_{k}|\eta_{k})} \left[ t(z_k) \right]
    }_{\text{$\mathbb{E}$ splits b/c $q(z_{-k}|\eta_{-k})$ and $q(z_k|\eta_k)$ are indep.}}
    - \underbrace{ \mathbb{E}_{q(z_{-k}|\eta_{-k})} \left[ A(g(z_{-k},x) \right] }_{\text{const wrt $\eta_k$}}
  \right) \\
&amp;amp;&amp;amp;&amp;amp; - \left(
    \underbrace{ \mathbb{E}_{q(z_k|\eta_k)} \left[ \log h(z_k) \right] }_{\text{cancels out}}
    + \eta_k^T \mathbb{E}_{q(z_k|\eta_k)} \left[ t(z_k) \right]
    - A(\eta_k)
  \right) \\
= &amp;amp; \arg\max_{\eta_k} &amp;amp;&amp;amp; \mathbb{E}_{q(z_{-k}|\eta_{-k})} \left[ g(z_{-k},x) \right]^T \left( \nabla_{\eta_k} A(\eta_k) \right)
    + \eta_k^T \left( \nabla_{\eta_k} A(\eta_k) \right)
    - A(\eta_k) \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;On this last line, we use the property &lt;span class="math"&gt;\(\nabla A_{\eta_k} (\eta_k) =
\mathbb{E}_{q(z_k|\eta_k)} [ t(z_k) ]\)&lt;/span&gt;, a fact that holds for the exponential
family.  Finally, let's take the gradient of this expression and set it to
zero to solve for &lt;span class="math"&gt;\(\eta_k\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  0
  &amp;amp; = \nabla_{\eta_k} L(\eta_k) \\
  &amp;amp; = \left( \nabla_{\eta_k}^2 A(\eta_k) \right)
    \left(
      \mathbb{E}_{q(z_{-k}|\eta_{-k})} \left[ g(z_{-k},x) \right]
      - \eta_k
    \right) \\
  \eta_k
  &amp;amp; = \mathbb{E}_{q(z_{-k}|\eta_{-k})} \left[ g(z_{-k},x) \right] \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;So what is this expression? It says that in order to update &lt;span class="math"&gt;\(\eta_k\)&lt;/span&gt;, we need
to be able to evaluate the expected parameters for &lt;span class="math"&gt;\(P(z_k|z_{-k},x)\)&lt;/span&gt;
under our approximation to the posterior &lt;span class="math"&gt;\(q(z_{-k}|\eta_{-k})\)&lt;/span&gt;. How do we do
this? Let's take a look at an example to make this concrete.&lt;/p&gt;
&lt;h1&gt;&lt;a name="example" href="#example"&gt;Example&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;For this part, let's take a look at the model defined by Latent Dirichlet
Allocation (LDA),&lt;/p&gt;
&lt;div class="img-center" style="max-width: 200px;"&gt;
  &lt;img src="/assets/img/variational_inference/graphical_model.png"&gt;&lt;/img&gt;
&lt;/div&gt;

&lt;div class="pseudocode"&gt;
&lt;p&gt;&lt;strong&gt;Input:&lt;/strong&gt; document-topic prior &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt;, topic-word prior &lt;span class="math"&gt;\(\beta\)&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;For each topic &lt;span class="math"&gt;\(k = 1 \ldots K\)&lt;/span&gt;&lt;ol&gt;
&lt;li&gt;Sample topic-word parameters &lt;span class="math"&gt;\(\phi_{k} \sim \text{Dirichlet}(\beta)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;For each document &lt;span class="math"&gt;\(i = 1 \ldots M\)&lt;/span&gt;&lt;ol&gt;
&lt;li&gt;Sample document-topic parameters &lt;span class="math"&gt;\(\theta_i \sim \text{Dirichlet}(\alpha)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;For each token &lt;span class="math"&gt;\(j = 1 \ldots N\)&lt;/span&gt;&lt;ol&gt;
&lt;li&gt;Sample topic &lt;span class="math"&gt;\(z_{i,j} \sim \text{Categorical}(\theta_i)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Sample word &lt;span class="math"&gt;\(x_{i,j} \sim \text{Categorical}(\phi_{z_{i,j}})\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;p&gt;First, a short word on notation. In the following I'll occasionally drop
indices to denote all variables with the same prefix. For example, when I say
&lt;span class="math"&gt;\(\theta\)&lt;/span&gt;, I mean &lt;span class="math"&gt;\(\theta_{1:M}\)&lt;/span&gt;, and when I say &lt;span class="math"&gt;\(z_i\)&lt;/span&gt;, I mean &lt;span class="math"&gt;\(z_{i,1:N}\)&lt;/span&gt;.
I'll also refer to &lt;span class="math"&gt;\(q(\theta_i|\eta_i)\)&lt;/span&gt; as "the variational distribution
corresponding to &lt;span class="math"&gt;\(P(\theta_i|\alpha,\theta_{-i},z,x)\)&lt;/span&gt;", and similarly for
&lt;span class="math"&gt;\(q(z_{i,j}|\gamma_{i,j})\)&lt;/span&gt;. Oh, and &lt;span class="math"&gt;\(z_{-i}\)&lt;/span&gt; means all &lt;span class="math"&gt;\(z_j\)&lt;/span&gt; with &lt;span class="math"&gt;\(j \ne i\)&lt;/span&gt;, and
&lt;span class="math"&gt;\(\theta_{1:M}\)&lt;/span&gt; means &lt;span class="math"&gt;\((\theta_1, \ldots \theta_M)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Our goal now is to derive the posterior distribution over the latent
variables, given the hyperparameters and the observed variables,
&lt;span class="math"&gt;\(P(\theta, z, \phi| \alpha, x, \beta)\)&lt;/span&gt;. We'll approximate it via the mean field
distribution,&lt;/p&gt;
&lt;div class="math"&gt;$$
  q(\theta,z,\phi | \eta,\gamma,\psi) = \left(
    \prod_{i} q(\theta_i | \eta_i) \prod_{j} q(z_{i,j} | \gamma_{i,j})
  \right) \left(
    \prod_{k} q(\phi_k | \psi_k)
  \right)
$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Outline&lt;/strong&gt; Deriving the update rules for Variational Inference requires we
do 3 things. First, we must derive the posterior distribution for each hidden
variable given all other variables, hidden and observed. This distribution must
lie in the exponential family, and the corresponding variational distribution for
that variable must be of the same form. For example, if
&lt;span class="math"&gt;\(P(\theta_i|\alpha,\theta_{-i},z,x)\)&lt;/span&gt; is a Dirichlet distribution, then
&lt;span class="math"&gt;\(q(\theta_i|\eta_i)\)&lt;/span&gt; must also be Dirichlet.&lt;/p&gt;
&lt;p&gt;Second, we need to derive, for each hidden variable, the function that gives
us the parameters for the posterior distribution over that variable given all
others, hidden and observed.&lt;/p&gt;
&lt;p&gt;Finally, we'll need to plug the functions we just derived into an expectation
with respect to the mean field distribution. If we are able to calculate this
expectation for a particular hidden variable, we can use it to update the
matching variational distribution's parameters.&lt;/p&gt;
&lt;p&gt;In the following, I'll show you how to derive the update for the variational
distribution of one of the hidden variables in LDA, &lt;span class="math"&gt;\(\theta_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1&lt;/strong&gt; First, we must show that the posterior distribution over each
individual hidden variable lies in the exponential family. This is not always
the case, but for models that employ &lt;a href="http://lesswrong.com/lw/5sn/the_joys_of_conjugate_priors/"&gt;conjugate priors&lt;/a&gt;, this
can be guaranteed. A conjugate prior dictates that if &lt;span class="math"&gt;\(P(z)\)&lt;/span&gt; is a conjugate
prior to &lt;span class="math"&gt;\(P(x|z)\)&lt;/span&gt;, then &lt;span class="math"&gt;\(P(z|x)\)&lt;/span&gt; is in the same family as &lt;span class="math"&gt;\(P(z)\)&lt;/span&gt; is. This is
the case for Dirichlet/Categorical distributions such as those that appear in
LDA. In other words, &lt;span class="math"&gt;\(P(\theta_i|\alpha,\theta_{-i},z,x) =
P(\theta_i|\alpha,z_{i})\)&lt;/span&gt; (by conditional independence) is a Dirichlet
distribution because &lt;span class="math"&gt;\(P(\theta_i|\alpha)\)&lt;/span&gt; is Dirichlet and
&lt;span class="math"&gt;\(P(z_{i,j}|\theta_i)\)&lt;/span&gt; is Categorical.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 2&lt;/strong&gt; Next, we derive the parameter function for each hidden variable
as a function of all other variables, hidden and observed. Let's see how this
plays out for the Dirichlet distribution,&lt;/p&gt;
&lt;p&gt;The exponential family form of the Dirichlet distribution is,&lt;/p&gt;
&lt;div class="math"&gt;$$
  P(\theta_i|\alpha) = \exp \left(
    \sum_{k} (\alpha_k - 1) \log (\theta_i)_k
    - \log \left(
      \frac{ \prod_{k} \Gamma(\alpha_k) }{ \Gamma( \sum_k \alpha_k ) }
    \right)
  \right)
$$&lt;/div&gt;
&lt;p&gt;The exponential family form of a Categorical distribution is,&lt;/p&gt;
&lt;div class="math"&gt;$$
  P(z_{i,j}|\theta_i) = \exp \left(
    \sum_{k} 1[z_{i,j} = k] \log (\theta_i)_k
  \right)
$$&lt;/div&gt;
&lt;p&gt;Thus, the posterior distribution for &lt;span class="math"&gt;\(\theta_i\)&lt;/span&gt; is proportional to,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  P(\theta_i|\alpha,z_{i})
  &amp;amp; \propto P(\theta_i, z_i | \alpha) \\
  &amp;amp; = P(\theta_i|\alpha) \prod_{j} P(z_{i,j}|\theta_i) \\
  &amp;amp; = \exp \left(
    \sum_{k} \left(\alpha_k - 1 + \sum_{j} 1[z_{i,j} = k] \right) \log (\theta_i)_k
  \right)
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Notice how &lt;span class="math"&gt;\(\alpha_k - 1\)&lt;/span&gt; changed to &lt;span class="math"&gt;\(\alpha_k - 1 + \sum_{j} 1[z_{i,j} = k]\)&lt;/span&gt;?
These are the parameters for our posterior distribution over &lt;span class="math"&gt;\(\theta_i\)&lt;/span&gt;. Thus,
the parameters for &lt;span class="math"&gt;\(P(\theta_i|\alpha,z_i)\)&lt;/span&gt; are,&lt;/p&gt;
&lt;div class="math"&gt;$$
  g_{\theta_i}(\alpha,z_{i}) = \begin{pmatrix}
    \alpha_1 - 1 + \sum_{j} 1[z_{i,j} = 1] \\
    \alpha_2 - 1 + \sum_{j} 1[z_{i,j} = 2] \\
    \vdots \\
  \end{pmatrix}
$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Step 3&lt;/strong&gt; Now we need to take the expectation over the parameter
function we just derived with respect to the mean field distribution. For
&lt;span class="math"&gt;\(g_{\theta_i}(\alpha, z_i)\)&lt;/span&gt;, this is particularly easy -- all the indicators
simply turn into probabilities. Thus the update for &lt;span class="math"&gt;\(q(\theta_i|\eta_i)\)&lt;/span&gt; is,&lt;/p&gt;
&lt;div class="math"&gt;$$
  \eta_i
  = E_{q(z_{i}|\gamma_i)} [ g_{\theta_i}(\alpha, z_i) ]
  = \begin{pmatrix}
    \alpha_1 - 1 + \sum_{j} q(z_{i,j} = 1 | \gamma_{i,j}) \\
    \alpha_2 - 1 + \sum_{j} q(z_{i,j} = 2 | \gamma_{i,j}) \\
    \vdots \\
  \end{pmatrix}
$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt; We've now derived the update rule for one of the components of
the mean field distribution, &lt;span class="math"&gt;\(q(\theta_i|\eta_i)\)&lt;/span&gt;. Left unexplained here is the
updates for &lt;span class="math"&gt;\(q(z_{i,j}|\gamma_{i,j})\)&lt;/span&gt; and &lt;span class="math"&gt;\(q(\phi_k|\psi_k)\)&lt;/span&gt;, though you can
find a (messier) derivation in the original paper on &lt;a href="http://www.cs.princeton.edu/~blei/papers/BleiNgJordan2003.pdf"&gt;Latent Dirichlet
Allocation&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a name="aside" href="#aside"&gt;Aside: Coordinate Ascent is Gradient Ascent&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Coordinate Ascent on the Mean Field Approximation is the "traditional" way
one does Variational Inference, but Coordinate Ascent is far from the only
optimization method we know. What if we wanted to do Gradient Ascent? What
would an update look like then?&lt;/p&gt;
&lt;p&gt;It ends up that for the Variational Inference objective, Coordinate Ascent
&lt;em&gt;is&lt;/em&gt; Gradient Ascent with step size equal to 1. Actually, that's only half true
-- it's Gradient Ascent using a "Natural Gradient" (rather than the usual
gradient defined with respect to &lt;span class="math"&gt;\(||\cdot||_2^2\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Gradient Ascent&lt;/strong&gt; First, recall the Gradient Ascent update for &lt;span class="math"&gt;\(\eta_k\)&lt;/span&gt; (we
use the definition of &lt;span class="math"&gt;\(\nabla_{\eta_k} L(\eta_k)\)&lt;/span&gt; we found when deriving the
Coordinate Ascent update).&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \eta_k^{(t+1)}
  &amp;amp; = \eta_k^{(t)} + \alpha^{(t)} \nabla_{\eta_k} L(\eta_k^{(t)}) \\
  &amp;amp; = \eta_k^{(t)} + \alpha^{(t)} \left[
      \left( \nabla_{\eta_k}^2 A(\eta_k^{(t)}) \right)
      \left(
        \mathbb{E}_{q(z_{-k}|\eta_{-k})} \left[ g(z_{-k},x) \right]
        - \eta_k^{(t)}
      \right)
    \right] \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Natural Gradient&lt;/strong&gt; Hmm, that &lt;span class="math"&gt;\(\nabla_{\eta_k}^2 A(\eta_k^{(t)})\)&lt;/span&gt; term is a
bit of a nuisance. Is there any way to make it just go away? In fact, we can --
by replacing the concept of a gradient with a "natural gradient". Whereas a
regular gradient is the direction of steepest ascent with respect to Euclidean
distance, a natural gradient is a direction of steepest ascent with respect to
a function (in particular, one we want to minimize). The intuition is that for
a given function, some input coordinates might be more important than others,
and this should be taken into account when considering how far away 2 points
are.&lt;/p&gt;
&lt;p&gt;So what do I mean "a direction of steepest ascent"?  Let's look at the
gradient of a function as the solution to the following problem as &lt;span class="math"&gt;\(\epsilon
\rightarrow 0\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \nabla_{\eta_k} L(\eta_k)
  = &amp;amp; \arg\min_{d \eta_k} L(\eta_k + d \eta_k) \\
    &amp;amp; \text{s.t.} \quad   ||d \eta_k||_2^2 &amp;lt; \epsilon
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;A natural gradient with respect to &lt;span class="math"&gt;\(L(\eta_k)\)&lt;/span&gt; is defined much the same way,
but with &lt;span class="math"&gt;\(D_{E}(x,y) = || x-y ||_2^2\)&lt;/span&gt; replaced with another squared metric.
In our case, we're going to use the symmetrized KL divergence,&lt;/p&gt;
&lt;div class="math"&gt;$$
  D_{KL}(\eta_k, \eta_k') = \text{KL} \left[ q(z_k|\eta_k) || q(z_k|\eta_k') \right]
                          + \text{KL} \left[ q(z_k|\eta_k') || q(z_k|\eta_k) \right]
$$&lt;/div&gt;
&lt;p&gt;Swapping the squared Euclidean metric &lt;span class="math"&gt;\(D_{E}\)&lt;/span&gt; with &lt;span class="math"&gt;\(D_{KL}\)&lt;/span&gt;, we have a
definition for a "Natural Gradient",&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \hat{\nabla}_{\eta_k} L(\eta_k)
  = &amp;amp; \arg\min_{d \eta_k}   L(\eta_k + d \eta_k) \\
    &amp;amp; \text{s.t.} \quad D_{KL}(\eta_k, \eta_k + d \eta_k) &amp;lt; \epsilon
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;While at first the gradient and natural gradient may seem difficult to
relate, suppose that &lt;span class="math"&gt;\(D_{KL}(\eta_k, \eta_k + d \eta_k) = d \eta_k^T
G(\eta_k) d \eta_k\)&lt;/span&gt; for some matrix &lt;span class="math"&gt;\(G(\eta_k)\)&lt;/span&gt;. Then by plugging this into the
previous optimization problem, replacing &lt;span class="math"&gt;\(L(\eta_k + d \eta_k)\)&lt;/span&gt; by its first
order Taylor approximation (which holds when &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; is small), and
requiring the derivative of the problem's Lagrangian be equal to 0, we see
that,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  0
  &amp;amp; = \nabla_{d \eta_k} \left[
      L(\eta_k + d \eta_k) + \lambda ( d \eta_k G(\eta_k) d \eta_k - \epsilon)
    \right] \\
  &amp;amp; \approx \nabla_{d \eta_k} \left[
      L(\eta_k) + \nabla_{\eta_k} L(\eta_k)^T (\eta_k + d \eta_k - \eta_k) + \lambda ( d \eta_k G(\eta_k) d \eta_k - \epsilon)
    \right] \\
  &amp;amp; = \nabla_{\eta_k} L(\eta_k) + 2 \lambda G(\eta_k) d \eta_k \\
  d \eta_k
  &amp;amp; \propto G(\eta_k)^{-1} \nabla_{\eta_k} L(\eta_k)
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;As &lt;span class="math"&gt;\(\epsilon \rightarrow 0\)&lt;/span&gt;, &lt;span class="math"&gt;\(d \eta_k\)&lt;/span&gt; becomes &lt;span class="math"&gt;\(\hat{\nabla}_{\eta_k}
L(\eta_k)\)&lt;/span&gt;, resulting in &lt;span class="math"&gt;\(\hat{\nabla}_{\eta_k} L(\eta_k) \propto
G(\eta_k)^{-1} \nabla_{\eta_k} L(\eta_k)\)&lt;/span&gt;. In other words, we can obtain
&lt;span class="math"&gt;\(\hat{\nabla}_{\eta_k} L(\eta_k)\)&lt;/span&gt; easily if we can simply compute &lt;span class="math"&gt;\(G(\eta_k)\)&lt;/span&gt;.
Now let's derive &lt;span class="math"&gt;\(G(\eta_k)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;First, let's take the first-order Taylor approximation to &lt;span class="math"&gt;\(q(z|\eta_k + d
\eta_k)\)&lt;/span&gt; and its &lt;span class="math"&gt;\(\log\)&lt;/span&gt; about &lt;span class="math"&gt;\(\eta_k\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  q(z_k|\eta_k + d \eta_k)
  &amp;amp; \approx q(z_k|\eta_k) + (\nabla q(z_k|\eta_k))^T (\eta_k + d \eta_k - \eta_k) \\
  &amp;amp; = q(z_k|\eta_k) + q(z_k|\eta_k) (\nabla \log q(z_k|\eta_k))^T d \eta_k \\
  \log q(z_k|\eta_k + d \eta_k)
  &amp;amp; \approx \log q(z_k|\eta_k) + (\nabla \log q(z_k|\eta_k))^T (\eta_k + d \eta_k - \eta_k) \\
  &amp;amp; = \log q(z_k|\eta_k) + (\nabla \log q(z_k|\eta_k))^T d \eta_k \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Plugging this back into the definition of &lt;span class="math"&gt;\(D_{KL}\)&lt;/span&gt; and cancelling out terms, we
get a nice expression for &lt;span class="math"&gt;\(G(\eta_k)\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  D_{KL}(\eta, \eta')
  &amp;amp; = \text{KL} \left[ q(z_k|\eta_k) || q(z_k|\eta_k + d\eta_k) \right] + \text{KL} \left[ q(z_k|\eta_k + d\eta_k) || q(z_k|\eta_k) \right] \\
  &amp;amp; = \sum_{z} q(z|\eta_k) \log \frac{ q(z|\eta_k) }{ q(z|\eta_k+d\eta_k) }
      + \sum_{z} q(z|\eta_k+d\eta_k) \log \frac{ q(z|\eta_k+d\eta_k) }{ q(z|\eta_k) } \\
  &amp;amp; = \sum_{z} \left[ q(z|\eta_k) - q(z|\eta_k+d\eta_k) \right]
               \left[ \log q(z|\eta_k) - \log q(z|\eta_k+d\eta_k) \right] \\
  &amp;amp; \approx \sum_{z}
      \left[ q(z|\eta_k) - q(z_k|\eta_k) - q(z_k|\eta_k)(\nabla \log q(z_k|\eta_k))^T d \eta_k \right] \\
      &amp;amp; \qquad \quad \times \left[ \log q(z|\eta_k) - \log q(z_k|\eta_k) - (\nabla \log q(z_k|\eta_k))^T d \eta_k \right] \\
  &amp;amp; = \sum_{z}
      \left[ - q(z_k|\eta_k) (\nabla \log q(z_k|\eta_k))^T d \eta_k \right]
      \left[ - (\nabla \log q(z_k|\eta_k))^T d \eta_k \right] \\
  &amp;amp; = d \eta_k^T \mathbb{E}_{q(z|\eta_k)} \left[ (\nabla \log q(z_k|\eta_k)) (\nabla \log q(z_k|\eta_k))^T \right] d \eta_k \\
  &amp;amp; = d \eta_k^T G(\eta_k) d \eta_k \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Looking at the expression for &lt;span class="math"&gt;\(G(\eta_k)\)&lt;/span&gt;, we can see that it is in fact the
&lt;a href="http://en.wikipedia.org/wiki/Fisher_information"&gt;Fisher Information Matrix&lt;/a&gt;. Since we already assumed that
&lt;span class="math"&gt;\(q(z_k|\eta_k)\)&lt;/span&gt; is in the exponential family, let's plug in its exponential
form &lt;span class="math"&gt;\(q(z_k|\eta_k) = h(z_k) \exp \left( \eta_k^T t(z_k) - A(\eta_k) \right)\)&lt;/span&gt;
and apply the &lt;span class="math"&gt;\(\log\)&lt;/span&gt; to see that we are simply taking the covariance matrix of
the sufficient statistics &lt;span class="math"&gt;\(t(z_k)\)&lt;/span&gt;. For exponential families, this also happens
to be the second derivative of the log normalizing constant,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  G(\eta_k)
  &amp;amp;= \mathbb{E}_{q(z_k|\eta_k)} \left[
      \left( \nabla_{\eta_k} \log q(z_k|\eta_k) \right) \left( \nabla_{\eta_k} \log q(z_k|\eta_k) \right)^T
    \right] \\
  &amp;amp;= \mathbb{E}_{q(z_k|\eta_k)} \left[
      \left( t(z_k) - \nabla_{\eta_k} A(\eta_k) \right) \left( t(z_k) - \nabla_{\eta_k} A(\eta_k) \right)^T
    \right] \\
  &amp;amp;= \mathbb{E}_{q(z_k|\eta_k)} \left[
      \left( t(z_k) - \mathbb{E}_{q(z_k|\eta_k)} [t(z_k)] \right) \left( t(z_k) - \mathbb{E}_{q(z_k|\eta_k)} [t(z_k)] \right)^T
    \right] \\
  &amp;amp;= \nabla_{\eta_k}^2 A(\eta_k) \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Finally, let's define a Gradient Ascent algorithm in terms of the Natural
Gradient, rather than the regular gradient,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \eta_k^{(t+1)}
  &amp;amp; = \eta_k^{(t)} + \alpha^{(t)} \hat{\nabla}_{\eta_k} L(\eta_k^{(t)}) \\
  &amp;amp; = \eta_k^{(t)} + \alpha^{(t)} G(\eta_k^{(t)})^{-1} \nabla_{\eta_k} L(\eta_k^{(t)}) \\
  &amp;amp; = \eta_k^{(t)} + \alpha^{(t)}
    \left( \nabla_{\eta_k}^2 A(\eta_k^{(t)}) \right)^{-1}
    \left[
      \left( \nabla_{\eta_k}^2 A(\eta_k^{(t)}) \right)
      \left(
        \mathbb{E}_{q(z_{-k}|\eta_{-k})} \left[ g(z_{-k},x) \right]
        - \eta_k^{(t)}
      \right)
    \right] \\
  &amp;amp; = (1 - \alpha^{(t)}) \eta_k^{(t)}
    + \alpha^{(t)} \mathbb{E}_{q(z_{-k}|\eta_{-k})} \left[ g(z_{-k},x) \right] \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Look at that -- &lt;span class="math"&gt;\(G(\eta_k^{(t)})^{-1} = (\nabla_{\eta_k}^2 A(\eta_k))^{-1}\)&lt;/span&gt;
perfectly cancels out &lt;span class="math"&gt;\(\nabla_{\eta_k}^2 A(\eta_k)\)&lt;/span&gt;, and we're left with a
linear combination of the old parameters and the parameters Coordinate Ascent
would recommend. If &lt;span class="math"&gt;\(\alpha^{(t)} = 1\)&lt;/span&gt;, then we just get the old Coordinate
Ascent update!&lt;/p&gt;
&lt;h1&gt;&lt;a name="extensions" href="#extensions"&gt;Extensions&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;The Variational Inference method I described here, while general in concept,
can only easily be applied to a very particular class models -- ones where
&lt;span class="math"&gt;\(P(z_k | z_{-k}, x)\)&lt;/span&gt; is in the exponential family. This more or less means that
&lt;span class="math"&gt;\(z_k\)&lt;/span&gt; be a discrete variable or that &lt;span class="math"&gt;\(P(z_k)\)&lt;/span&gt; be a conjugate prior to all other
variables depending on it.&lt;/p&gt;
&lt;p&gt;In addition, we restricted &lt;span class="math"&gt;\(q(z | \eta)\)&lt;/span&gt; to be a mean field approximation,
meaning that each variable is independent with its own distribution &lt;span class="math"&gt;\(q(z_k |
\eta_k)\)&lt;/span&gt;. This approximation has no hope of representing any interactions
between variables, and perhaps surprisingly &lt;span class="math"&gt;\(q(z_k|\eta_k)\)&lt;/span&gt; does &lt;em&gt;not match the
marginal distribution over &lt;span class="math"&gt;\(z_k\)&lt;/span&gt; at all.&lt;/em&gt;  This is a common source of confusion
for first-time users, and makes debugging Variational Inference algorithms
rather difficult.&lt;/p&gt;
&lt;p&gt;Third, the Coordinate Ascent algorithm described is not necessarily quick. I
explained how Coordinate Ascent is really just Gradient Ascent on the natural
gradient, so it's easy to ask what other methods we might be able to apply.&lt;/p&gt;
&lt;p&gt;Here are a handful of papers that extend Variational Inference to faster
optimization methods, different variational distribution, and non-conjugate
models.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://books.nips.cc/papers/files/nips25/NIPS2012_1314.pdf"&gt;"Fast Variational Inference in the Conjugate Exponential
Family"&lt;/a&gt; -- Conjugate Gradient applied to the Marginalized
Variational Bound. Shows that the Marginalized Variational Bound upper bounds the
typical Variational Bound and that the former also has better curvature. That
means second-order optimizers like Conjugate Gradient can take larger steps and
render better performance.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/abs/1206.6679"&gt;"Fixed-Form Variational Posterior Approximation through Stochastic Linear
Regression"&lt;/a&gt; -- fits a (potentially) non-decomposable
exponential family distribution via Linear Regression. Involves looking at KL
divergence between unnormalized variational distribution and joint distribution
of model, taking derivative with respect to variational distribution's
parameters and setting to 0, then solving for the parameters. Can be applied to
non-conjugate models due to sampling for estimating expectations.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.cs.princeton.edu/~blei/papers/BleiNgJordan2003.pdf"&gt;"Variational Inference in Nonconjugate Models"&lt;/a&gt; -- Getting
away from conjugate priors via Laplace and the Delta Method.&lt;/p&gt;
&lt;h1&gt;&lt;a name="references" href="#references"&gt;References&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;The seminal work on the Natural Gradient is due to Shunichi Amari's &lt;a href="http://www.maths.tcd.ie/~mnl/store/Amari1998a.pdf"&gt;"Natural
Gradient Works Efficiently in Learning"&lt;/a&gt;. The derivation for the natural
gradient is Theorem 1. Thanks to &lt;a href="https://twitter.com/atpassos_ml"&gt;Alexandre Passos&lt;/a&gt; for suggesting
this and giving a short-hand intuition of the proof.&lt;/p&gt;
&lt;p&gt;The derivation for Variational Inference and the correspondence between
Coordinate Ascent and Gradient Ascent is based on the introduction to Matt
Hoffman et al.'s &lt;a href="http://arxiv.org/abs/1206.7051"&gt;"Stochastic Variational Inference"&lt;/a&gt;.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="optimization"></category><category term="optimization"></category><category term="inference"></category><category term="bayesian"></category></entry><entry><title>Accelerated Proximal Gradient Descent</title><link href="https://stronglyconvex.com/blog/accelerated-proximal-gradient-descent.html" rel="alternate"></link><published>2013-04-25T00:00:00-07:00</published><updated>2013-04-25T00:00:00-07:00</updated><author><name>Daniel Duckworth</name></author><id>tag:stronglyconvex.com,2013-04-25:/blog/accelerated-proximal-gradient-descent.html</id><summary type="html">&lt;p&gt;&lt;span class="math"&gt;\(\def\prox{\text{prox}}\)&lt;/span&gt;
  In a &lt;a href="https://stronglyconvex.com/blog/proximal-gradient-descent.html"&gt;previous post&lt;/a&gt;, I presented Proximal Gradient, a
method for bypassing the &lt;span class="math"&gt;\(O(1 / \epsilon^2)\)&lt;/span&gt; convergence rate of Subgradient
Descent.  This method relied on assuming that the objective function could be
expressed as the sum of 2 functions, &lt;span class="math"&gt;\(g(x)\)&lt;/span&gt; and &lt;span class="math"&gt;\(h(x)\)&lt;/span&gt;, with …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;span class="math"&gt;\(\def\prox{\text{prox}}\)&lt;/span&gt;
  In a &lt;a href="https://stronglyconvex.com/blog/proximal-gradient-descent.html"&gt;previous post&lt;/a&gt;, I presented Proximal Gradient, a
method for bypassing the &lt;span class="math"&gt;\(O(1 / \epsilon^2)\)&lt;/span&gt; convergence rate of Subgradient
Descent.  This method relied on assuming that the objective function could be
expressed as the sum of 2 functions, &lt;span class="math"&gt;\(g(x)\)&lt;/span&gt; and &lt;span class="math"&gt;\(h(x)\)&lt;/span&gt;, with &lt;span class="math"&gt;\(g\)&lt;/span&gt; being
differentiable and &lt;span class="math"&gt;\(h\)&lt;/span&gt; having an easy to compute &lt;a href="/blog/proximal-gradient-descent.html#intuition"&gt;&lt;span class="math"&gt;\(\prox\)&lt;/span&gt;
function&lt;/a&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
  \prox_{\alpha h}(x) = \arg\min_{y} \alpha h(y) + \frac{1}{2}||y - x||_2^2
$$&lt;/div&gt;
&lt;p&gt;In the &lt;a href="https://stronglyconvex.com/blog/accelerated-gradient-descent.html"&gt;post before that&lt;/a&gt;, I presented Accelerated
Gradient Descent, a method that outperforms Gradient Descent while making the
exact same assumptions. It is then natural to ask, "Can we combine Accelerated
Gradient Descent and Proximal Gradient to obtain a new algorithm?"  Well if we
couldn't, why the hell would I be writing about something called "Accelerated
Proximal Gradient."  C'mon people, work with me.  Now let's get on with it!&lt;/p&gt;
&lt;h1&gt;&lt;a name="implementation" href="#implementation"&gt;How does it work?&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;As you might guess, the setup is precisely the same as Proximal Gradient. Let
our objective be expressed as the sum of 2 functions,&lt;/p&gt;
&lt;div class="math"&gt;$$
  \min_{x} g(x) + h(x)
$$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(g\)&lt;/span&gt; is differentiable and &lt;span class="math"&gt;\(h\)&lt;/span&gt; is "simple" in the sense that its &lt;span class="math"&gt;\(\prox\)&lt;/span&gt;
function can cheaply be computed. Given that, the algorithm is pretty much what
you would expect from the lovechild of Proximal Gradient and Accelerated
Gradient Descent,&lt;/p&gt;
&lt;div class="pseudocode"&gt;
&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt;: initial iterate &lt;span class="math"&gt;\(x^{(0)}\)&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Let &lt;span class="math"&gt;\(y^{(0)} = x^{(0)}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;For &lt;span class="math"&gt;\(t = 1, 2, \ldots\)&lt;/span&gt;&lt;ol&gt;
&lt;li&gt;Let &lt;span class="math"&gt;\(x^{(t)} = \prox_{\alpha^{(t)} h} (y^{(t-1)} - \alpha^{(t)} \nabla f(y^{(t-1)}) )\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;if converged, return &lt;span class="math"&gt;\(x^{(t)}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Let &lt;span class="math"&gt;\(y^{(t)} = x^{(t)} + \frac{t-1}{t+2} (x^{(t)} - x^{(t-1)})\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;h1&gt;&lt;a name="example" href="#example"&gt;A Small Example&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;To illustrate Accelerated Proximal Gradient, I'll use the same objective function as I did in illustrating Proximal Gradient Descent. Namely,&lt;/p&gt;
&lt;div class="math"&gt;$$
  \min_{x} \, \log(1 + \exp(-2x)) + ||x||_1
$$&lt;/div&gt;
&lt;p&gt;which has the following gradient for &lt;span class="math"&gt;\(g(x) = \log(1+\exp(-2x))\)&lt;/span&gt; and &lt;span class="math"&gt;\(\prox\)&lt;/span&gt;
operator for &lt;span class="math"&gt;\(h(x) = ||x||_1\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \nabla g(x) &amp;amp;= \frac{1}{1 + \exp(-2x)} \left( \exp(-2x) \right) (-2) \\
  \prox_{\alpha h}(x) &amp;amp; = \text{sign}(x) \max(0, \text{abs}(x) - \alpha) \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;As before, we employ Backtracking Line Search to select the step size. In
this example, regular Proximal Gradient seems to beat out Accelerated
Proximal Gradient, but rest assured this is an artifact of the tiny problem
size.&lt;/p&gt;
&lt;div class="img-center"&gt;
  &lt;img src="/assets/img/accelerated_proximal_gradient_descent/convergence.png"&gt;&lt;/img&gt;
  &lt;span class="caption"&gt;
    This plot shows how quickly the objective function decreases as the
    number of iterations increases. Notice how the objective function doesn't
    necessarily decrease at each step.
  &lt;/span&gt;
&lt;/div&gt;

&lt;div class="img-center"&gt;
  &lt;img src="/assets/img/accelerated_proximal_gradient_descent/iterates.png"&gt;&lt;/img&gt;
  &lt;span class="caption"&gt;
    This plot shows the actual iterates and the objective function evaluated at
    those points. More red indicates a higher iteration number.
  &lt;/span&gt;
&lt;/div&gt;

&lt;h1&gt;&lt;a name="proof" href="#proof"&gt;Why does it work?&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;For the proof of Accelerated Proximal Gradient, we'll make the same
assumptions we did in Proximal Gradient. Namely,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;span class="math"&gt;\(g(x)\)&lt;/span&gt; is convex, differentiable, and finite for all &lt;span class="math"&gt;\(x\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;a finite solution &lt;span class="math"&gt;\(x^{*}\)&lt;/span&gt; exists&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\nabla g(x)\)&lt;/span&gt; is Lipschitz continuous with constant &lt;span class="math"&gt;\(L\)&lt;/span&gt;. That is, there must
   be an &lt;span class="math"&gt;\(L\)&lt;/span&gt; such that,&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="math"&gt;$$
  || \nabla g(x) - \nabla g(y) ||_2 \le L || x - y ||_2 \qquad \forall x,y
$$&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;&lt;span class="math"&gt;\(h(x)\)&lt;/span&gt; is convex&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Proof Outline&lt;/strong&gt; In the same way that the proof for Proximal Gradient
largely follows the proof for regular Gradient Descent, the proof for
Accelerated Proximal Gradient follows the proof for Accelerated Gradient
Descent. Our goal is to prove a statement of the form,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
    (g+h)(x^{+})
    \le (1-\theta) (g+h)(x) + \theta (g+h)(x^{*}) + \frac{\theta^2}{2 \alpha^{+}} \left(
        ||v - x^{*}||_2^2 - ||v^{+} - x^{*}||_2^2
      \right) \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Once we achieve this, the proof follows that of Accelerated Gradient with &lt;span class="math"&gt;\(f
\rightarrow g+h\)&lt;/span&gt; from Step 2 onwards.&lt;/p&gt;
&lt;p&gt;How will we do this? As with Accelerated Gradient, we define a new set of
iterates &lt;span class="math"&gt;\(v^{(t)}\)&lt;/span&gt; in terms of &lt;span class="math"&gt;\(x^{(t)}\)&lt;/span&gt; and &lt;span class="math"&gt;\(x^{(t-1)}\)&lt;/span&gt; and then define
&lt;span class="math"&gt;\(y^{(t)}\)&lt;/span&gt; in terms of &lt;span class="math"&gt;\(v^{(t)}\)&lt;/span&gt; and &lt;span class="math"&gt;\(x^{(t)}\)&lt;/span&gt;. We then exploit the Lipschitz bound
on &lt;span class="math"&gt;\(g\)&lt;/span&gt; and a particular subgradient bound on &lt;span class="math"&gt;\(h\)&lt;/span&gt; to establish an upper bound
on &lt;span class="math"&gt;\((g+h)(x^{(t)})\)&lt;/span&gt;. Finally, through algebraic manipulations we show the
equation presented above, and we can simply copy-paste the Accelerated Gradient
Descent proof to completion.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1&lt;/strong&gt; Define a new set of iterates &lt;span class="math"&gt;\(v^{(t)}\)&lt;/span&gt;. As with Accelerated
Gradient, we define a new set of iterates &lt;span class="math"&gt;\(v^{(t)}\)&lt;/span&gt; and a particular
&lt;span class="math"&gt;\(\theta^{(t)}\)&lt;/span&gt; as follows,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  v^{(t)}
  &amp;amp; = \frac{t+1}{2} x^{(t)} - \frac{t-1}{2} x^{(t-1)}
    = x^{(t-1)} + \frac{1}{\theta^{(t)}} (x^{(t)} - x^{(t-1)}) \\
  \theta^{(t)}
  &amp;amp; = \frac{2}{t+1} \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;This definition also allows us to redefine &lt;span class="math"&gt;\(y^{(t)}\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
  y^{(t)}
  = (1 - \theta^{(t)}) x^{(t)} + \theta^{(t)} v^{(t)} \\
$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Step 2&lt;/strong&gt; Use the Lipschitz property of &lt;span class="math"&gt;\(g\)&lt;/span&gt; and subgradient property of &lt;span class="math"&gt;\(h\)&lt;/span&gt;
to upper bound &lt;span class="math"&gt;\((g+h)(x^{(t+1)})\)&lt;/span&gt;.  Let's begin by defining &lt;span class="math"&gt;\(x^{+} \triangleq
x^{(t)}\)&lt;/span&gt;, &lt;span class="math"&gt;\(x \triangleq x^{(t-1)}\)&lt;/span&gt;, &lt;span class="math"&gt;\(y \triangleq y^{(t-1)}\)&lt;/span&gt;, &lt;span class="math"&gt;\(\theta
\triangleq \theta^{(t-1)}\)&lt;/span&gt;, &lt;span class="math"&gt;\(v^{+} \triangleq v^{(t)}\)&lt;/span&gt;, and &lt;span class="math"&gt;\(v \triangleq
v^{(t-1)}\)&lt;/span&gt;.  From the Lipschitz property of &lt;span class="math"&gt;\(g\)&lt;/span&gt;, we immediately get,&lt;/p&gt;
&lt;div class="math"&gt;$$
  g(x^{+}) \le g(y) + \nabla g(y)^T (x^{+} - y) + \frac{L}{2} ||x^{+} - y||_2^2
$$&lt;/div&gt;
&lt;p&gt;Let's immediately assume &lt;span class="math"&gt;\(\alpha \le \frac{1}{L}\)&lt;/span&gt;, so we can replace &lt;span class="math"&gt;\(\frac{L}{2}\)&lt;/span&gt; with &lt;span class="math"&gt;\(\frac{1}{2 \alpha}\)&lt;/span&gt;. Now let's derive the subgradient property of &lt;span class="math"&gt;\(h\)&lt;/span&gt; we need.  Recall the subgradient definition,&lt;/p&gt;
&lt;div class="math"&gt;$$
  h(z) \ge h(\tilde{x}) + G^T (z-\tilde{x}) \qquad G \in \partial h(\tilde{x})
$$&lt;/div&gt;
&lt;p&gt;Now let &lt;span class="math"&gt;\(x^{+} = \prox_{\alpha h}(\tilde{x}) = \arg\min_{w} \alpha h(w) + \frac{1}{2}||w - \tilde{x}||_2^2\)&lt;/span&gt;.  According to the KKT conditions, 0 must be in the subdifferential of &lt;span class="math"&gt;\(\alpha h(x^{+}) + \frac{1}{2} || x^{+} - \tilde{x} ||_2^2\)&lt;/span&gt;.  Plugging this in, we see that,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  0 &amp;amp; \in \alpha \partial h(x^{+}) + (x^{+} - \tilde{x}) \\
  \frac{1}{\alpha} \left( \tilde{x} - x^{+} \right) &amp;amp; \in \partial h(x^{+})
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;We now have a subgradient for &lt;span class="math"&gt;\(h(x^{+})\)&lt;/span&gt;.  Plugging this back into the
subgradient condition with &lt;span class="math"&gt;\(\tilde{x} \rightarrow x^{+}\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  h(z)
  &amp;amp;\ge h(x^{+}) + \frac{1}{\alpha} \left( \tilde{x} - x^{+} \right)^T(z - x^{+}) \\
  h(z) + \frac{1}{\alpha} \left( x^{+} - \tilde{x} \right)^T (z - x^{+})
  &amp;amp;\ge h(x^{+}) \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Finally, substitute &lt;span class="math"&gt;\(\tilde{x} = y - \alpha \nabla g(y)\)&lt;/span&gt; to obtain our
desired upper bound on &lt;span class="math"&gt;\(h(x^{+})\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  h(x^{+})
  &amp;amp; \le h(z) + \frac{1}{\alpha} \left( x^{+} - \left(y - \alpha \nabla g(y) \right) \right)^T (z - x^{+}) \\
  &amp;amp; = h(z) + \nabla g(y)^T (z - x^{+}) + \frac{1}{\alpha} ( x^{+} - y )^T (z - x^{+})
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Nice. Now add the Lipschitz bound on &lt;span class="math"&gt;\(g\)&lt;/span&gt; and the subgradient bound on
&lt;span class="math"&gt;\(h\)&lt;/span&gt; to obtain an upper bound on &lt;span class="math"&gt;\((g+h)(x^{+})\)&lt;/span&gt;, then invoke convexity on &lt;span class="math"&gt;\(g(z)
\ge g(y) + \nabla g(y)^T (z-y)\)&lt;/span&gt; to get rid of the linear term involving &lt;span class="math"&gt;\(\nabla
g(y)\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  (g+h)(x^{+})
  &amp;amp; \le g(y) + h(z) + \nabla g(y)^T (z-y) + \frac{1}{\alpha} (x^{+} - y)^T (z - x^{+}) + \frac{1}{2\alpha} ||x^{+} - y||_2^2 \\
  &amp;amp; \le g(z) + h(z) + \frac{1}{\alpha} (x^{+} - y)^T (z - x^{+}) + \frac{1}{2\alpha} ||x^{+} - y||_2^2
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Step 3&lt;/strong&gt; Use the previous upper bound to obtain the equation necessary for
invoking Accelerated Gradient Descent's proof. The core of this is to
manipulate and bound the following statement,&lt;/p&gt;
&lt;div class="math"&gt;$$
  (g+h)(x^{+}) - \theta (g+h)(x^{*}) - (1-\theta) (g+h)(x)
$$&lt;/div&gt;
&lt;p&gt;First, upper bound &lt;span class="math"&gt;\(-(g+h)(x^{*})\)&lt;/span&gt; and &lt;span class="math"&gt;\(-(g+h)(x)\)&lt;/span&gt; with &lt;span class="math"&gt;\(z = x^{*}\)&lt;/span&gt; and &lt;span class="math"&gt;\(z =
x^{+}\)&lt;/span&gt; using the result of Step 2, then add zero and factor the quadratic,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  &amp;amp; (g+h)(x^{+}) - \theta (g+h)(x^{*}) - (1-\theta) (g+h)(x) \\
  &amp;amp; \le (g+h)(x^{+}) + \theta \left(
      - (g+h)(x^{+}) + \frac{1}{\alpha} (x^{+} - y)^T (x^{*} - x^{+}) + \frac{1}{2 \alpha} ||x^{+} - y||_2^2
    \right) \\
  &amp;amp; \qquad + (1-\theta) \left(
      - (g+h)(x    ) + \frac{1}{\alpha} (x^{+} - y)^T (x     - x^{+}) + \frac{1}{2 \alpha} ||x     - y||_2^2
    \right) \\
  &amp;amp; = \frac{1}{\alpha} (x^{+} - y)^T ( \theta x^{*} + (1-\theta) x - x^{+} ) + \frac{1}{2 \alpha} ||x^{+} - y||_2^2 \pm \frac{1}{2 \alpha} ||\theta x^{*} + (1-\theta) x - x^{+} ||_2^2 \\
  &amp;amp; = \frac{1}{2 \alpha} \left(
    ||x^{+} - y + \theta x^{*} + (1 - \theta) x - x^{+}||_2^2
    - ||\theta x^{*} + (1 - \theta) x - x^{+}||_2^2
  \right) \\
  &amp;amp; = \frac{1}{2 \alpha} \left(
    ||y - \theta x^{*} - (1 - \theta) x||_2^2
    - || x^{+} - \theta x^{*} - (1 - \theta) x||_2^2
  \right) \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Finally, use &lt;span class="math"&gt;\(y = (1 - \theta) x + \theta v\)&lt;/span&gt; to get &lt;span class="math"&gt;\(y - (1-\theta) x =
\theta v\)&lt;/span&gt; and then &lt;span class="math"&gt;\(v^{+} = x + \frac{1}{\theta} ( x^{+} - x )\)&lt;/span&gt; to obtain
&lt;span class="math"&gt;\(\theta v^{+} = x^{+} - (1-\theta) x\)&lt;/span&gt;. Substituting these in,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  &amp;amp; (g+h)(x^{+}) - \theta (g+h)(x^{*}) - (1-\theta) (g+h)(x) \\
  &amp;amp; \le \frac{1}{2 \alpha} \left(
    ||\theta v - \theta x^{*}||_2^2 - || \theta v^{+} - \theta x^{*} ||_2^2
  \right) \\
  &amp;amp; = \frac{\theta^2}{2 \alpha} \left(
    || v - x^{*}||_2^2 - || v^{+} - x^{*} ||_2^2
  \right) \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Which was our original goal.  We then follow the proof for Accelerated
Gradient Descent with &lt;span class="math"&gt;\(f \rightarrow g + h\)&lt;/span&gt; starting from Step 2 to obtain
the desired rate of convergence, &lt;span class="math"&gt;\(O(1 / \sqrt{\epsilon})\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;As a final note, you'll notice that in this proof &lt;span class="math"&gt;\(\theta^{(t)} =
\frac{2}{t+1}\)&lt;/span&gt;, but in the original Accelerated Gradient proof &lt;span class="math"&gt;\(\theta^{(t)}
= \frac{2}{t+2}\)&lt;/span&gt;. This ends up no mattering, as the only property we need being
&lt;span class="math"&gt;\(\frac{1 - \theta^{(t)}}{ (\theta^{(t)})^2 } \le \frac{1}{ (\theta^{(t)})^2 }\)&lt;/span&gt;,
which holds for either definition.&lt;/p&gt;
&lt;h1&gt;&lt;a name="usage" href="#usage"&gt;When should I use it?&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;As with &lt;a href="/blog/accelerated-gradient-descent.html#usage"&gt;Accelerated Gradient&lt;/a&gt;, the algorithm
works well &lt;em&gt;as long as you get the step size right&lt;/em&gt;. That means Backtracking
Line Search is an absolute must if you don't know &lt;span class="math"&gt;\(g\)&lt;/span&gt;'s Lipschitz constant
analytically.  If Line Search is possible, you can only gain over Proximal
Gradient by employing Accelerated Proximal Gradient; with that said, test a
Proximal Gradient algorithm first, and advance to Accelerated Proximal Gradient
only if you're sure you need the faster convergence rate.&lt;/p&gt;
&lt;h1&gt;&lt;a name="extensions" href="#extensions"&gt;Extensions&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Step Size&lt;/strong&gt; As with Accelerated Gradient, getting the correct step size is
of utmost importance. If &lt;span class="math"&gt;\(\alpha^{(t)} &amp;gt; \frac{1}{L}\)&lt;/span&gt;, &lt;em&gt;the algorithm will
diverge&lt;/em&gt;. With that said, Backtracking Line Search will guarantee convergence.
You can find an implementation in &lt;a href="/blog/proximal-gradient-descent.html#line_search"&gt;my previous post on Proximal
Gradient&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a name="references" href="#references"&gt;References&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Proof of convergence&lt;/strong&gt; The proof of convergence is taken from Lieven
Vandenberghe's fantastic &lt;a href="http://www.ee.ucla.edu/~vandenbe/236C/lectures/fgrad.pdf"&gt;EE236c slides&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a name="reference-impl" href="#reference-impl"&gt;Reference Implementation&lt;/a&gt;&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;accelerated_proximal_gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;g_gradient&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h_prox&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                  &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_iterations&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Proximal Gradient Descent&lt;/span&gt;

&lt;span class="sd"&gt;  Parameters&lt;/span&gt;
&lt;span class="sd"&gt;  ----------&lt;/span&gt;
&lt;span class="sd"&gt;  g_gradient : function&lt;/span&gt;
&lt;span class="sd"&gt;      Compute the gradient of `g(x)`&lt;/span&gt;
&lt;span class="sd"&gt;  h_prox : function&lt;/span&gt;
&lt;span class="sd"&gt;      Compute prox operator for h * alpha&lt;/span&gt;
&lt;span class="sd"&gt;  x0 : array&lt;/span&gt;
&lt;span class="sd"&gt;      initial value for x&lt;/span&gt;
&lt;span class="sd"&gt;  alpha : function&lt;/span&gt;
&lt;span class="sd"&gt;      function computing step sizes&lt;/span&gt;
&lt;span class="sd"&gt;  n_iterations : int, optional&lt;/span&gt;
&lt;span class="sd"&gt;      number of iterations to perform&lt;/span&gt;

&lt;span class="sd"&gt;  Returns&lt;/span&gt;
&lt;span class="sd"&gt;  -------&lt;/span&gt;
&lt;span class="sd"&gt;  xs : list&lt;/span&gt;
&lt;span class="sd"&gt;      intermediate values for x&lt;/span&gt;
&lt;span class="sd"&gt;  &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
  &lt;span class="n"&gt;xs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="n"&gt;ys&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_iterations&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;ys&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;g_gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;x_plus&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;h_prox&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;y_plus&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mf"&gt;3.0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_plus&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_plus&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_plus&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;xs&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;backtracking_line_search&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;g_gradient&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h_prox&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;alpha_0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;
  &lt;span class="n"&gt;beta&lt;/span&gt;    &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.9&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;search&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;alpha_0&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="n"&gt;x_plus&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;h_prox&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;g_gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;G&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;x_plus&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_plus&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_plus&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;G&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;G&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;
      &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;beta&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;search&lt;/span&gt;


&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;

  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;yannopt.plotting&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plotting&lt;/span&gt;

  &lt;span class="c1"&gt;### ACCELERATED PROXIMAL GRADIENT ###&lt;/span&gt;

  &lt;span class="c1"&gt;# problem definition&lt;/span&gt;
  &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="n"&gt;h&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;function&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;g_gradient&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="n"&gt;h_prox&lt;/span&gt;      &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sign&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;alpha&lt;/span&gt;       &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;backtracking_line_search&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;g_gradient&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h_prox&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;x0&lt;/span&gt;          &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;5.0&lt;/span&gt;
  &lt;span class="n"&gt;n_iterations&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;

  &lt;span class="c1"&gt;# run gradient descent&lt;/span&gt;
  &lt;span class="n"&gt;iterates&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;accelerated_proximal_gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                  &lt;span class="n"&gt;g_gradient&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h_prox&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                  &lt;span class="n"&gt;n_iterations&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;n_iterations&lt;/span&gt;
             &lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="c1"&gt;### PLOTTING ###&lt;/span&gt;

  &lt;span class="n"&gt;plotting&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot_iterates_vs_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iterates&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                     &lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;figures/iterates.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                     &lt;span class="n"&gt;y_star&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.69314718055994529&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;plotting&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot_iteration_vs_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iterates&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                      &lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;figures/convergence.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                      &lt;span class="n"&gt;y_star&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.69314718055994529&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="optimization"></category><category term="optimization"></category><category term="first-order"></category><category term="accelerated"></category><category term="proximal"></category></entry><entry><title>Coordinate Ascent for Convex Clustering</title><link href="https://stronglyconvex.com/blog/coordinate-ascent-convex-clustering.html" rel="alternate"></link><published>2013-04-23T00:00:00-07:00</published><updated>2013-04-23T00:00:00-07:00</updated><author><name>Daniel Duckworth</name></author><id>tag:stronglyconvex.com,2013-04-23:/blog/coordinate-ascent-convex-clustering.html</id><summary type="html">&lt;p&gt;Convex clustering is the reformulation of k-means clustering as a convex
problem. While the two problems are not equivalent, the former can be seen as a
relaxation of the latter that allows us to easily find globally optimal
solutions (as opposed to only locally optimal ones).&lt;/p&gt;
&lt;p&gt;Suppose we have a …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Convex clustering is the reformulation of k-means clustering as a convex
problem. While the two problems are not equivalent, the former can be seen as a
relaxation of the latter that allows us to easily find globally optimal
solutions (as opposed to only locally optimal ones).&lt;/p&gt;
&lt;p&gt;Suppose we have a set of points &lt;span class="math"&gt;\(\{ x_i : i = 1, \ldots, n\}\)&lt;/span&gt;. Our goal is to
partition these points into groups such that all the elements in each group are
close to each other and are distant from points in other groups.&lt;/p&gt;
&lt;p&gt;In this post, I'll talk about an algorithm to do just that.&lt;/p&gt;
&lt;div class="img-center" style="max-width: 400px;"&gt;
  &lt;img src="/assets/img/convex_clustering/clusters.png"&gt;&lt;/img&gt;
  &lt;span class="caption"&gt;
    8 clusters of points in 2D with their respective centers.  All points of
    the same color belong to the same cluster.
  &lt;/span&gt;
&lt;/div&gt;

&lt;h1&gt;&lt;a name="k-means" href="#k-means"&gt;K-Means&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;The original objective for k-means clustering is as follows. Suppose we want
to find &lt;span class="math"&gt;\(k\)&lt;/span&gt; sets &lt;span class="math"&gt;\(S_i\)&lt;/span&gt; such that every &lt;span class="math"&gt;\(x_i\)&lt;/span&gt; is in exactly 1 set &lt;span class="math"&gt;\(S_j\)&lt;/span&gt;. Each &lt;span class="math"&gt;\(S_j\)&lt;/span&gt;
will then have a center &lt;span class="math"&gt;\(\theta_j\)&lt;/span&gt;, which is simply the average of all &lt;span class="math"&gt;\(x_i\)&lt;/span&gt; it
contains. Putting it all together, we obtain the following optimization problme,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  &amp;amp; \underset{S}{\min}  &amp;amp; &amp;amp; \sum_{j=1}^{k} \sum_{i \in S_j} ||x_i - \theta_j||_2^2 \\
  &amp;amp; \text{subject to}   &amp;amp; &amp;amp; \theta_j = \frac{1}{|S_j|} \sum_{i \in S_j} x_i \\
  &amp;amp;                     &amp;amp; &amp;amp; \bigcup_{j} S_j = \{ 1 \ldots n \}
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;In 2009, &lt;a href="http://dl.acm.org/citation.cfm?id=1519389"&gt;Aloise et al.&lt;/a&gt; proved that solving this problem is
NP-hard, meaning that short of enumerating every possible partition, we cannot
say whether or not we've found an optimal solution &lt;span class="math"&gt;\(S^{*}\)&lt;/span&gt;. In other words, we
can approximately solve k-means, but actually solving it is very
computationally intense (with the usual caveats about &lt;span class="math"&gt;\(P = NP\)&lt;/span&gt;).&lt;/p&gt;
&lt;h1&gt;&lt;a name="convex-clustering" href="#convex-clustering"&gt;Convex Clustering&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Convex clustering sidesteps this complexity result by proposing a new
problem that we &lt;em&gt;can&lt;/em&gt; solve quickly. The optimal solution for this new problem
need not coincide with that of k-means, but &lt;a href="http://www.control.isy.liu.se/research/reports/2011/2992.pdf"&gt;can be seen&lt;/a&gt; a solution to
the convex relaxation of the original problem.&lt;/p&gt;
&lt;p&gt;The idea of convex clustering is that each point &lt;span class="math"&gt;\(x_i\)&lt;/span&gt; is paired with its
associated center &lt;span class="math"&gt;\(u_i\)&lt;/span&gt;, and the distance between the two is minimized. If this
were nothing else, &lt;span class="math"&gt;\(u_i = x_i\)&lt;/span&gt; would be the optimal solution, and no
clustering would happen. Instead, a penalty term is added that brings the
clusters centers close together,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \min_{u} \frac{1}{2} \sum_{i=1}^{n} ||x_i - u_i||_2^2
            + \gamma \sum_{i &amp;lt; j} w_{i,j} ||u_i - u_j||_p
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Notice that the distance &lt;span class="math"&gt;\(||x_i - u_i||_2^2\)&lt;/span&gt; is a squared 2-norm, but
the distance between the centers &lt;span class="math"&gt;\(||u_i - u_j||_p\)&lt;/span&gt; is a p-norm (&lt;span class="math"&gt;\(p \in \{1, 2,
\infty \}\)&lt;/span&gt;). This sum-of-norms type penalization brings about "group sparsity"
and is used primarily because many of the elements in this sum will be 0 at the
optimum. In convex clustering, that means &lt;span class="math"&gt;\(u_i = u_j\)&lt;/span&gt; for some pairs &lt;span class="math"&gt;\(i\)&lt;/span&gt; and
&lt;span class="math"&gt;\(j\)&lt;/span&gt; -- in other words, &lt;span class="math"&gt;\(i\)&lt;/span&gt; and &lt;span class="math"&gt;\(j\)&lt;/span&gt; are clustered together!&lt;/p&gt;
&lt;h1&gt;&lt;a name="algorithms" href="#algorithms"&gt;Algorithms for Convex Clustering&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;As the convex clustering formulation is a convex problem, we automatically
get a variety of black-box algorithms capable of solving it. Unfortunately, the
number of variables in the problem is rather large -- if &lt;span class="math"&gt;\(x_i \in
\mathcal{R}^{d}\)&lt;/span&gt;, then &lt;span class="math"&gt;\(u \in \mathcal{R}^{n \times d}\)&lt;/span&gt;.  If &lt;span class="math"&gt;\(d = 5\)&lt;/span&gt;, we cannot
reasonably expect interior point solvers such as &lt;a href="http://cvxr.com/cvx/"&gt;cvx&lt;/a&gt; to handle any more
than a few thousand points.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.icml-2011.org/papers/419_icmlpaper.pdf"&gt;Hocking et al.&lt;/a&gt; and &lt;a href="http://arxiv.org/abs/1304.0499"&gt;Chi et al.&lt;/a&gt; were the first to design
algorithms specifically for convex clustering. The former designed one
algorithm for each &lt;span class="math"&gt;\(p\)&lt;/span&gt;-norm, employing active sets (&lt;span class="math"&gt;\(p \in \{1, 2\}\)&lt;/span&gt;),
subgradient descent (&lt;span class="math"&gt;\(p = 2\)&lt;/span&gt;), and the Frank-Wolfe algorithm (&lt;span class="math"&gt;\(p = \infty\)&lt;/span&gt;).
The latter makes use of &lt;a href="http://www.stanford.edu/~boyd/papers/admm_distr_stats.html"&gt;ADMM&lt;/a&gt; and AMA, the latter of which reduces to
proximal gradient on a dual objective.&lt;/p&gt;
&lt;p&gt;Here, I'll describe another method for solving the convex clustering problem
based on coordinate ascent. The idea is to take the original formulation,
substitute a new primal variable &lt;span class="math"&gt;\(z_l = u_{l_1} - u_{l_2}\)&lt;/span&gt;, then update a dual
variable &lt;span class="math"&gt;\(\lambda_l\)&lt;/span&gt; corresponding to each equality constraint 1 at a time. For
this problem, we can reconstruct the primal variables &lt;span class="math"&gt;\(u_i\)&lt;/span&gt; in closed form
given the dual variables, so it is easy to check how close we are to the
optimum.&lt;/p&gt;
&lt;!--
  &lt;table class="table table-hover table-bordered"&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th&gt;Memory required&lt;/th&gt;
      &lt;th&gt;per-iteration complexity&lt;/th&gt;
      &lt;th&gt;number of iterations required&lt;/th&gt;
      &lt;th&gt;parallelizability&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Clusterpath ($L_1$)&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Clusterpath ($L_2$)&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Clusterpath ($L_{\infty}$)&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ADMM&lt;/td&gt;
      &lt;td&gt;$O(pd)$&lt;/td&gt;
      &lt;td&gt;$O(pd)$&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AMA (accelerated)&lt;/td&gt;
      &lt;td&gt;$O(pd)$&lt;/td&gt;
      &lt;td&gt;$O(pd)$&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Coordinate Ascent&lt;/td&gt;
      &lt;td&gt;$O(pd)$&lt;/td&gt;
      &lt;td&gt;$O(pd)$&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
      &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;

  For $p =$ number of pairs with $w_l &gt; 0$, $n =$ the number of points $x_i$,
$d =$ the dimensionality of $x_i$, $c = $ the current number of clusters
--&gt;

&lt;h1&gt;&lt;a name="reformulation" href="#reformulation"&gt;Problem Reformulation&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;To describe the dual problem being maximized, we first need to modify the
primal problem. First, let &lt;span class="math"&gt;\(z_l = u_{l_1} - u_{l_2}\)&lt;/span&gt;. Then we can write the
objective function as,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  &amp;amp; \underset{S}{\min}  &amp;amp; &amp;amp; \frac{1}{2} \sum_{i=1}^{n} ||x_i - u_i||_2^2
                            + \gamma \sum_{l} w_{l} ||z_l||_p \\
  &amp;amp; \text{subject to}   &amp;amp; &amp;amp; z_l = u_{l_1} - u_{l_2}
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/abs/1304.0499"&gt;Chi et al.&lt;/a&gt; show on page 6 that the dual of this problem is then,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  &amp;amp; \underset{\lambda}{\max}  &amp;amp; &amp;amp; - \frac{1}{2} \sum_{i} ||\Delta_i||_2^2
                                  - \sum_{l} \lambda_l^T (x_{l_1} - x_{l_2}) \\
  &amp;amp; \text{subject to}         &amp;amp; &amp;amp; ||\lambda_l||_{p^{*}} \le \gamma w_l \\
  &amp;amp;                           &amp;amp; &amp;amp; \Delta_{i} = \sum_{l: l_1 = i} \lambda_l - \sum_{l : l_2 = i} \lambda_l
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;In this notation, &lt;span class="math"&gt;\(||\cdot||_{p^{*}}\)&lt;/span&gt; is the dual norm of &lt;span class="math"&gt;\(||\cdot||_p\)&lt;/span&gt;. The
primal variables &lt;span class="math"&gt;\(u\)&lt;/span&gt; and dual variables &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt; are then related by the
following equation,&lt;/p&gt;
&lt;div class="math"&gt;$$
  u_i = \Delta_i + x_i
$$&lt;/div&gt;
&lt;h1&gt;&lt;a name="coordinate-ascent" href="#coordinate-ascent"&gt;Coordinate Ascent&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Now let's optimize the dual problem 1 &lt;span class="math"&gt;\(\lambda_k\)&lt;/span&gt; at a time. First, notice
that &lt;span class="math"&gt;\(\lambda_k\)&lt;/span&gt; will only appear in 2 &lt;span class="math"&gt;\(\Delta_i\)&lt;/span&gt; terms -- &lt;span class="math"&gt;\(\Delta_{k_1}\)&lt;/span&gt; and
&lt;span class="math"&gt;\(\Delta_{k_2}\)&lt;/span&gt;. After dropping all terms independent of &lt;span class="math"&gt;\(\lambda_k\)&lt;/span&gt;, we now get
the following problem,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  &amp;amp; \underset{\lambda_k}{\min}  &amp;amp; &amp;amp; \frac{1}{2} (||\Delta_{k_1}||_2^2 + ||\Delta_{k_2}||_2^2)
                                    + \lambda_k^T (x_{k_1} - x_{k_2}) \\
  &amp;amp; \text{subject to}         &amp;amp; &amp;amp; ||\lambda_k||_{p^{*}} \le \gamma w_k \\
  &amp;amp;                           &amp;amp; &amp;amp; \Delta_{k_1} = \sum_{l: l_1 = k_1} \lambda_l - \sum_{l : l_2 = k_1} \lambda_l \\
  &amp;amp;                           &amp;amp; &amp;amp; \Delta_{k_2} = \sum_{l: l_1 = k_2} \lambda_l - \sum_{l : l_2 = k_2} \lambda_l
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;We can pull &lt;span class="math"&gt;\(\lambda_k\)&lt;/span&gt; out of &lt;span class="math"&gt;\(\Delta_{k_1}\)&lt;/span&gt; and &lt;span class="math"&gt;\(\Delta_{k_2}\)&lt;/span&gt; to get,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  ||\Delta_{k_1}||_2^2 &amp;amp; = ||\lambda_k||_2^2 + ||\Delta_{k_1} - \lambda_k||_2^2 + 2 \lambda_k^T (\Delta_{k_1} - \lambda_k) \\
  ||\Delta_{k_2}||_2^2 &amp;amp; = ||\lambda_k||_2^2 + ||\Delta_{k_2} + \lambda_k||_2^2 - 2 \lambda_k^T (\Delta_{k_2} + \lambda_k)
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Let's define &lt;span class="math"&gt;\(\tilde{\Delta_{k_1}} = \Delta_{k_1} - \lambda_k\)&lt;/span&gt; and
&lt;span class="math"&gt;\(\tilde{\Delta_{k_2}} = \Delta_{k_2} + \lambda_k\)&lt;/span&gt; and add &lt;span class="math"&gt;\(||\frac{1}{2}
(\tilde{\Delta_{k_1}} - \tilde{\Delta_{k_2}} + x_{k_1} - x_{k_2})||_2^2\)&lt;/span&gt; to the
objective.&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  &amp;amp; \underset{\lambda_k}{\min}  &amp;amp; &amp;amp; ||\lambda_k||_2^2
                                    + 2 \frac{1}{2} \lambda_k^T (\tilde{\Delta_{k_1}} - \tilde{\Delta_{k_2}} + x_{k_1} - x_{k_2})
                                    + ||\frac{1}{2} (\tilde{\Delta_{k_1}} - \tilde{\Delta_{k_2}} + x_{k_1} - x_{k_2})||_2^2 \\
  &amp;amp; \text{subject to}         &amp;amp; &amp;amp; ||\lambda_k||_{p^{*}} \le \gamma w_k \\
  &amp;amp;                           &amp;amp; &amp;amp; \tilde{\Delta_{k_1}} = \sum_{l: l_1 = k_1; l \ne k} \lambda_l - \sum_{l : l_2 = k_1; l \ne k} \lambda_l \\
  &amp;amp;                           &amp;amp; &amp;amp; \tilde{\Delta_{k_2}} = \sum_{l: l_1 = k_2; l \ne k} \lambda_l - \sum_{l : l_2 = k_2; l \ne k} \lambda_l
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;We can now factor the objective into a quadratic,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  &amp;amp; \underset{\lambda_k}{\min}  &amp;amp; &amp;amp; ||\lambda_k - \left( - \frac{1}{2}(\tilde{\Delta_{k_1}} - \tilde{\Delta_{k_2}} + x_{k_1} - x_{k_2}) \right) ||_2^2 \\
  &amp;amp; \text{subject to}         &amp;amp; &amp;amp; ||\lambda_k||_{p^{*}} \le \gamma w_k \\
  &amp;amp;                           &amp;amp; &amp;amp; \tilde{\Delta_{k_1}} = \sum_{l: l_1 = k_1; l \ne k} \lambda_l - \sum_{l : l_2 = k_1; l \ne k} \lambda_l \\
  &amp;amp;                           &amp;amp; &amp;amp; \tilde{\Delta_{k_2}} = \sum_{l: l_1 = k_2; l \ne k} \lambda_l - \sum_{l : l_2 = k_2; l \ne k} \lambda_l
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;This problem is simply a Euclidean projection onto the ball defined by
&lt;span class="math"&gt;\(||\cdot||_{p^{*}}\)&lt;/span&gt;. We're now ready to write the algorithm,&lt;/p&gt;
&lt;div class="pseudocode"&gt;
&lt;p&gt;&lt;strong&gt;Input:&lt;/strong&gt; Initial dual variables &lt;span class="math"&gt;\(\lambda^{(0)}\)&lt;/span&gt;, weights &lt;span class="math"&gt;\(w_l\)&lt;/span&gt;, and regularization parameter &lt;span class="math"&gt;\(\gamma\)&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Initialize &lt;span class="math"&gt;\(\Delta_i^{(0)} = \sum_{l: l_1 = i} \lambda_l^{(0)} - \sum_{l: l_2 = i} \lambda_l^{(0)}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;For each iteration &lt;span class="math"&gt;\(m = 0,1,2,\ldots\)&lt;/span&gt; until convergence&lt;ol&gt;
&lt;li&gt;Let &lt;span class="math"&gt;\(\Delta^{(m+1)} = \Delta^{(m)}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;For each pair of points &lt;span class="math"&gt;\(l = (i,j)\)&lt;/span&gt; with &lt;span class="math"&gt;\(w_{l} &amp;gt; 0\)&lt;/span&gt;&lt;ol&gt;
&lt;li&gt;Let &lt;span class="math"&gt;\(\Delta_i^{(m+1)} \leftarrow \Delta_i^{(m+1)} - \lambda_l^{(m)}\)&lt;/span&gt; and &lt;span class="math"&gt;\(\Delta_j^{(m+1)} \leftarrow \Delta_i^{(m+1)} + \lambda_l^{(m)}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\lambda_l^{(m+1)} = \text{project}(- \frac{1}{2}(\Delta_i^{(m+1)} - \Delta_j^{(m+1)} + x_{i} - x_{j}),
                                       \{ \lambda : ||\lambda||_{p^{*}} \le \gamma w_l \}\)&lt;/span&gt;)&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\Delta_i^{(m+1)} \leftarrow \Delta_i^{(m+1)} + \lambda_l^{(m+1)}\)&lt;/span&gt; and &lt;span class="math"&gt;\(\Delta_j^{(m+1)} \leftarrow \Delta_j^{(m+1)} - \lambda_l^{(m+1)}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Return &lt;span class="math"&gt;\(u_i = \Delta_i + x_i\)&lt;/span&gt; for all &lt;span class="math"&gt;\(i\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;p&gt;Since we can easily construct the primal variables from the dual variables
and can evaluate the primal and dual functions in closed form, we can use the
duality gap to determine when we are converged.&lt;/p&gt;
&lt;h1&gt;&lt;a name="conclusion" href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;In this post, I introduced a coordinate ascent algorithm for convex
clustering. Empirically, the algorithm is quite quick, but it doesn't share the
parallelizability or convergence proofs of its siblings, ADMM and AMA. However,
coordinate descent has an upside: there are no parameters to tune, and every
iteration is guaranteed to improve the objective function. Within each
iteration, updates are quick asymptotically and empirically.&lt;/p&gt;
&lt;p&gt;Unfortunately, like all algorithms based on the dual for this particular
problem, the biggest burden is on memory. Whereas the primal formulation
requires the number of variables grow linearly with the number of data points,
the dual formulation can grow as high as quadratically. In addition, the primal
variables allow for centers to be merged, allowing for potential space-savings
as the algorithm is running. The dual seems to lack this property, requiring
all dual variables to be fully instantiated.&lt;/p&gt;
&lt;h1&gt;&lt;a name="references" href="#references"&gt;References&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;The original formulation for convex clustering was introduced by &lt;a href="http://www.control.isy.liu.se/research/reports/2011/2992.pdf"&gt;Lindsten et
al.&lt;/a&gt; and &lt;a href="http://www.icml-2011.org/papers/419_icmlpaper.pdf"&gt;Hocking et al.&lt;/a&gt;. &lt;a href="http://arxiv.org/abs/1304.0499"&gt;Chi et al.&lt;/a&gt; introduced
ADMM and AMA-based algorithms specifically designed for convex clustering.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="optimization"></category><category term="optimization"></category><category term="coordinate-descent"></category><category term="clustering"></category></entry><entry><title>Why does L1 produce sparse solutions?</title><link href="https://stronglyconvex.com/blog/l1-sparsity.html" rel="alternate"></link><published>2013-04-22T00:00:00-07:00</published><updated>2013-04-22T00:00:00-07:00</updated><author><name>Daniel Duckworth</name></author><id>tag:stronglyconvex.com,2013-04-22:/blog/l1-sparsity.html</id><summary type="html">&lt;p&gt;Supervised machine learning problems are typically of the form "minimize your
error while regularizing your parameters." The idea is that while many choices
of parameters may make your training error low, the goal isn't low training
error -- it's low test-time error. Thus, parameters should be minimize training
error while remaining …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Supervised machine learning problems are typically of the form "minimize your
error while regularizing your parameters." The idea is that while many choices
of parameters may make your training error low, the goal isn't low training
error -- it's low test-time error. Thus, parameters should be minimize training
error while remaining "simple," where the definition of "simple" is left up to
the regularization function. Typically, supervised learning can be phrased as
minimizing the following objective function,&lt;/p&gt;
&lt;div class="math"&gt;$$
  w^{*} = \arg\min_{w} \sum_{i} L(y_i, f(x_i; w)) + \lambda \Omega(w)
$$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(L(y_i, f(x_i; w))\)&lt;/span&gt; is the loss for predicting &lt;span class="math"&gt;\(f(x_i; w)\)&lt;/span&gt; when the
true label is for sample &lt;span class="math"&gt;\(i\)&lt;/span&gt; is &lt;span class="math"&gt;\(y_i\)&lt;/span&gt; and &lt;span class="math"&gt;\(\Omega(w)\)&lt;/span&gt; is a regularization
function.&lt;/p&gt;
&lt;h1&gt;&lt;a name="sparsifying-regularizers" href="#sparsifying-regularizers"&gt;Sparsifying Regularizers&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;There are many choices for &lt;span class="math"&gt;\(\Omega(w)\)&lt;/span&gt;, but the ones I'm going to talk about
today are so called "sparsifying regularizers" such as &lt;span class="math"&gt;\(||w||_1\)&lt;/span&gt;. These norms
are most often employed because they produce "sparse" &lt;span class="math"&gt;\(w^{*}\)&lt;/span&gt; -- that is,
&lt;span class="math"&gt;\(w^{*}\)&lt;/span&gt; with many zeros. This is in stark contrast to other regularizers such
as &lt;span class="math"&gt;\(\frac{1}{2}||w||_2^2\)&lt;/span&gt; which leads to lots of small but nonzero entries in
&lt;span class="math"&gt;\(w^{*}\)&lt;/span&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a name="why-sparse-solutions" href="#why-sparse-solutions"&gt;Why Sparse Solutions?&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Feature Selection&lt;/strong&gt; One of the key reasons people turn to sparsifying
regularizers is that they lead to automatic feature selection. Quite often,
many of the entries of &lt;span class="math"&gt;\(x_i\)&lt;/span&gt; are irrelevant or uninformative to predicting
the output &lt;span class="math"&gt;\(y_i\)&lt;/span&gt;. Minimizing the objective function using these extra
features will lead to lower training error, but when the learned &lt;span class="math"&gt;\(w^{*}\)&lt;/span&gt; is
employed at test-time it will depend on these features to be more informative
than they are. By employing a sparsifying regularizer, the hope is that these
features will automatically be eliminated.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Interpretability&lt;/strong&gt; A second reason for favoring sparse solutions is that
the model is easier to interpret. For example, a simple sentiment classifier
might use a binary vector where an entry is 1 if a word is present and 0
otherwise. If the resulting learned weights &lt;span class="math"&gt;\(w^{*}\)&lt;/span&gt; has only a few non-zero
entries, we might believe that those are the most indicative words in deciding
sentiment.&lt;/p&gt;
&lt;h1&gt;&lt;a name="nonsmooth-regularizers" href="#nonsmooth-regularizers"&gt;Non-smooth Regularizers and their Solutions&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;We now come to the \&lt;span class="math"&gt;\( 100 million question: why do regularizers like the 1-norm
lead to sparse solutions? At some point someone probably told you "they're our
best convex approximation to $\ell_0\)&lt;/span&gt; norm," but there's a better reason than
that.  In fact, I claim that any regularizer that is non-differentiable at &lt;span class="math"&gt;\(w_i
= 0\)&lt;/span&gt; and can be decomposed into a sum can lead to sparse solutions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Intuition&lt;/strong&gt; The intuition lies in the idea of subgradients. Recall that the
subgradient of a (convex) function &lt;span class="math"&gt;\(\Omega\)&lt;/span&gt; at &lt;span class="math"&gt;\(x\)&lt;/span&gt; is any vector &lt;span class="math"&gt;\(v\)&lt;/span&gt; such that,&lt;/p&gt;
&lt;div class="math"&gt;$$
  \Omega(y) \ge \Omega(x) + v^T (y-x)
$$&lt;/div&gt;
&lt;p&gt;The set of all subgradients for &lt;span class="math"&gt;\(\Omega\)&lt;/span&gt; at &lt;span class="math"&gt;\(x\)&lt;/span&gt; is called the subdifferential
and is denoted &lt;span class="math"&gt;\(\partial \Omega(x)\)&lt;/span&gt;. If &lt;span class="math"&gt;\(\Omega\)&lt;/span&gt; is differentiable at &lt;span class="math"&gt;\(x\)&lt;/span&gt;,
then &lt;span class="math"&gt;\(\partial \Omega(x) = \{ \nabla \Omega(x) \}\)&lt;/span&gt; -- in other words,
&lt;span class="math"&gt;\(\partial \Omega(x)\)&lt;/span&gt; contains 1 vector, the gradient. Where the
subdifferential begins to matter is when &lt;span class="math"&gt;\(\Omega\)&lt;/span&gt; &lt;em&gt;isn't&lt;/em&gt; differentiable at
&lt;span class="math"&gt;\(x\)&lt;/span&gt;. Then, it becomes something more interesting.&lt;/p&gt;
&lt;p&gt;Suppose we want to minimize an unconstrained objective like the following,&lt;/p&gt;
&lt;div class="math"&gt;$$
  \min_{x} f(x) + \lambda \Omega(x)
$$&lt;/div&gt;
&lt;p&gt;By the &lt;a href="http://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions"&gt;KKT conditions&lt;/a&gt;, 0 must be in the subdifferential at
the minimizer &lt;span class="math"&gt;\(x^{*}\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  0 &amp;amp; \in \nabla f(x^{*}) + \partial \lambda \Omega(x^{*}) \\
  - \frac{1}{\lambda} \nabla f(x^{*}) &amp;amp; \in \partial \Omega(x^{*}) \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Looking forward, we're particularly interested in when the previous
inequality holds when &lt;span class="math"&gt;\(x^{*} = 0\)&lt;/span&gt;. What conditions are necessary for this to be
true?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dual Norms&lt;/strong&gt; Since we're primarily concerned with &lt;span class="math"&gt;\(\Omega(x) = ||x||_1\)&lt;/span&gt;,
let's plug that in. In the following, it'll actually be easier to prove things
about any norm, so we'll drop the 1 for the rest of this section.&lt;/p&gt;
&lt;p&gt;Recal the definition of a dual norm. In particular, the dual norm of a norm
&lt;span class="math"&gt;\(||\cdot||\)&lt;/span&gt; is defined as,&lt;/p&gt;
&lt;div class="math"&gt;$$
  ||y||_{*} = \sup_{||x|| \le 1} x^{T} y
$$&lt;/div&gt;
&lt;p&gt;A cool fact is that the dual of a dual norm is the original norm. In other words,&lt;/p&gt;
&lt;div class="math"&gt;$$
  ||x|| = \sup_{||y||_{*} \le 1} y^{T} x
$$&lt;/div&gt;
&lt;p&gt;Let's take the gradient of the previous expression on both sides. A nice fact
to keep in mind is that if we take the gradient of an expression of the form
&lt;span class="math"&gt;\(\sup_{y} g(y, x)\)&lt;/span&gt;, then its gradient with respect to x is &lt;span class="math"&gt;\(\nabla_x g(y^{*},
x)\)&lt;/span&gt; where &lt;span class="math"&gt;\(y^{*}\)&lt;/span&gt; is any &lt;span class="math"&gt;\(y\)&lt;/span&gt; that achieves the &lt;span class="math"&gt;\(\sup\)&lt;/span&gt;. Since &lt;span class="math"&gt;\(g(y, x) = y^{T}
x\)&lt;/span&gt;, that means,&lt;/p&gt;
&lt;div class="math"&gt;$$
  \nabla_x \sup_{y} g(y, x) = \nabla_x \left( (y^{*})^T x \right) = y^{*} = \arg\max_{||y||_{*} \le 1} y^{T} x
$$&lt;/div&gt;
&lt;div class="math"&gt;$$
  \partial ||x|| = \{ y^{*} :  y^{*} = \arg\max_{||y||_{*} \le 1} y^{T} x \}
$$&lt;/div&gt;
&lt;p&gt;Now let &lt;span class="math"&gt;\(x = 0\)&lt;/span&gt;. Then &lt;span class="math"&gt;\(y^{T} x = 0\)&lt;/span&gt; for all &lt;span class="math"&gt;\(y\)&lt;/span&gt;, so any &lt;span class="math"&gt;\(y\)&lt;/span&gt; with &lt;span class="math"&gt;\(||y||_{*}
\le 1\)&lt;/span&gt; is in &lt;span class="math"&gt;\(\partial ||x||\)&lt;/span&gt; for &lt;span class="math"&gt;\(x = 0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Back to our original goal, recall that&lt;/p&gt;
&lt;div class="math"&gt;$$
  -\frac{1}{\lambda} \nabla f(x) \in \partial ||x||
$$&lt;/div&gt;
&lt;p&gt;If &lt;span class="math"&gt;\(||-\frac{1}{\lambda} \nabla f(x)||_{*} \le 1\)&lt;/span&gt; when &lt;span class="math"&gt;\(x=0\)&lt;/span&gt;, then we've
already established that &lt;span class="math"&gt;\(-\frac{1}{\lambda} \nabla f(0)\)&lt;/span&gt; is in &lt;span class="math"&gt;\(\partial
||0||\)&lt;/span&gt;. In other words, &lt;span class="math"&gt;\(x^{*} = 0\)&lt;/span&gt; solves the original problem!&lt;/p&gt;
&lt;h1&gt;&lt;a name="coordinate-sparsity" href="#coordinate-sparsity"&gt;Onto Coordinate-wise Sparsity&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;We've just established that &lt;span class="math"&gt;\(||\frac{1}{\lambda} \nabla f(0)||_{*} \le 1\)&lt;/span&gt;
implies &lt;span class="math"&gt;\(x^{*} = 0\)&lt;/span&gt;, but we don't want all of &lt;span class="math"&gt;\(x^{*}\)&lt;/span&gt; to be 0, we want &lt;em&gt;some
coordinates&lt;/em&gt; of &lt;span class="math"&gt;\(x^{*}\)&lt;/span&gt; to be 0. How can we take what we just concluded and
apply it only a subvector of &lt;span class="math"&gt;\(x^{*}\)&lt;/span&gt;?&lt;/p&gt;
&lt;p&gt;Rather than a general norm, let's return once again to the &lt;span class="math"&gt;\(L_1\)&lt;/span&gt; norm. The
&lt;span class="math"&gt;\(L_1\)&lt;/span&gt; norm has a very special property that will be of use here:
separability. In words, this means that the &lt;span class="math"&gt;\(L_1\)&lt;/span&gt; norm can be expressed as a
sum of functions over &lt;span class="math"&gt;\(x\)&lt;/span&gt;'s individual coordinates, each independent of every
other. In particular, &lt;span class="math"&gt;\(||x||_1 = \sum_{i} |x_{i}|\)&lt;/span&gt;.  It's easy to see that the
function &lt;span class="math"&gt;\(\Omega_i(x) = |x_i|\)&lt;/span&gt; is independent of the rest of &lt;span class="math"&gt;\(x\)&lt;/span&gt;'s elements.&lt;/p&gt;
&lt;p&gt;Let's take another look at our objective function,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \min_{x} f(x) + \lambda ||x||_1
  &amp;amp; = \min_{x_i} \left( \min_{x_{-i}} f(x_i, x_{-i}) + \lambda \sum_{j} |x_j| \right) \\
  &amp;amp; = \min_{x_i} g(x_i) + \lambda |x_i|
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(x_{-i}\)&lt;/span&gt; is all coordinates of &lt;span class="math"&gt;\(x\)&lt;/span&gt; except &lt;span class="math"&gt;\(x_i\)&lt;/span&gt; and &lt;span class="math"&gt;\(g(x_i) =
\min_{x_{-i}} f(x_i, x_{-i}) + \lambda \sum_{j \ne i} |x_j|\)&lt;/span&gt;. Taking the
derivative of &lt;span class="math"&gt;\(g(x_i)\)&lt;/span&gt; with respect to &lt;span class="math"&gt;\(x_i\)&lt;/span&gt;, we again require that,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  0 &amp;amp;\in \nabla_{x_i} g(x_i) + \lambda \partial |x_i| \\
  -\frac{1}{\lambda} \nabla_{x_i} g(x_i) &amp;amp; \in \partial |x_i| \\
  -\frac{1}{\lambda} \nabla_{x_i} f(x_i, x_{-i}^{*}) &amp;amp; \in \partial |x_i|
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Hmm, that looks familiar. And isn't &lt;span class="math"&gt;\(|x_i| = ||x_i||_1\)&lt;/span&gt;? That means that if&lt;/p&gt;
&lt;div class="math"&gt;$$
  \left| \left| \frac{1}{\lambda} \nabla_{x_i} f(x_i, x_{-i}^{*}) \right| \right|_{\infty}
  = \left| \frac{1}{\lambda} \nabla_{x_i} f(x_i, x_{-i}^{*}) \right| \le 1
$$&lt;/div&gt;
&lt;p&gt;when &lt;span class="math"&gt;\(x_i = 0\)&lt;/span&gt;, then &lt;span class="math"&gt;\(x_i^{*} = 0\)&lt;/span&gt;. In other words, given the optimal values
for all coordinates other than &lt;span class="math"&gt;\(i\)&lt;/span&gt;, we can evaluate the derivative of
&lt;span class="math"&gt;\(\frac{1}{\lambda} f\)&lt;/span&gt; with respect to &lt;span class="math"&gt;\(x_i\)&lt;/span&gt; and check if the absolute value
of that is less than 1. If it is, then &lt;span class="math"&gt;\(x_i = 0\)&lt;/span&gt; is optimal!&lt;/p&gt;
&lt;h1&gt;&lt;a name="conclusion" href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;In the first section, we showed that in order to solve the problem
&lt;span class="math"&gt;\(\min_{x} f(x) + \lambda \Omega(x)\)&lt;/span&gt;, it is necessary that &lt;span class="math"&gt;\(-\frac{1}{\lambda}
\nabla f(x^{*}) \in \partial \Omega(x^{*})\)&lt;/span&gt;. If &lt;span class="math"&gt;\(\Omega(x^{*})\)&lt;/span&gt; is
differentiable at &lt;span class="math"&gt;\(x^{*}\)&lt;/span&gt;, then there can be only 1 possible choice for
&lt;span class="math"&gt;\(x^{*}\)&lt;/span&gt;, but in all other cases there are a multitude of potential solutions.
When &lt;span class="math"&gt;\(\Omega(x)\)&lt;/span&gt; isn't differentiable at &lt;span class="math"&gt;\(x = 0\)&lt;/span&gt;, there is a non-singleton set
of values which &lt;span class="math"&gt;\(-\frac{1}{\lambda} \nabla f(x^{*})\)&lt;/span&gt; can be in such that &lt;span class="math"&gt;\(x^{*}
= 0\)&lt;/span&gt; is an optimal solution. If &lt;span class="math"&gt;\(\Omega(x) = ||x||\)&lt;/span&gt;, then a sufficient
condition for &lt;span class="math"&gt;\(x^{*} = 0\)&lt;/span&gt; to be optimal is &lt;span class="math"&gt;\(||\frac{1}{\lambda} \nabla
f(x)||_{*} \le 1\)&lt;/span&gt; at &lt;span class="math"&gt;\(x = 0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In the next section, we showed that in the special case of the &lt;span class="math"&gt;\(L_1\)&lt;/span&gt; norm, we
can express the norm as the sum of &lt;span class="math"&gt;\(L_1\)&lt;/span&gt; norms applied to &lt;span class="math"&gt;\(x\)&lt;/span&gt;'s individual
coordinates. Because of this, we can rewrite the original optimization problem
as &lt;span class="math"&gt;\(\min_{x_i} g(x_i) + \lambda ||x_i||_1\)&lt;/span&gt; where &lt;span class="math"&gt;\(g(x_i) = \min_{x_{-i}} f(x_i,
x_{-i}) + \lambda ||x_{-i}||_1\)&lt;/span&gt;. Using the same results from the previous
section, we showed that as long as &lt;span class="math"&gt;\(|\frac{1}{\lambda} \nabla_{x_i} f(x_i,
x_{-i}^{*})| \le 1\)&lt;/span&gt; when &lt;span class="math"&gt;\(x_i = 0\)&lt;/span&gt;, then &lt;span class="math"&gt;\(x_i^{*} = 0\)&lt;/span&gt; is an optimal choice. In
other words, we established conditions upon which a coordinate will be 0. This
is why the &lt;span class="math"&gt;\(L_1\)&lt;/span&gt; norm causes sparsity.&lt;/p&gt;
&lt;h1&gt;&lt;a name="references" href="#references"&gt;References&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Everything written here was explained to me by the ever-knowledgable
MetaOptimize king, &lt;a href="https://twitter.com/atpassos"&gt;Alexandre Passos&lt;/a&gt;.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="optimization"></category><category term="optimization"></category><category term="sparsity"></category></entry><entry><title>Proximal Gradient Descent</title><link href="https://stronglyconvex.com/blog/proximal-gradient-descent.html" rel="alternate"></link><published>2013-04-19T00:00:00-07:00</published><updated>2013-04-19T00:00:00-07:00</updated><author><name>Daniel Duckworth</name></author><id>tag:stronglyconvex.com,2013-04-19:/blog/proximal-gradient-descent.html</id><summary type="html">&lt;p&gt;&lt;span class="math"&gt;\( \def\prox{\text{prox}} $
  In a [previous post][subgradient_descent_usage], I mentioned that one cannot
hope to asymptotically outperform the $O(\frac{1}{\epsilon^2})\)&lt;/span&gt; convergence
rate of Subgradient Descent when dealing with a non-differentiable objective
function. This is in fact only half-true; Subgradient Descent cannot be beat
&lt;em&gt;using only first-order …&lt;/em&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;span class="math"&gt;\( \def\prox{\text{prox}} $
  In a [previous post][subgradient_descent_usage], I mentioned that one cannot
hope to asymptotically outperform the $O(\frac{1}{\epsilon^2})\)&lt;/span&gt; convergence
rate of Subgradient Descent when dealing with a non-differentiable objective
function. This is in fact only half-true; Subgradient Descent cannot be beat
&lt;em&gt;using only first-order information&lt;/em&gt; (that is, gradients and subgradients).
In this article, I'll describe Proximal Gradient Descent, an algorithm that
exploits problem structure to obtain a rate of &lt;span class="math"&gt;\(O(\frac{1}{\epsilon})\)&lt;/span&gt;. In
particular, Proximal Gradient is useful if the following 2 assumptions hold.
First, the objective function must be of the form,&lt;/p&gt;
&lt;div class="math"&gt;$$
  \min_{x} \, g(x) + h(x)
$$&lt;/div&gt;
&lt;p&gt;with &lt;span class="math"&gt;\(g\)&lt;/span&gt; is differentiable. Second &lt;span class="math"&gt;\(h\)&lt;/span&gt; must be "simple" enough such that we
can calculate its &lt;span class="math"&gt;\(\prox\)&lt;/span&gt; operator very quickly,&lt;/p&gt;
&lt;div class="math"&gt;$$
  \prox_{h}(x) = \min_{u} h(u) + \frac{1}{2} ||u-x||_2^2
$$&lt;/div&gt;
&lt;p&gt;Using these two assumptions, we can obtain a convergence rate identical to
Gradient Descent even when optimizing non-differentiable objective functions.&lt;/p&gt;
&lt;h1&gt;&lt;a name="implementation" href="#implementation"&gt;How does it work?&lt;/a&gt;&lt;/h1&gt;
&lt;div class="pseudocode"&gt;
&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt;: initial iterate &lt;span class="math"&gt;\(x^{(0)}\)&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;For &lt;span class="math"&gt;\(t = 0, 1, 2, \ldots\)&lt;/span&gt;&lt;ol&gt;
&lt;li&gt;Let &lt;span class="math"&gt;\(x^{(t+1)} = \prox_{ \alpha^{(t)} h } \left( x^{(t)} - \alpha^{(t)} \nabla g(x^{(t)}) \right)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;if converged, return &lt;span class="math"&gt;\(x^{(t+1)}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;p&gt;&lt;a id="intuition"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a name="intuition" href="#intuition"&gt;Intuition for the &lt;span class="math"&gt;\(\prox\)&lt;/span&gt; Operator&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;At first sight, the &lt;span class="math"&gt;\(\prox\)&lt;/span&gt; operator looks suspicious.  Where did it come
from? Why did someone really think it would work?  It ends up that we can
derive the update for Gradient Descent and the update for Gradient Descent
almost identically. First, notice that the Gradient Descent Update is the
solution to the following quadratic approximation to &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  x^{(t+1)} &amp;amp; = \arg\min_{y} f(x^{(t)}) + \nabla f(x^{(t)})^T (y-x^{(t)}) + \frac{L}{2} ||y-x^{(t)}||_2^2 \\
  0     &amp;amp; = \nabla f(x^{(t)}) + L (x^{(t+1)}-x^{(t)}) \\
  x^{(t+1)} &amp;amp; = x^{(t)} - \frac{1}{L} \nabla f(x^{(t)})
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;We take the gradient of the right hand side with respect to &lt;span class="math"&gt;\(y\)&lt;/span&gt; and set it to
zero in the second line.  Now replace &lt;span class="math"&gt;\(f\)&lt;/span&gt; with &lt;span class="math"&gt;\(g\)&lt;/span&gt;, and add &lt;span class="math"&gt;\(h(y)\)&lt;/span&gt; to the
very end of the first line,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  x^{(t+1)}
  &amp;amp; = \arg\min_{y} g(x^{(t)}) + \nabla g(x^{(t)})^T (y-x^{(t)}) + \frac{L}{2} ||y-x^{(t)}||_2^2 + h(y) \\
  &amp;amp; = \arg\min_{y} g(x^{(t)}) + \frac{L}{2} \left( \frac{2}{L} \nabla g(x^{(t)})^T (y-x^{(t)}) \right) + \frac{L}{2} ||y-x^{(t)}||_2^2 + h(y) + \frac{L}{2} ||\nabla g(x^{(t)})||_2^2 \\
  &amp;amp; = \arg\min_{y} \frac{L}{2} || y - (x^{(t)} - \frac{1}{L} \nabla g(x^{(t)})) ||_2^2 + h(y) \\
  &amp;amp; = \prox_{ \frac{1}{L} h }(x^{(t)} - \frac{1}{L} \nabla g(x^{(t)})) \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;This time, we add constants (with respect to &lt;span class="math"&gt;\(y\)&lt;/span&gt;) such that we can pull the
&lt;span class="math"&gt;\(\nabla g(x^{(t)})^T (y-x^{(t)})\)&lt;/span&gt; into the quadratic term, leading us to the
Proximal Gradient Descent update.&lt;/p&gt;
&lt;h1&gt;&lt;a name="example" href="#example"&gt;A Small Example&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Let's now see how well Proximal Gradient Descent works.  For this example,
we'll solve the following problem,&lt;/p&gt;
&lt;div class="math"&gt;$$
  \min_{x} \, \log(1 + \exp(-2x)) + ||x||_1
$$&lt;/div&gt;
&lt;p&gt;Letting &lt;span class="math"&gt;\(g(x) = \log(1+\exp(-2x))\)&lt;/span&gt; and &lt;span class="math"&gt;\(h(x) = ||x||_1\)&lt;/span&gt;, it can be shown
that,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \nabla g(x) &amp;amp;= \frac{1}{1 + \exp(-2x)} \left( \exp(-2x) \right) (-2) \\
  \prox_{\alpha h}(x) &amp;amp; = \text{sign}(x) \max(0, \text{abs}(x) - \alpha) \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;We'll use a variant of &lt;a href="#line_search"&gt;Backtracking Line Search&lt;/a&gt; modified for
Proximal Gradient Descent and an initial choice of &lt;span class="math"&gt;\(x^{(0)} = 5\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="img-center"&gt;
  &lt;img src="/assets/img/proximal_gradient_descent/convergence.png"&gt;&lt;/img&gt;
  &lt;span class="caption"&gt;
    This plot shows how quickly the objective function decreases as the
    number of iterations increases.
  &lt;/span&gt;
&lt;/div&gt;

&lt;div class="img-center"&gt;
  &lt;img src="/assets/img/proximal_gradient_descent/iterates.png"&gt;&lt;/img&gt;
  &lt;span class="caption"&gt;
    This plot shows the actual iterates and the objective function evaluated at
    those points. More red indicates a higher iteration number.
  &lt;/span&gt;
&lt;/div&gt;

&lt;h1&gt;&lt;a name="proof" href="#proof"&gt;Why does it work?&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Proximal Gradient Descent, like regular Gradient Descent, is a "descent"
method where the objective value is guaranteed to decrease. In fact, the
assumptions for Proximal Gradient Descent's &lt;span class="math"&gt;\(g(x)\)&lt;/span&gt; are the identical to the
Gradient Descent assumptions for &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt;. The only additional condition is
that &lt;span class="math"&gt;\(h(x)\)&lt;/span&gt; be convex,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;span class="math"&gt;\(g(x)\)&lt;/span&gt; is convex, differentiable, and finite for all &lt;span class="math"&gt;\(x\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;a finite solution &lt;span class="math"&gt;\(x^{*}\)&lt;/span&gt; exists&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\nabla g(x)\)&lt;/span&gt; is Lipschitz continuous with constant &lt;span class="math"&gt;\(L\)&lt;/span&gt;. That is, there must
   be an &lt;span class="math"&gt;\(L\)&lt;/span&gt; such that,&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="math"&gt;$$
  || \nabla g(x) - \nabla g(y) ||_2 \le L || x - y ||_2 \qquad \forall x,y
$$&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;&lt;span class="math"&gt;\(h(x)\)&lt;/span&gt; is convex&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Proof Outline&lt;/strong&gt; The majority of the convergence proof for Proximal Gradient
Descent is identical to the proof for regular Gradient Descent. The key is to
carefully choose a function &lt;span class="math"&gt;\(G_{\alpha}(x)\)&lt;/span&gt; that can take the place of &lt;span class="math"&gt;\(\nabla
f(x)\)&lt;/span&gt;.  Once it is defined, we can rephrase Proximal Gradient Descent as
&lt;span class="math"&gt;\(x^{(t+1)} = x^{(t)} - \alpha^{(t)} G_{\alpha^{(t)}}(x^{(t)})\)&lt;/span&gt;. Next, we'll
show that,&lt;/p&gt;
&lt;div class="math"&gt;$$
  (g+h)(x^{(t+1)}) \le (g+h)(x^{*}) + G_{\alpha^{(t)}}(x^{(t)})^T (x-x^{*}) - \frac{\alpha^{(t)}}{2} ||G_{\alpha^{(t)}}(x^{(t)})||_2^2
$$&lt;/div&gt;
&lt;p&gt;Once we have this, we can repeat the Gradient Descent proof verbatim with &lt;span class="math"&gt;\(g
+ h \rightarrow f\)&lt;/span&gt; and &lt;span class="math"&gt;\(G_{\alpha^{(t)}}(x^{(t)}) \rightarrow \nabla
  f(x^{(t)})\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1&lt;/strong&gt; Phrase Proximal Gradient Descent as &lt;span class="math"&gt;\(x^{(t+1)} = x^{(t)} - \alpha^{(t)} G_{\alpha^{(t)}}(x^{(t)})\)&lt;/span&gt;. Define &lt;span class="math"&gt;\(G\)&lt;/span&gt;
as follows,&lt;/p&gt;
&lt;div class="math"&gt;$$
  G_{\alpha}(x) \triangleq \frac{1}{\alpha} (x - \prox_{\alpha h}( x - \alpha \nabla g(x)))
$$&lt;/div&gt;
&lt;p&gt;Now let &lt;span class="math"&gt;\(x^{+} \triangleq x^{(t+1)}\)&lt;/span&gt;, &lt;span class="math"&gt;\(x \triangleq x^{(t)}\)&lt;/span&gt;, and &lt;span class="math"&gt;\(\alpha
\triangleq \alpha^{(t)}\)&lt;/span&gt;. Using &lt;span class="math"&gt;\(G\)&lt;/span&gt;, we can reframe Proximal Gradient Descent
as a typical descent method,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  x^{+}
  &amp;amp;= x - \alpha G_{\alpha}(x) \\
  &amp;amp;= x - \alpha \left(
      \frac{1}{\alpha} (x - \prox_{\alpha h}( x - \alpha \nabla g(x))
    \right) \\
  &amp;amp;= x - (x - \prox_{\alpha h}( x - \alpha \nabla g(x)) \\
  &amp;amp;= \prox_{\alpha h}( x - \alpha \nabla g(x)) \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Step 2&lt;/strong&gt; Show that &lt;span class="math"&gt;\(G_{\alpha}(x)\)&lt;/span&gt; can be used like Gradient
Descent's &lt;span class="math"&gt;\(\nabla f(x)\)&lt;/span&gt;. Our goals is to obtain a statement identical to
&lt;span class="math"&gt;\(f(x^{+}) \le f(x^{*}) + \nabla f(x)^T (x-x^{*}) - \frac{\alpha}{2} ||\nabla
f(x)||_2^2\)&lt;/span&gt; except with &lt;span class="math"&gt;\(G_{\alpha}(x)\)&lt;/span&gt; instead of &lt;span class="math"&gt;\(\nabla f(x)\)&lt;/span&gt;.  Once we
have this, the rest of the proof is exactly the same as Gradient Descent's.
Begin by recalling the Lipschitz condition on &lt;span class="math"&gt;\(g\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
  g(y) \le g(x) + \nabla g(x)^T (y-x) + \frac{L}{2} ||y-x||_2^2
$$&lt;/div&gt;
&lt;p&gt;Substitute &lt;span class="math"&gt;\(y = x^{+} = x - \alpha G_{\alpha}(x)\)&lt;/span&gt; to obtain,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  g(x - \alpha G_{\alpha}(x))
  &amp;amp; \le g(x) + \nabla g(x)^T(x - \alpha G_{\alpha}(x) - x) + \frac{L}{2}||x - \alpha G_{\alpha}(x) - x||_2^2 \\
  &amp;amp; = g(x) - \alpha \nabla g(x)^T G_{\alpha}(x) + \frac{L ( \alpha )^2}{2}||G_{\alpha}(x)||_2^2 \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Assume then that &lt;span class="math"&gt;\(\alpha \le \frac{1}{L}\)&lt;/span&gt; (this is what Backtracking Line
Search does), We can upper bound &lt;span class="math"&gt;\(\frac{L ( \alpha )^2}{2} \le
\frac{\alpha}{2}\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  g(x - \alpha G_{\alpha}(x))
  &amp;amp; \le g(x) - \alpha \nabla g(x)^T G_{\alpha}(x) + \frac{ \alpha }{2}||G_{\alpha}(x)||_2^2 \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Then add &lt;span class="math"&gt;\(h(x - \alpha G_{\alpha}(x))\)&lt;/span&gt; to both sides,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  (g+h)(x - \alpha G_{\alpha}(x))
  &amp;amp; \le g(x) - \alpha \nabla g(x)^T G_{\alpha}(x) + \frac{ \alpha }{2}||G_{\alpha}(x)||_2^2 \\
  &amp;amp; \quad + h(x - \alpha G_{\alpha}(x)) \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Next, we'll upper bound &lt;span class="math"&gt;\(g(x)\)&lt;/span&gt; and &lt;span class="math"&gt;\(h(x - \alpha G_{\alpha}(x))\)&lt;/span&gt; using the definition of convexity. The following 2 equations hold for all &lt;span class="math"&gt;\(z\)&lt;/span&gt;, For &lt;span class="math"&gt;\(g\)&lt;/span&gt;, we'll use,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  g(z) &amp;amp; \ge g(x) + \nabla g(x)^T (z-x) \\
  g(z) + \nabla g(x)^T (x-z) &amp;amp; \ge g(x) \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;For &lt;span class="math"&gt;\(h\)&lt;/span&gt; we have something a bit more mysterious,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  h(z)
  &amp;amp; \ge h(x - \alpha G_{\alpha}(x)) + [G_{\alpha}(x) - \nabla g(x)]^T (z-(x - \alpha G_{\alpha}(x))) \\
  h(z) + [G_{\alpha}(x) - \nabla g(x)]^T(x - \alpha G_{\alpha}(x) - z)
  &amp;amp; \ge h(x - \alpha G_{\alpha}(x))
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Where did that come from? It so happens that &lt;span class="math"&gt;\(G_{\alpha}(x) - \nabla
g(x)\)&lt;/span&gt; is a valid subgradient for &lt;span class="math"&gt;\(h\)&lt;/span&gt; at &lt;span class="math"&gt;\(x - \alpha G_{\alpha}(x)\)&lt;/span&gt;.
Recall the 2 definitions we have for &lt;span class="math"&gt;\(x^{+}\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  x^{+}
  &amp;amp;= \prox_{\alpha h} (x - \alpha \nabla g(x)) \\
  &amp;amp;= \arg\min_{u} \alpha h(u) + \frac{1}{2} ||u - (x - \alpha \nabla g(x))||_2^2 \\
  0
  &amp;amp; \in \alpha \partial h(x^{+}) + x^{+} - (x - \alpha \nabla g(x)) \\
  (x - \alpha \nabla g(x)) - x^{+}
  &amp;amp; \in \alpha \partial h(x^{+}) \\
  (x - \alpha \nabla g(x)) - (x - \alpha G_{\alpha}(x))
  &amp;amp; \in \alpha \partial h(x^{+}) \\
  \alpha [G_{\alpha}(x)) - \nabla g(x)]
  &amp;amp; \in \alpha \partial h(x^{+}) \\
  [G_{\alpha}(x)) - \nabla g(x)]
  &amp;amp; \in \partial h(x^{+}) \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Thus, &lt;span class="math"&gt;\(G_{\alpha}(x)) - \nabla g(x)\)&lt;/span&gt; is a valid subgradient for &lt;span class="math"&gt;\(h\)&lt;/span&gt; at
&lt;span class="math"&gt;\(x^{+} \triangleq x - \alpha G_{\alpha}(x)\)&lt;/span&gt;, and the previous lower
bound on &lt;span class="math"&gt;\(h(z)\)&lt;/span&gt; holds.  Putting the previous two inequalities back into the
preceding equation and canceling out, we can see that for all &lt;span class="math"&gt;\(z\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  (g+h)(x - \alpha G_{\alpha}(x))
  &amp;amp; \le g(x) - \alpha \nabla g(x)^T G_{\alpha}(x) + \frac{ \alpha }{2}||G_{\alpha}(x)||_2^2 \\
  &amp;amp; \quad + h(x - \alpha G_{\alpha}(x)) \\
  (g+h)(x - \alpha G_{\alpha}(x))
  &amp;amp; \le \left( g(z) + \nabla g(z)^T (x-z) \right) - \alpha \nabla g(x)^T G_{\alpha}(x) + \frac{ \alpha }{2}||G_{\alpha}(x)||_2^2 \\
  &amp;amp; \quad + \left( h(z) + [G_{\alpha}(x) - \nabla g(x)]^T (x - \alpha G_{\alpha}(x) - z) \right) \\
  &amp;amp; = (g+h)(z) + G_{\alpha}(x)^T (x-z) - \frac{ \alpha }{2}||G_{\alpha}(x)||_2^2 \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Now let &lt;span class="math"&gt;\(z = x^{*}\)&lt;/span&gt; to get,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  (g+h)(x^{+})
  &amp;amp; \le (g+h)(x^{*}) + G_{\alpha}(x)^T (x-x^{*}) - \frac{ \alpha }{2}||G_{\alpha}(x)||_2^2 \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Looking back at Step 1 of the &lt;a href="/blog/gradient-descent.html#proof"&gt;Gradient Descent
Proof&lt;/a&gt;, you can see that this equation is exactly the
same as the one used before except that &lt;span class="math"&gt;\(G_{\alpha}(x)\)&lt;/span&gt; replaces &lt;span class="math"&gt;\(\nabla
f(x)\)&lt;/span&gt;. Following the rest of the Gradient Descent proof, we find that of we
want &lt;span class="math"&gt;\((g+h)(x^{(t)}) - (g+h)(x^{*}) \le \epsilon\)&lt;/span&gt;, we need
&lt;span class="math"&gt;\(O(\frac{1}{\epsilon})\)&lt;/span&gt; iterations, just like Gradient Descent.&lt;/p&gt;
&lt;h1&gt;&lt;a name="usage" href="#usage"&gt;When should I use it?&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Proximal Gradient Descent requires being able to easily calculate
&lt;span class="math"&gt;\(\prox_{\alpha h}(x)\)&lt;/span&gt;.  The benefits of doing so are clear -- we can reach an
&lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt;-approximate solution in far fewer iterations than Subgradient
Descent. But this is only valuable if the cost of an iteration of Proximal Gradient
Descent is similar to that of Subgradient Descent. For some choices of &lt;span class="math"&gt;\(h(x)\)&lt;/span&gt;,
this actually holds (see &lt;a href="#common_prox_functions"&gt;Common Prox Functions&lt;/a&gt;
below); it is then that Proximal Gradient Descent should be used. For other
cases where no closed-form solution exists, it is often better to stick with
Subgradient Descent.&lt;/p&gt;
&lt;h1&gt;&lt;a name="extensions" href="#extensions"&gt;Extensions&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;a id="line_search"&gt;&lt;/a&gt;
  &lt;strong&gt;Step Size&lt;/strong&gt; The proof above assumes the step size &lt;span class="math"&gt;\(\alpha^{(t)} \le
\frac{1}{L}\)&lt;/span&gt; (&lt;span class="math"&gt;\(L\)&lt;/span&gt; is the Lipschitz constant of &lt;span class="math"&gt;\(g(x)\)&lt;/span&gt;). Rather than guessing
for such values, Backtracking Line Search can be employed with a slight
modification. Recall that Backtracking Line Search chooses &lt;span class="math"&gt;\(\alpha^{(t)}\)&lt;/span&gt; such
that,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  f(x^{(t)} - \alpha^{(t)} \nabla f(x^{(t)}))
  &amp;amp; \le f(x^{(t)}) - \frac{\alpha^{(t)}}{2}|| \nabla f(x^{(t)})||_2^2 \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;If &lt;span class="math"&gt;\(\alpha^{(t)} \le \frac{1}{L}\)&lt;/span&gt;, this statement must hold. To see why, let's write out where the condition came from,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  f(x^{(t+1)})
  &amp;amp; \le f(x^{(t)}) + \nabla f(^{(t)})^T (x^{(t+1)} - x^{(t)}) + \frac{1}{2 \alpha^{(t)}}||x^{(t+1)} - x^{(t)}||_2^2 \\
  f(x^{(t)} - \alpha^{(t)} \nabla f(x^{(t)}))
  &amp;amp; \le f(x^{(t)}) + \nabla f(^{(t)})^T (x^{(t)} - \alpha^{(t)} \nabla f(x^{(t)}) - x^{(t)}) \\
  &amp;amp; \quad + \frac{1}{2 \alpha^{(t)}}||x^{(t)} - \alpha^{(t)} \nabla f(x^{(t)}) - x^{(t)}||_2^2 \\
  f(x^{(t)} - \alpha^{(t)} \nabla f(x^{(t)}))
  &amp;amp; \le f(x^{(t)}) - \alpha^{(t)} ||\nabla f(^{(t)}) ||_2^2 + \frac{\alpha^{(t)}}{2}|| \nabla f(x^{(t)})||_2^2 \\
  f(x^{(t)} - \alpha^{(t)} \nabla f(x^{(t)}))
  &amp;amp; \le f(x^{(t)}) - \frac{\alpha^{(t)}}{2}|| \nabla f(x^{(t)})||_2^2 \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;If we assume that &lt;span class="math"&gt;\(f\)&lt;/span&gt; is &lt;span class="math"&gt;\(L\)&lt;/span&gt;-Lipschitz, then &lt;span class="math"&gt;\(\alpha^{(t)} = \frac{1}{L}\)&lt;/span&gt; is
precisely the Lipschitz assumption. Recall now that for this problem, we have
&lt;span class="math"&gt;\(G_{\alpha^{(t)}}(x^{(t)})\)&lt;/span&gt; in place of &lt;span class="math"&gt;\(\nabla f(x^{(t)})\)&lt;/span&gt;. Replacing &lt;span class="math"&gt;\(f\)&lt;/span&gt; with
&lt;span class="math"&gt;\(g+h\)&lt;/span&gt; and &lt;span class="math"&gt;\(\nabla f(x)\)&lt;/span&gt; with &lt;span class="math"&gt;\(G_{\alpha}(x)\)&lt;/span&gt;, we come to a similar condition,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  (g+h)(x^{(t+1)})
  &amp;amp; \le (g+h)(x^{(t)}) - \frac{\alpha^{(t)}}{2}|| G_{\alpha^{(t)}}(x^{(t)}) ||_2^2 \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;In other words, we can perform Backtracking Line Search for Proximal Gradient Descent as follows,&lt;/p&gt;
&lt;div class="pseudocode"&gt;
&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt;: iterate &lt;span class="math"&gt;\(x^{(t)}\)&lt;/span&gt;, initial step size &lt;span class="math"&gt;\(\alpha_0\)&lt;/span&gt;, step factor &lt;span class="math"&gt;\(\beta\)&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\alpha = \alpha_0\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;While True&lt;ol&gt;
&lt;li&gt;Calculate &lt;span class="math"&gt;\(G_{\alpha}(x^{(t)}) = \frac{1}{\alpha}( x - \prox_{\alpha h}(x^{(t)} - \alpha \nabla g(x)) )\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;if &lt;span class="math"&gt;\((g+h)(x^{(t+1)}) \le (g+h)(x^{(t)}) - \frac{\alpha}{2}|| G_{\alpha}(x^{(t)}) ||_2^2\)&lt;/span&gt;, set &lt;span class="math"&gt;\(\alpha^{(t)} = \alpha\)&lt;/span&gt; and return&lt;/li&gt;
&lt;li&gt;otherwise set &lt;span class="math"&gt;\(\alpha \leftarrow \alpha \beta\)&lt;/span&gt; and continue&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;h1&gt;&lt;a name="common-prox" href="#common-prox"&gt;Common &lt;span class="math"&gt;\(\prox\)&lt;/span&gt; Functions&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;There are several common choices for &lt;span class="math"&gt;\(h(x)\)&lt;/span&gt; that admit particularly efficient
&lt;span class="math"&gt;\(\prox\)&lt;/span&gt; functions. If your objective function contains one of these, consider
applying Proximal Gradient immediately -- you'll converge far faster than
Subgradient Descent.&lt;/p&gt;
&lt;table class="table table-bordered table-centered"&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;$h(x)$&lt;/th&gt;
      &lt;th&gt;$\prox_{\alpha h}(x)$&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$||x||_1$&lt;/td&gt;
      &lt;td&gt;$\text{sign}(x) \max(0, \text{abs}(x) - \alpha)$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$\frac{1}{2}||x||_2^2$&lt;/td&gt;
      &lt;td&gt;$\frac{1}{1 + \alpha} x$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$||x||_2$&lt;/td&gt;
      &lt;td&gt;$\left( 1 - \frac{\alpha}{||x||_2} \right) x$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$||x||_{\infty}$&lt;/td&gt;
      &lt;td&gt;
          $\text{sign}(x) \min( \text{abs}(x), \theta )$

        where

          $\theta = \frac{1}{\rho} \sum_{j : |x_j| &gt; |x_{(\rho)}|} (|x_j| - \alpha)$

        where $x_{(i)}$ is is the $i$-th largest element of $x$ in magnitude and
        $\rho$ is the smallest $i$ such that
        $\sum_{j : |x_j| &gt; |x_{(i)}|} (|x_j| - |x_{(i)}|) &lt; \alpha$.
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$\frac{1}{2} x^T Q x + b^T x$&lt;/td&gt;
      &lt;td&gt;$(\alpha Q + I)^{-1} (x - \alpha b)$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1&gt;&lt;a name="references" href="#references"&gt;References&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Proof of Convergence&lt;/strong&gt; The original proof of convergence is thanks to
Laurent El Ghaoui's &lt;a href="http://www.eecs.berkeley.edu/~elghaoui/Teaching/EE227A/lecture18.pdf"&gt;EE227a slides&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;List of Proximal Functions&lt;/strong&gt;The list of proximal functions is taken from
John Duchi's article on &lt;a href="http://www.cs.berkeley.edu/~jduchi/projects/DuchiSi09c.pdf"&gt;Forward-Backward Splitting (FOBOS)&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a name="reference-impl" href="#reference-impl"&gt;Reference Implementation&lt;/a&gt;&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;proximal_gradient_descent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;g_gradient&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h_prox&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                              &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_iterations&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Proximal Gradient Descent&lt;/span&gt;

&lt;span class="sd"&gt;  Parameters&lt;/span&gt;
&lt;span class="sd"&gt;  ----------&lt;/span&gt;
&lt;span class="sd"&gt;  g_gradient : function&lt;/span&gt;
&lt;span class="sd"&gt;      Compute the gradient of `g(x)`&lt;/span&gt;
&lt;span class="sd"&gt;  h_prox : function&lt;/span&gt;
&lt;span class="sd"&gt;      Compute prox operator for h * alpha&lt;/span&gt;
&lt;span class="sd"&gt;  x0 : array&lt;/span&gt;
&lt;span class="sd"&gt;      initial value for x&lt;/span&gt;
&lt;span class="sd"&gt;  alpha : function&lt;/span&gt;
&lt;span class="sd"&gt;      function computing step sizes&lt;/span&gt;
&lt;span class="sd"&gt;  n_iterations : int, optional&lt;/span&gt;
&lt;span class="sd"&gt;      number of iterations to perform&lt;/span&gt;

&lt;span class="sd"&gt;  Returns&lt;/span&gt;
&lt;span class="sd"&gt;  -------&lt;/span&gt;
&lt;span class="sd"&gt;  xs : list&lt;/span&gt;
&lt;span class="sd"&gt;      intermediate values for x&lt;/span&gt;
&lt;span class="sd"&gt;  &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
  &lt;span class="n"&gt;xs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_iterations&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;g_gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;x_plus&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;h_prox&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_plus&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;xs&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;backtracking_line_search&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;g_gradient&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h_prox&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;alpha_0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;
  &lt;span class="n"&gt;beta&lt;/span&gt;    &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.9&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;search&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;alpha_0&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="n"&gt;x_plus&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;h_prox&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;g_gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;G&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;x_plus&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_plus&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_plus&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;G&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;G&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;
      &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;beta&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;search&lt;/span&gt;


&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;

  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;yannopt.plotting&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plotting&lt;/span&gt;

  &lt;span class="c1"&gt;### PROXIMAL GRADIENT DESCENT ###&lt;/span&gt;

  &lt;span class="c1"&gt;# problem definition&lt;/span&gt;
  &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="n"&gt;h&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;function&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;g_gradient&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="n"&gt;h_prox&lt;/span&gt;      &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sign&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;alpha&lt;/span&gt;       &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;backtracking_line_search&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;g_gradient&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h_prox&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;x0&lt;/span&gt;          &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;5.0&lt;/span&gt;
  &lt;span class="n"&gt;n_iterations&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;

  &lt;span class="c1"&gt;# run gradient descent&lt;/span&gt;
  &lt;span class="n"&gt;iterates&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;proximal_gradient_descent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                  &lt;span class="n"&gt;g_gradient&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h_prox&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                  &lt;span class="n"&gt;n_iterations&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;n_iterations&lt;/span&gt;
             &lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="c1"&gt;### PLOTTING ###&lt;/span&gt;

  &lt;span class="n"&gt;plotting&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot_iterates_vs_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iterates&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                     &lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;figures/iterates.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                     &lt;span class="n"&gt;y_star&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.69314718055994529&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;plotting&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot_iteration_vs_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iterates&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                      &lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;figures/convergence.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                      &lt;span class="n"&gt;y_star&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.69314718055994529&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="optimization"></category><category term="optimization"></category><category term="first-order"></category><category term="proximal"></category></entry><entry><title>Accelerated Gradient Descent</title><link href="https://stronglyconvex.com/blog/accelerated-gradient-descent.html" rel="alternate"></link><published>2013-04-12T00:00:00-07:00</published><updated>2013-04-12T00:00:00-07:00</updated><author><name>Daniel Duckworth</name></author><id>tag:stronglyconvex.com,2013-04-12:/blog/accelerated-gradient-descent.html</id><summary type="html">&lt;p&gt;In the mid-1980s, Yurii Nesterov hit the equivalent of an academic home run.
At the same time, he established the Accelerated Gradient Method, proved that
its convergence rate superior to Gradient Descent (&lt;span class="math"&gt;\(O(1/\sqrt{\epsilon})\)&lt;/span&gt;
iterations instead of &lt;span class="math"&gt;\(O(1/\epsilon)\)&lt;/span&gt;), and then proved that no other
first-order (that …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In the mid-1980s, Yurii Nesterov hit the equivalent of an academic home run.
At the same time, he established the Accelerated Gradient Method, proved that
its convergence rate superior to Gradient Descent (&lt;span class="math"&gt;\(O(1/\sqrt{\epsilon})\)&lt;/span&gt;
iterations instead of &lt;span class="math"&gt;\(O(1/\epsilon)\)&lt;/span&gt;), and then proved that no other
first-order (that is, gradient-based) algorithm could ever hope to beat it.
What a boss.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://stronglyconvex.com/blog/gradient-descent.html"&gt;Continuing&lt;/a&gt; &lt;a href="https://stronglyconvex.com/blog/subgradient-descent.html"&gt;my analogy&lt;/a&gt;, imagine
that you are standing on the side of a mountain and want to reach the bottom.
If you were to follow the Accelerated Gradient Method, you'd do something like
this,&lt;/p&gt;
&lt;div class="pseudocode"&gt;
&lt;ol&gt;
&lt;li&gt;Look around you and see which way points the most dowards&lt;/li&gt;
&lt;li&gt;Take a step in that direction&lt;/li&gt;
&lt;li&gt;Take another step in that direction, even if it starts taking you uphill.
     Then repeat.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;p&gt;As we'll see, that last unintuitive bit is the key to Accelerated Gradient
Descent's speed.&lt;/p&gt;
&lt;h1&gt;&lt;a name="implementation" href="#implementation"&gt;How does it work?&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;We begin by assuming the we want to minimize an unconstrained function &lt;span class="math"&gt;\(f\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
  \min_{x} \, f(x)
$$&lt;/div&gt;
&lt;p&gt;As with Gradient Descent, we'll assume that &lt;span class="math"&gt;\(f\)&lt;/span&gt; is differentiable and that we
can easily compute its gradient &lt;span class="math"&gt;\(\nabla f(x)\)&lt;/span&gt;. Then the Accelerated Gradient
Method is defined as,&lt;/p&gt;
&lt;div class="pseudocode"&gt;
&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt;: initial iterate &lt;span class="math"&gt;\(y^{(0)}\)&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;For &lt;span class="math"&gt;\(t = 1, 2, \ldots\)&lt;/span&gt;&lt;ol&gt;
&lt;li&gt;Let &lt;span class="math"&gt;\(x^{(t)} = y^{(t-1)} - \alpha^{(t)} \nabla f(y^{(t-1)})\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;if converged, return &lt;span class="math"&gt;\(x^{(t)}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Let &lt;span class="math"&gt;\(y^{(t)} = x^{(t)} + \frac{t-1}{t+2} (x^{(t)} - x^{(t-1)})\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;h1&gt;&lt;a name="example" href="#example"&gt;A Small Example&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;We'll try out Accelerated Gradient on the &lt;a href="/blog/gradient-descent.html#example"&gt;same example used to showcase
Gradient Descent&lt;/a&gt;. We'll use the objective function
&lt;span class="math"&gt;\(f(x) = x^4\)&lt;/span&gt;, meaning that &lt;span class="math"&gt;\(\nabla_x f(x) = 4 x^3\)&lt;/span&gt;. For a step size, we'll use
Backtracking Line Search where the largest acceptable step size is &lt;span class="math"&gt;\(0.05\)&lt;/span&gt;.
Finally, we'll start at &lt;span class="math"&gt;\(x^{(0)} = 1\)&lt;/span&gt;.  Compare these 2 graphs to the ones for
Gradient Descent.&lt;/p&gt;
&lt;div class="img-center"&gt;
  &lt;img src="/assets/img/accelerated_gradient/convergence.png"&gt;&lt;/img&gt;
  &lt;span class="caption"&gt;
    This plot shows how quickly the objective function decreases as the
    number of iterations increases.
  &lt;/span&gt;
&lt;/div&gt;

&lt;div class="img-center"&gt;
  &lt;img src="/assets/img/accelerated_gradient/iterates.png"&gt;&lt;/img&gt;
  &lt;span class="caption"&gt;
    This plot shows the actual iterates and the objective function evaluated at
    those points. More red indicates a higher iteration number.
  &lt;/span&gt;
&lt;/div&gt;

&lt;h1&gt;&lt;a name="proof" href="#proof"&gt;Why does it work?&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;The assumptions for the Accelerated Gradient Method are identical to Gradient
Descent's. In particular, we assume,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;span class="math"&gt;\(f\)&lt;/span&gt; is convex, differentiable, and finite for all &lt;span class="math"&gt;\(x\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;a finite solution &lt;span class="math"&gt;\(x^{*}\)&lt;/span&gt; exists&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\nabla f(x)\)&lt;/span&gt; is Lipschitz continuous with constant &lt;span class="math"&gt;\(L\)&lt;/span&gt;. That is, there must
   be an &lt;span class="math"&gt;\(L\)&lt;/span&gt; such that,&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="math"&gt;$$
  || \nabla f(x) - \nabla f(y) ||_2 \le L || x - y ||_2 \qquad \forall x,y
$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Assumptions&lt;/strong&gt; As explained in my post on &lt;a href="https://stronglyconvex.com/blog/gradient-descent.html"&gt;Gradient
Descent&lt;/a&gt;, these assumptions give us 2 things. Assumption 1
gives us a linear lower bound on &lt;span class="math"&gt;\(f\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
  f(y) \ge f(x) + \nabla f(x)^T (y-x) \qquad \forall x, y
$$&lt;/div&gt;
&lt;p&gt;Assumption 3 then gives us a quadratic upper bound on &lt;span class="math"&gt;\(f\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
  f(y) \le f(x) + \nabla f(x)^T (y-x) + \frac{L}{2} ||x - y||_2^2 \qquad \forall x, y
$$&lt;/div&gt;
&lt;p&gt;Both of these will prove critical in the following proof.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof Outline&lt;/strong&gt; The proof for the Accelerated Gradient Method is the
trickiest one yet. We'll see that everything fits into place just right, but
that there's very little intuition as to where it all came from.&lt;/p&gt;
&lt;p&gt;We begin in Step 1 by defining a third iterate &lt;span class="math"&gt;\(v^{(t)}\)&lt;/span&gt; that's a
linear combination of &lt;span class="math"&gt;\(x^{(t)}\)&lt;/span&gt; and &lt;span class="math"&gt;\(x^{(t-1)}\)&lt;/span&gt;. These iterates are purely for
the sake of the proof and are not computed during the algorithm. Using these
iterates, we upper bound &lt;span class="math"&gt;\(f(x^{(t+1)})\)&lt;/span&gt; in terms of &lt;span class="math"&gt;\(f(x^{(t)})\)&lt;/span&gt;, &lt;span class="math"&gt;\(f(x^{*})\)&lt;/span&gt;,
the distance between &lt;span class="math"&gt;\(v^{(t+1)}\)&lt;/span&gt; and &lt;span class="math"&gt;\(x^{*}\)&lt;/span&gt;, and the distance between
&lt;span class="math"&gt;\(v^{(t)}\)&lt;/span&gt; and &lt;span class="math"&gt;\(x^{*}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Step 2 involves upper bounding the error &lt;span class="math"&gt;\(f(x^{(t+1)}) - f(x^{*})\)&lt;/span&gt; by &lt;span class="math"&gt;\(f(x^{0})
- f(x^{*})\)&lt;/span&gt; and the distance between &lt;span class="math"&gt;\(v^{(0)}\)&lt;/span&gt; and &lt;span class="math"&gt;\(x^{*}\)&lt;/span&gt; using our very
careful choice of &lt;span class="math"&gt;\(\frac{t-1}{t+2}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Finally, Step 3 brings it all together by bounding &lt;span class="math"&gt;\(f(x^{(t+1)}) - f(x^{*})\)&lt;/span&gt; by
a term depending on &lt;span class="math"&gt;\(1/(t+2)^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1&lt;/strong&gt; upper bounding &lt;span class="math"&gt;\(f(x^{(t+1)})\)&lt;/span&gt;.  First, define the following and assume that &lt;span class="math"&gt;\(\theta^{(0)} = 1\)&lt;/span&gt;, &lt;span class="math"&gt;\(v^{(0)} = x^{(0)}\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
  v^{(t)}
  = \frac{t+1}{2} x^{(t)} - \frac{t-1}{2} x^{(t-1)} \qquad
  \theta^{(t)}
  = \frac{2}{t+2}
$$&lt;/div&gt;
&lt;p&gt;There are 2 consequences of this definition for &lt;span class="math"&gt;\(v^{(t)}\)&lt;/span&gt;. The first is that &lt;span class="math"&gt;\(y^{(t)}\)&lt;/span&gt; is a linear combination of &lt;span class="math"&gt;\(v^{(t)}\)&lt;/span&gt; and &lt;span class="math"&gt;\(x^{(t)}\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \color{fuchsia} y^{(t)}
  &amp;amp; = x^{(t)} + \frac{t-1}{t+2} ( x^{(t)} - x^{(t-1)} ) \\
  &amp;amp; = \frac{(t+2) + (t-1)}{t+2} x^{(t)} - \frac{t-1}{t+2} x^{(t-1)} \\
  &amp;amp; = \frac{t+1}{t+2} x^{(t)} - \frac{t-1}{t+2} x^{(t-1)} + \frac{t}{t+2} x^{(t)} \\
  &amp;amp; = \frac{2}{t+2} \left( \frac{t+1}{2} x^{(t)} - \frac{t-1}{2} x^{(t-1)} \right) + (1 - \frac{2}{t+2}) x^{(t)} \\
  &amp;amp; = \color{fuchsia} \theta^{(t)} v^{(t)} + (1 - \theta^{(t)}) x^{(t)} \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;The second is that &lt;span class="math"&gt;\(v^{(t)}\)&lt;/span&gt; is a gradient step on &lt;span class="math"&gt;\(v^{(t)}\)&lt;/span&gt;, except that the gradient is evaluated at &lt;span class="math"&gt;\(y^{(t)}\)&lt;/span&gt; (work backwards from the following),&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \color{OrangeRed} v^{(t+1)}
  &amp;amp; = \color{OrangeRed} v^{(t)} - \frac{\alpha^{(t+1)}}{\theta^{(t)}} \nabla f(y^{(t)}) \\
  &amp;amp; = v^{(t)} + \frac{1}{\theta^{(t)}} ( y^{(t)} - \alpha^{(t+1)} \nabla f(y^{(t)}) - y^{(t)} ) \\
  &amp;amp; = v^{(t)} + \frac{1}{\theta^{(t)}} ( x^{(t+1)} - y^{(t)} ) \\
  \frac{t+2}{2} x^{(t+1)} - \frac{t}{2} x^{(t)}
  &amp;amp; = \frac{t+1}{2} x^{(t)} - \frac{t-1}{2} x^{(t-1)} + \frac{1}{\theta^{(t)}} ( x^{(t+1)} - y^{(t)} ) \\
  &amp;amp; = \frac{t+1}{2} x^{(t)} - \frac{t-1}{2} x^{(t-1)} + \frac{t+2}{2} ( x^{(t+1)} - y^{(t)} ) \\
  - \frac{t}{2} x^{(t)}
  &amp;amp; = \frac{t+1}{2} x^{(t)} - \frac{t-1}{2} x^{(t-1)} - \frac{t+2}{2} y^{(t)} \\
  y^{(t)}
  &amp;amp; = \frac{2t+1}{t+2} x^{(t)} - \frac{t-1}{t+2} x^{(t-1)} \\
  &amp;amp; = x^{(t)} + \frac{t-1}{t+2} ( x^{(t)} - x^{(t-1)} )
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;With these 2 properties in hand, let's upper bound &lt;span class="math"&gt;\(f(x^{(t)})\)&lt;/span&gt;.  Let &lt;span class="math"&gt;\(\alpha^{(t)} \le \frac{1}{L}\)&lt;/span&gt; and define
&lt;span class="math"&gt;\(x^{+} \triangleq x^{(t)}\)&lt;/span&gt;,
&lt;span class="math"&gt;\(x \triangleq x^{(t-1)}\)&lt;/span&gt;,
&lt;span class="math"&gt;\(v^{+} \triangleq v^{(t)}\)&lt;/span&gt;,
&lt;span class="math"&gt;\(v \triangleq v^{(t-1)}\)&lt;/span&gt;,
&lt;span class="math"&gt;\(\alpha^{+} \triangleq \alpha^{(t)}\)&lt;/span&gt;,
&lt;span class="math"&gt;\(y \triangleq y^{(t-1)}\)&lt;/span&gt;,
&lt;span class="math"&gt;\(\theta \triangleq \theta^{(t-1)}\)&lt;/span&gt;&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  f(x^{+})
  &amp;amp; = f(y - \alpha^{+} \nabla f(y)) \\
  &amp;amp; \le {\color{red} f(y) - \frac{\alpha^{+}}{2} || \nabla f(y) ||_2^2} \\
  &amp;amp; \le {\color{blue} (1-\theta) f(x) + \theta f(x^{*}) + \nabla f(y)^T (y - (1-\theta) x + \theta x^{*}) } - \frac{\alpha^{+}}{2} || \nabla f(y) ||_2^2 \\
  &amp;amp; = (1-\theta) f(x) + \theta f(x^{*}) + \nabla f(y)^T ({\color{fuchsia} \theta v} + \theta x^{*}) - \frac{\alpha^{+}}{2} || \nabla f(y) ||_2^2 \\
  &amp;amp; = (1-\theta) f(x) + \theta f(x^{*}) + \frac{\theta^2}{2 \alpha^{+}} \left(
        \frac{2 \alpha^{+}}{\theta} \nabla f(y)^T (v-x) - \left( \frac{\alpha^{+}}{\theta} \right)^2 || \nabla f(y) ||_2^2
        \pm ||v - x^{*}||_2^2
      \right) \\
  &amp;amp; = (1-\theta) f(x) + \theta f(x^{*}) + \frac{\theta^2}{2 \alpha^{+}} \left(
        ||v - x^{*}||_2^2 - ||v - x^{*} - \frac{\alpha^{+}}{\theta} \nabla f(y)||_2^2 
      \right) \\
  &amp;amp; = (1-\theta) f(x) + \theta f(x^{*}) + \frac{\theta^2}{2 \alpha^{+}} \left(
        ||v - x^{*}||_2^2 - ||{\color{OrangeRed} v^{+} } - x^{*}||_2^2
      \right) \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Using the Lipschitz assumption on &lt;span class="math"&gt;\(||\nabla f(y)||_2\)&lt;/span&gt; and that &lt;span class="math"&gt;\(\alpha^{+} \le \frac{1}{L}\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \color{red}
  f(y - \alpha^{+} \nabla f(y))
  &amp;amp; \le f(y) + \nabla f(y)^T (y - \alpha^{+} \nabla f(y) - y) + \frac{L}{2}{ ||y - \alpha^{+} \nabla f(y) - y ||_2^2 } \\
  &amp;amp; = f(y) - \alpha^{+} || \nabla f(y) ||_2^2 + \frac{L (\alpha^{+})^2}{2} || \nabla f(y) ||_2^2 \\
  &amp;amp; = f(y) - \frac{\alpha^{+}}{2} ( 2 - L \alpha^{+} ) || \nabla f(y) ||_2^2 \\
  &amp;amp; \le \color{red} f(y) - \frac{\alpha^{+}}{2} || \nabla f(y) ||_2^2 \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Using convexity's linear lower bound and its line-over-function properties,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \color{blue}
  f( (1-\theta)x + \theta x^{*} )
  &amp;amp; \ge f(y) + \nabla f(y)^T ( (1-\theta)x + \theta x^{*} - y) \\
  (1-\theta) f(x) + \theta f(x^{*}) 
  &amp;amp; \ge f(y) + \nabla f(y)^T ( (1-\theta)x + \theta x^{*} - y) \\
  f(y)
  &amp;amp; \le \color{blue} (1-\theta) f(x) + \theta f(x^{*}) + \nabla f(y)^T(y - (1-\theta) x + \theta x^{*} )
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Step 2&lt;/strong&gt; Upper bounding &lt;span class="math"&gt;\(f(x^{(t+1)}) - f(x^{*})\)&lt;/span&gt;. We begin by manipulating the result from step 1 into something such that the left and right side look almost the same,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  f(x^{(t+1)})
  &amp;amp; \le (1-\theta^{(t)}) f(x^{(t)}) + \theta^{(t)} f(x^{*}) \\
  &amp;amp; \quad + \frac{ (\theta^{(t)})^2}{2 \alpha^{(t+1)}} \left(
        ||v^{(t)} - x^{*}||_2^2 - \underbrace{ ||v^{(t+1)} - x^{*}||_2^2 }_{\text{move to other side}}
     \right) \\
  f(x^{(t+1)}) + \frac{ (\theta^{(t)})^2}{2 \alpha^{(t+1)}} ||v^{(t+1)} - x^{*}||_2^2
  &amp;amp; \le (1-\theta^{(t)}) f(x^{(t)}) + \theta^{(t)} f(x^{*}) \\
  &amp;amp; \quad + \frac{ (\theta^{(t)})^2}{2 \alpha^{(t+1)}} ||v^{(t)} - x^{*}||_2^2 \underbrace{ \pm f(x^{*}) }_{=0} \\
  f(x^{(t+1)}) - f(x^{*}) + \frac{ (\theta^{(t)})^2}{2 \alpha^{(t+1)}} ||v^{(t+1)} - x^{*}||_2^2
  &amp;amp; \le (1-\theta^{(t)}) f(x^{(t)}) \underbrace{ - f(x^{*}) + \theta^{(t)} f(x^{*}) }_{\text{group together}} \\
  &amp;amp; \quad + \frac{ (\theta^{(t)})^2}{2 \alpha^{(t+1)}} ||v^{(t)} - x^{*}||_2^2 \\
  f(x^{(t+1)}) - f(x^{*}) + \frac{ (\theta^{(t)})^2}{2 \alpha^{(t+1)}} ||v^{(t+1)} - x^{*}||_2^2
  &amp;amp; \le (1-\theta^{(t)}) f(x^{(t)}) - (1-\theta^{(t)}) f(x^{*}) \\
  &amp;amp; \quad + \frac{ (\theta^{(t)})^2}{2 \alpha^{(t+1)}} ||v^{(t)} - x^{*}||_2^2 \\
  \frac{1}{( \theta^{(t)} )^2} \left( f(x^{(t+1)}) - f(x^{*}) \right) + \frac{1}{2 \alpha^{(t+1)}} ||v^{(t+1)} - x^{*}||_2^2
  &amp;amp; \le \frac{ (1-\theta^{(t)}) }{ (\theta^{(t)})^2 } \left( f(x^{(t)}) - f(x^{*}) \right) \\
  &amp;amp; \quad + \frac{1}{2 \alpha^{(t+1)}} ||v^{(t)} - x^{*}||_2^2 \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Remember how &lt;span class="math"&gt;\(\theta^{(t)} = \frac{2}{t+2}\)&lt;/span&gt;? Well that means &lt;span class="math"&gt;\(\theta^{(t)} &amp;gt; 0\)&lt;/span&gt; and thus &lt;span class="math"&gt;\(\frac{1 - \theta^{(t)}}{ (\theta^{(t)})^2 } \le \frac{1}{ (\theta^{(t)})^2 }\)&lt;/span&gt;. Subbing that into the previous equation lets us apply it recursively to obtain,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \frac{1}{( \theta^{(t)} )^2} \left( f(x^{(t+1)}) - f(x^{*}) \right) + \frac{1}{2 \alpha^{(t+1)}} ||v^{(t+1)} - x^{*}||_2^2
  &amp;amp; \le \frac{ (1-\theta^{(0)}) }{ (\theta^{(0)})^2 } \left( f(x^{(0)}) - f(x^{*}) \right) + \frac{1}{2 \alpha^{(1)}} ||v^{(0)} - x^{*}||_2^2 \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Step 3&lt;/strong&gt; Bound the error in terms of &lt;span class="math"&gt;\(\frac{1}{(t+2)^2}\)&lt;/span&gt;.  Recall that &lt;span class="math"&gt;\(\theta^{(0)} = 1\)&lt;/span&gt; and &lt;span class="math"&gt;\(v^{(0)} = x^{(0)}\)&lt;/span&gt;. Then,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \frac{1}{( \theta^{(t)} )^2} \left( f(x^{(t+1)}) - f(x^{*}) \right) 
    + \underbrace{ \frac{1}{2 \alpha^{(t+1)}} ||v^{(t+1)} - x^{*}||_2^2 }_{\ge 0 \text{, so drop}}
  &amp;amp; \le \underbrace{ \frac{ (1-\theta^{(0)}) }{ (\theta^{(0)})^2 } }_{= 0} \left( f(x^{(0)}) - f(x^{*}) \right)
    + \frac{1}{2 \alpha^{(1)}} ||\underbrace{ v^{(0)} }_{x^{(0)}} - x^{*}||_2^2 \\
  \frac{1}{( \theta^{(t)} )^2} \left( f(x^{(t+1)}) - f(x^{*}) \right)
  &amp;amp; \le \frac{1}{2 \alpha^{(1)}} || x^{(0)} - x^{*} ||_2^2 \\
  f(x^{(t+1)}) - f(x^{*})
  &amp;amp; \le \frac{( \theta^{(t)} )^2}{2 \alpha^{(1)}} || x^{(0)} - x^{*} ||_2^2 \\
  &amp;amp; = \frac{2}{ (t+2)^2 \alpha^{(1)} } || x^{(0)} - x^{*} ||_2^2
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Thus, the convergence rate of the Accelerated Gradient Method is
&lt;span class="math"&gt;\(O(\frac{1}{\sqrt{\epsilon}})\)&lt;/span&gt;. Woo!&lt;/p&gt;
&lt;p&gt;&lt;a id="usage"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a name="usage" href="#usage"&gt;When should I use it?&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;The Accelerated Gradient Method trumps Gradient Descent in every way theoretically, but the latter is still more widely used and preferred.  Why? The fact is that Accelerated Gradient is much more of a pain to implement. Whereas with Gradient Descent you can simply check if your new iterate's score is less than the previous one, Accelerated Gradient's score may increase before decreasing again. Accelerated Gradient is also extremely sensitive to step size -- if &lt;span class="math"&gt;\(\alpha^{(t)}\)&lt;/span&gt; isn't in &lt;span class="math"&gt;\((0, \frac{1}{L}]\)&lt;/span&gt;, &lt;em&gt;it will diverge&lt;/em&gt;. Accelerated Gradient is a powerful but fickle tool. Use it when you can, but keep Gradient Descent handy if everything is going awry.&lt;/p&gt;
&lt;h1&gt;&lt;a name="extensions" href="#extensions"&gt;Extensions&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Step Size&lt;/strong&gt; As mentioned previously, Accelerated Gradient is very fickle
with step size.  While Backtracking Line Search can and should be used when
possible, it is essential that the constants be set such that &lt;span class="math"&gt;\(\alpha^{(t+1)}
\le \frac{1}{L}\)&lt;/span&gt;. In other words, when,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  f(y^{(t)} - \alpha^{(t+1)} \nabla f(y^{(t)}))
  &amp;amp; \le f(y^{(t)}) + \nabla f(y^{(t)})^T ((y^{(t)} - \alpha^{(t+1)} \nabla f(y^{(t)})) - y^{(t)}) \\
  &amp;amp; \quad + \frac{1}{2 \alpha^{(t+1)} } ||(y^{(t)} - \alpha^{(t+1)} \nabla f(y^{(t)})) - y^{(t)}||_2^2 \\
  &amp;amp; = f(y^{(t)}) - \alpha^{(t+1)} || \nabla f(y^{(t)}) ||_2^2 + \frac{ \alpha^{(t+1)} }{2} ||\nabla f(y^{(t)}) ||_2^2 \\
  &amp;amp; = f(y^{(t)}) - \frac{\alpha^{(t+1)}}{2} || \nabla f(y^{(t)}) ||_2^2 \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Typically the &lt;span class="math"&gt;\(\frac{1}{2}\)&lt;/span&gt; in the last part of the last line is traded for another constant. &lt;em&gt;This will not work for Accelerated Gradient!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Checking Convergence&lt;/strong&gt; As with Gradient Descent and Subgradient Descent,
there is no real way to be certain when &lt;span class="math"&gt;\(f(x^{(t)}) - f(x^{*}) &amp;lt; \epsilon\)&lt;/span&gt;
without some problem-specific knowledge. Instead, it is common to stop after a
fixed number of iterations or when &lt;span class="math"&gt;\(||\nabla f(x^{(t)})||_2\)&lt;/span&gt; is small.&lt;/p&gt;
&lt;h1&gt;&lt;a name="references" href="#references"&gt;References&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Proof of Convergence&lt;/strong&gt; The proof of convergence is thanks to Lieven
Vandenberghe's &lt;a href="http://math.sjtu.edu.cn/faculty/zw2109/course/sp04-2-gradient.pdf"&gt;EE236c slides&lt;/a&gt; hosted by Zaiwen Wen.&lt;/p&gt;
&lt;h1&gt;&lt;a name="reference-impl" href="#reference-impl"&gt;Reference Implementation&lt;/a&gt;&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;accelerated_gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_iterations&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Accelerated Gradient Method&lt;/span&gt;

&lt;span class="sd"&gt;  Parameters&lt;/span&gt;
&lt;span class="sd"&gt;  ----------&lt;/span&gt;
&lt;span class="sd"&gt;  gradient : function&lt;/span&gt;
&lt;span class="sd"&gt;      Computes the gradient of the objective function at x&lt;/span&gt;
&lt;span class="sd"&gt;  y0 : array&lt;/span&gt;
&lt;span class="sd"&gt;      initial value for x&lt;/span&gt;
&lt;span class="sd"&gt;  alpha : function&lt;/span&gt;
&lt;span class="sd"&gt;      function computing step sizes&lt;/span&gt;
&lt;span class="sd"&gt;  n_iterations : int, optional&lt;/span&gt;
&lt;span class="sd"&gt;      number of iterations to perform&lt;/span&gt;

&lt;span class="sd"&gt;  Returns&lt;/span&gt;
&lt;span class="sd"&gt;  -------&lt;/span&gt;
&lt;span class="sd"&gt;  xs : list&lt;/span&gt;
&lt;span class="sd"&gt;      intermediate values for x&lt;/span&gt;
&lt;span class="sd"&gt;  &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
  &lt;span class="n"&gt;ys&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;y0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="n"&gt;xs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;y0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_iterations&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ys&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;x_plus&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;
    &lt;span class="n"&gt;y_plus&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x_plus&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_plus&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_plus&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_plus&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;xs&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;BacktrackingLineSearch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;function&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;    &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.05&lt;/span&gt;

  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__call__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;function&lt;/span&gt;
    &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
      &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="mf"&gt;0.99&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;

  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;yannopt.plotting&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plotting&lt;/span&gt;

  &lt;span class="c1"&gt;### ACCELERATED GRADIENT ###&lt;/span&gt;

  &lt;span class="c1"&gt;# problem definition&lt;/span&gt;
  &lt;span class="n"&gt;function&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;     &lt;span class="c1"&gt;# the function to minimize&lt;/span&gt;
  &lt;span class="n"&gt;gradient&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;  &lt;span class="c1"&gt;# its gradient&lt;/span&gt;
  &lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BacktrackingLineSearch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;x0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;
  &lt;span class="n"&gt;n_iterations&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;

  &lt;span class="c1"&gt;# run gradient descent&lt;/span&gt;
  &lt;span class="n"&gt;iterates&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;accelerated_gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_iterations&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;n_iterations&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="c1"&gt;### PLOTTING ###&lt;/span&gt;

  &lt;span class="n"&gt;plotting&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot_iterates_vs_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iterates&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                     &lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;figures/iterates.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_star&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;plotting&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot_iteration_vs_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iterates&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                      &lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;figures/convergence.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_star&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="optimization"></category><category term="optimization"></category><category term="first-order"></category><category term="accelerated"></category></entry><entry><title>Subgradient Descent</title><link href="https://stronglyconvex.com/blog/subgradient-descent.html" rel="alternate"></link><published>2013-04-11T00:00:00-07:00</published><updated>2013-04-11T00:00:00-07:00</updated><author><name>Daniel Duckworth</name></author><id>tag:stronglyconvex.com,2013-04-11:/blog/subgradient-descent.html</id><summary type="html">&lt;p&gt;Not far from &lt;a href="https://stronglyconvex.com/blog/gradient-descent.html"&gt;Gradient Descent&lt;/a&gt; is another first-order
descent algorithm (that is, an algorithm that only relies on the first
derivative) is Subgradient Descent. In implementation, they are in fact
identical. The only difference is on the assumptions placed on the objective
function we wish to minimize, &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt;.  If …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Not far from &lt;a href="https://stronglyconvex.com/blog/gradient-descent.html"&gt;Gradient Descent&lt;/a&gt; is another first-order
descent algorithm (that is, an algorithm that only relies on the first
derivative) is Subgradient Descent. In implementation, they are in fact
identical. The only difference is on the assumptions placed on the objective
function we wish to minimize, &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt;.  If you were to follow the Subgradient
Descent algorithm to walk down a mountain, it would look something like this,&lt;/p&gt;
&lt;div class="pseudocode"&gt;
&lt;ol&gt;
&lt;li&gt;Look around you and see which way points the most downwards. If there are multiple directions that are equally downwards, just pick one.&lt;/li&gt;
&lt;li&gt;Take a step in that direction. Then repeat.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;h1&gt;&lt;a name="implementation" href="#implementation"&gt;How does it work?&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;As before, we adopt the usual problem definition,&lt;/p&gt;
&lt;div class="math"&gt;$$
  \min_{x} \, f(x)
$$&lt;/div&gt;
&lt;p&gt;But this time, we don't assume &lt;span class="math"&gt;\(f\)&lt;/span&gt; is differentiable. Instead, we assume &lt;span class="math"&gt;\(f\)&lt;/span&gt;
is convex, implying that for all &lt;span class="math"&gt;\(x\)&lt;/span&gt; there exists a &lt;span class="math"&gt;\(g_{x}\)&lt;/span&gt; such that,&lt;/p&gt;
&lt;div class="math"&gt;$$
  f(y) \ge f(x) + g_{x}^T (y - x)
$$&lt;/div&gt;
&lt;p&gt;If &lt;span class="math"&gt;\(f\)&lt;/span&gt; is differentiable at &lt;span class="math"&gt;\(x\)&lt;/span&gt; and is convex, then &lt;span class="math"&gt;\(\nabla f(x)\)&lt;/span&gt; is the only
value for &lt;span class="math"&gt;\(g_{x}\)&lt;/span&gt; that satisfies this property, but if &lt;span class="math"&gt;\(f\)&lt;/span&gt; is convex but
non-differentiable at &lt;span class="math"&gt;\(x\)&lt;/span&gt;, there will be other options.&lt;/p&gt;
&lt;p&gt;The set of all &lt;span class="math"&gt;\(g_x\)&lt;/span&gt; that satisfies this property called the
&lt;strong&gt;subdifferential&lt;/strong&gt; of &lt;span class="math"&gt;\(f\)&lt;/span&gt; at &lt;span class="math"&gt;\(x\)&lt;/span&gt; and is denoted &lt;span class="math"&gt;\(\partial f(x)\)&lt;/span&gt;. Given that we
have an algorithm for finding a point in the subdifferential, Subgradient
Descent is&lt;/p&gt;
&lt;figure&gt;
  &lt;img src="/assets/img/subgradient_descent/subgradient.png"&gt;&lt;/img&gt;
  &lt;figcaption&gt;
    $f$ is differentiable at $x_1$, so there's only one possible subgradient
    (the actual gradient). At $x_2$, $f$ isn't differentiable, so $g_2$ and
    $g_3$ are both in $\partial f(x_2)$. Image taken from [EE392o slides][subgradient].
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;div class="pseudocode"&gt;
&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt;: initial iterate &lt;span class="math"&gt;\(x^{(0)}\)&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;For &lt;span class="math"&gt;\(t = 0, 1, \ldots\)&lt;/span&gt;&lt;ol&gt;
&lt;li&gt;if converged, return &lt;span class="math"&gt;\(x^{(t)}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Compute a &lt;a href="http://www.stanford.edu/class/ee392o/subgrad.pdf"&gt;subgradient&lt;/a&gt; of &lt;span class="math"&gt;\(f\)&lt;/span&gt; at &lt;span class="math"&gt;\(x^{(t)}\)&lt;/span&gt;, &lt;span class="math"&gt;\(g^{(t)} \in \partial f(x^{(t)})\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(x^{(t+1)} = x^{(t)} - \alpha^{(t)} g^{(t)}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;p&gt;The initial iterate &lt;span class="math"&gt;\(x^{(0)}\)&lt;/span&gt; can be selected arbitrarily, but &lt;span class="math"&gt;\(\alpha^{(t)}\)&lt;/span&gt;
must be selected more carefully than in Gradient Descent. A common choice is
&lt;span class="math"&gt;\(\frac{1}{t}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a id="example"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a name="example" href="#example"&gt;A Small Example&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Let's watch Subgradient Descent do its thing. We'll use &lt;span class="math"&gt;\(f(x) = |x|\)&lt;/span&gt; as our
objective function, giving us &lt;span class="math"&gt;\(sign(x)\)&lt;/span&gt; as a valid way to compute subgradients.
We'll use the &lt;a href="#polyak"&gt;Polyak Step Size&lt;/a&gt; and initialize with &lt;span class="math"&gt;\(x^{(0)} = 0.75\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="img-center"&gt;
  &lt;img src="/assets/img/subgradient_descent/convergence.png"&gt;&lt;/img&gt;
  &lt;span class="caption"&gt;
    This plot shows how the objective value changes as the number of iterations
    increase. We can see that, unlike Gradient Descent, it isn't strictly
    decreasing. This is expected!
  &lt;/span&gt;
&lt;/div&gt;

&lt;div class="img-center"&gt;
  &lt;img src="/assets/img/subgradient_descent/iterates.png"&gt;&lt;/img&gt;
  &lt;span class="caption"&gt;
    This plot shows the actual iterates and the objective function evaluated at
    those points. More red indicates a higher iteration number.
  &lt;/span&gt;
&lt;/div&gt;

&lt;h1&gt;&lt;a name="proof" href="#proof"&gt;Why does it work?&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Now let's prove that Subgradient Descent can find &lt;span class="math"&gt;\(x^{*} = \arg\min_x f(x)\)&lt;/span&gt;.
We begin by making the following assumptions,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;span class="math"&gt;\(f\)&lt;/span&gt; is convex and finite for all &lt;span class="math"&gt;\(x\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;a finite solution &lt;span class="math"&gt;\(x^{*}\)&lt;/span&gt; exists&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(f\)&lt;/span&gt; is Lipschitz with constant &lt;span class="math"&gt;\(G\)&lt;/span&gt;. That is,&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="math"&gt;$$
  || f(x) - f(y) ||_2 \le G || x - y ||_2 \qquad \forall x,y
$$&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;The initial distance to &lt;span class="math"&gt;\(x^{*}\)&lt;/span&gt; is bounded by &lt;span class="math"&gt;\(R\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="math"&gt;$$
  || x^{(0)} - x^{*} || \le R
$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Assumptions&lt;/strong&gt; Looking back at the convergence proof of Gradient Descent, we
see that the main difference is in assumption 3. Before, we assumed that the
&lt;span class="math"&gt;\(\nabla f\)&lt;/span&gt; was Lipschitz, but now we assume that &lt;span class="math"&gt;\(f\)&lt;/span&gt; is Lipschitz. The
reason for this is because non-smooth functions cannot have a Lipschitz
Subgradient function (Imagine 2 different subgradients for &lt;span class="math"&gt;\(f\)&lt;/span&gt;, &lt;span class="math"&gt;\(g_x\)&lt;/span&gt; and
&lt;span class="math"&gt;\(g_y\)&lt;/span&gt;, such that &lt;span class="math"&gt;\(g_x \ne g_y\)&lt;/span&gt; and &lt;span class="math"&gt;\(x = y\)&lt;/span&gt;. Then &lt;span class="math"&gt;\(||x-y||_2 = 0\)&lt;/span&gt; but &lt;span class="math"&gt;\(||g_x -
g_y||_2 &amp;gt; 0\)&lt;/span&gt;).  However, this assumption does guarantee one thing: that &lt;span class="math"&gt;\(g_x
\le G\)&lt;/span&gt; for all &lt;span class="math"&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Assumption 4 isn't really a condition at all.  It's just a notational
convenience for later.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof Outline&lt;/strong&gt; The proof for Gradient Descent relied on &lt;span class="math"&gt;\(f(x^{(t)}) -
f(x^{*})\)&lt;/span&gt; decreasing with each iteration, but the proof for Subgradient Descent
relies on decreasing the (upper bound on) Euclidean distance between &lt;span class="math"&gt;\(x^{(t)}\)&lt;/span&gt;
and the set of all possible &lt;span class="math"&gt;\(x^{*}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We begin by upper bounding the current distance to the optimal point by the
previous distance (&lt;span class="math"&gt;\(||x^{(t)} - x^{*}||_2\)&lt;/span&gt;), the previous error (&lt;span class="math"&gt;\(f(x^{(t)}) -
f(x^{*})\)&lt;/span&gt;), and the norm of the subgradient (&lt;span class="math"&gt;\(||g^{(t)}||_2\)&lt;/span&gt;).  Next, we
recursively apply the previous finding across all &lt;span class="math"&gt;\(t\)&lt;/span&gt; to bound the sum of
errors by the &lt;em&gt;initial&lt;/em&gt; distance to &lt;span class="math"&gt;\(x^{*}\)&lt;/span&gt; and the sum of all subgradient
norms.  Then, we lower bound the sum of all errors with a minimum over &lt;span class="math"&gt;\(t\)&lt;/span&gt;,
giving us an upper bound on our error at iteration &lt;span class="math"&gt;\(t+1\)&lt;/span&gt;. Finally, we use
Assumption 4. to make that bound go to zero.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1&lt;/strong&gt; Upper bound &lt;span class="math"&gt;\(||x^{(t+1)} - x^{*}||\)&lt;/span&gt;. Let &lt;span class="math"&gt;\(x^{*}\)&lt;/span&gt; be any point in
&lt;span class="math"&gt;\(\arg\min_{x} f(x)\)&lt;/span&gt;. Then,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  ||x^{(t+1)} - x^{*}||_2^2
  = &amp;amp; ||x^{(t)} - \alpha^{(t)} g^{(t)} - x^{*}||_2^2
    &amp;amp;&amp;amp; \text{# Definition of $x^{(t+1)}$} \\
  = &amp;amp; ||x^{(t)} - x^{*}||_2^2 - 2 \alpha^{(t)} \langle g^{(t)}, x^{(t)} - x^{*} \rangle + ( \alpha^{(t)} )^2 ||g^{(t)}||_2^2
    \\
  \le &amp;amp; ||x^{(t)} - x^{*}||_2^2 - 2 \alpha^{(t)} ( f(x^{(t)}) - f(x^{*}) ) + ( \alpha^{(t)} )^2 ||g^{(t)}||_2^2
    \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Our last step uses &lt;span class="math"&gt;\(f(x^{*}) \ge f(x^{(t)}) + \langle g^{(t)}, x^{*} - x^{(t)} \rangle\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 2&lt;/strong&gt; Upper bound &lt;span class="math"&gt;\(||x^{(t+1)} - x^{*}||\)&lt;/span&gt; by &lt;span class="math"&gt;\(||x^{(0)} - x^{*}||\)&lt;/span&gt;.
First, we apply Step 1 recursively to bound the current distance to &lt;span class="math"&gt;\(x^{*}\)&lt;/span&gt;&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  ||x^{(t+1)} - x^{*}||_2^2
  \le &amp;amp; ||x^{(t)} - x^{*}||_2^2 - 2 \alpha^{(t)} ( f(x^{(t)}) - f(x^{*}) ) + ( \alpha^{(t)} )^2 ||g^{(t)}||_2^2
    \\
  \le &amp;amp; \left( ||x^{(t-1)} - x^{*}||_2^2 - 2 \alpha^{(t-1)} ( f(x^{(t-1)}) - f(x^{*}) ) + ( \alpha^{(t-1)} )^2 ||g^{(t-1)}||_2^2 \right) \\
      &amp;amp; \quad - 2 \alpha^{(t)} ( f(x^{(t)}) - f(x^{*}) ) + ( \alpha^{(t)} )^2 ||g^{(t)}||_2^2
      &amp;amp;&amp;amp; \text{# Apply recursion}\\
    = &amp;amp; ||x^{(t-1)} - x^{*}||_2^2
        - 2 \sum_{\tau=t-1}^{t} \alpha^{(\tau)} ( f(x^{(\tau)}) - f(x^{*}) )
        + \sum_{\tau=t-1}^{t} ( \alpha^{(\tau)} )^2 ||g^{(\tau)}||_2^2 \\
  \vdots \\
  \le &amp;amp; ||x^{(0)} - x^{*}||_2^2
        - 2 \sum_{\tau=0}^{t} \alpha^{(\tau)} ( f(x^{(\tau)}) - f(x^{*}) )
        + \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )^2 ||g^{(\tau)}||_2^2 \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Then we drop &lt;span class="math"&gt;\(||x^{(t+1)} - x^{*}||_2^2\)&lt;/span&gt; from the left side it's lower bounded by zero,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  0
  \le &amp;amp; ||x^{(0)} - x^{*}||_2^2
        - 2 \sum_{\tau=0}^{t} \alpha^{(\tau)} ( f(x^{(\tau)}) - f(x^{*}) )
        + \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )^2 ||g^{(\tau)}||_2^2 \\
  2 \sum_{\tau=0}^{t} \alpha^{(\tau)} ( f(x^{(\tau)}) - f(x^{*}) )
  \le &amp;amp; ||x^{(0)} - x^{*}||_2^2
        + \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )^2 ||g^{(\tau)}||_2^2 \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Step 3&lt;/strong&gt; Upper bound current error. First, notice that we can lower bound the
contents of the sum on the left with the minimum across &lt;span class="math"&gt;\(\tau\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \sum_{\tau=0}^{t} \alpha^{(\tau)} ( f(x^{(\tau)}) - f(x^{*}) )
  \ge &amp;amp; \left( \min_{\tau \in 0 \ldots t} f(x^{(\tau)}) - f(x^{*}) \right) \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Then divide by &lt;span class="math"&gt;\(2 \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  2 \left( \min_{\tau \in 0 \ldots t} f(x^{(\tau)}) - f(x^{*}) \right) \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )
  \le &amp;amp; 2 \sum_{\tau=0}^{t} \alpha^{(\tau)} ( f(x^{(\tau)}) - f(x^{*}) ) \\
  \le &amp;amp; ||x^{(0)} - x^{*}||_2^2
          + \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )^2 ||g^{(\tau)}||_2^2 \\
  \left( \min_{\tau \in 0 \ldots t} f(x^{(\tau)}) \right) - f(x^{*})
  \le &amp;amp; \frac{
          ||x^{(0)} - x^{*}||_2^2
          + \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )^2 ||g^{(\tau)}||_2^2
        }{
          2 \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )
        } \\
  \left( \min_{\tau \in 0 \ldots t} f(x^{(\tau)}) \right) - f(x^{*})
  \le &amp;amp; \frac{
          R^2
          + G^2 \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )^2
        }{
          2 \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )
        } \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Step 4&lt;/strong&gt; Making the bound go to zero.  Let &lt;span class="math"&gt;\(\alpha^{(\tau)} = \frac{R}{G
\sqrt{t}}\)&lt;/span&gt; (this is the minimizer of the right hand side for constant
&lt;span class="math"&gt;\(\alpha^{(\tau)}\)&lt;/span&gt;). Then,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  \left( \min_{\tau \in 0 \ldots t} f(x^{(\tau)}) \right) - f(x^{*})
  \le &amp;amp; \frac{
          R^2 + G^2 \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )^2
        }{
          2 \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )
        } \\
    = &amp;amp; \frac{
          R^2 + G^2 \frac{R^2}{G^2} \sum_{\tau=0}^{t} \frac{1}{t+1}
        }{
          2 \frac{R}{G} \sum_{\tau=0}^{t} \frac{1}{\sqrt{t+1}}
        } \\
    = &amp;amp; \frac{ RG }{ 2 \sqrt{t+1} }
        + \frac{ RG } { 2 \sqrt{t+1} }
    = \frac{ RG }{ \sqrt{t+1} }
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Thus, we can conclude that if we want &lt;span class="math"&gt;\(f(x^{(t)}) - f(x^{*}) \le \epsilon\)&lt;/span&gt;,
we need &lt;span class="math"&gt;\(O(\frac{1}{\epsilon^2})\)&lt;/span&gt; iterations. Compared to Gradient
Descent's &lt;span class="math"&gt;\(O(\frac{1}{\epsilon})\)&lt;/span&gt; convergence rate, Subgradient Descent looks
pretty bad!&lt;/p&gt;
&lt;h1&gt;&lt;a name="usage" href="#usage"&gt;When should I use it?&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;As the implementation of Gradient Descent and Subgradient Descent are
essentially the same, ease of use is always the first reason to use Subgradient
Descent. Similarly, Subgradient Descent requires a minimal memory footprint,
and has thus found a large following in the large scale machine learning
community.&lt;/p&gt;
&lt;p&gt;As far as black box, first-order for non-differentiable convex problems go,
it can be shown that Subgradient Descent is as (asymptotically) fast as we can
hope for. That doesn't mean Subgradient Descent is as fast as you can get for
your specific problem. Proximal Gradient methods, for example, are one such
family of algorithms that allow you to exploit the properties of differentiable
problems even if your problem isn't.&lt;/p&gt;
&lt;h1&gt;&lt;a name="extensions" href="#extensions"&gt;Extensions&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Step Size&lt;/strong&gt; As stated previously, a common choice of step size is
&lt;span class="math"&gt;\(\alpha^{(t)} = \frac{1}{t}\)&lt;/span&gt;, but that's far from your only choice. Indeed, any
step rule that satisfies the following conditions works when inserted into the
above proof,&lt;/p&gt;
&lt;div class="math"&gt;$$
  \sum_{t=0}^{\infty} \alpha^{(t)} = \infty \qquad
  \sum_{t=0}^{\infty} ( \alpha^{(t)} )^2 &amp;lt; \infty
$$&lt;/div&gt;
&lt;p&gt;For example, &lt;span class="math"&gt;\(\alpha^{(t)} = \frac{a}{b + t^{c}}\)&lt;/span&gt; for positive constants &lt;span class="math"&gt;\(a\)&lt;/span&gt;
and &lt;span class="math"&gt;\(b\)&lt;/span&gt; and &lt;span class="math"&gt;\(c \in (0.5, 1]\)&lt;/span&gt; also works. These conditions are referred to as
being square-summable but not summable.&lt;/p&gt;
&lt;p&gt;If &lt;span class="math"&gt;\(f(x^{*})\)&lt;/span&gt; is known ahead of time, another choice is &lt;a href="http://www.stanford.edu/class/ee364b/lectures/subgrad_method_slides.pdf"&gt;Polyak's Step
Size&lt;/a&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\alpha^{(t)} = \frac{ f(x^{(t)}) - f(x^{*}) }
                    { ||g^{(t)}||_2^2 }
$$&lt;/div&gt;
&lt;p&gt;If &lt;span class="math"&gt;\(f(x^{*})\)&lt;/span&gt; isn't know, then &lt;span class="math"&gt;\(\alpha^{(t)} = \frac{ f(x^{(t)}) -
f^{(t)}_{best} + \gamma^{(t)} }{ ||g^{(t)}||_2^2 }\)&lt;/span&gt; is also valid for
&lt;span class="math"&gt;\(f^{(t)}_{best} = \min_{\tau \in 0\ldots t} f(x^{(t)})\)&lt;/span&gt; and &lt;span class="math"&gt;\(\gamma^{(t)}\)&lt;/span&gt;
being square-summable and not summable.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Checking Convergence&lt;/strong&gt; In short, there are no easy ways to know when to stop
with Subgradient Descent. Checking if &lt;span class="math"&gt;\(\nabla f(x)\)&lt;/span&gt; is small doesn't make sense
because &lt;span class="math"&gt;\(\nabla f(x)\)&lt;/span&gt; isn't defined at some points and &lt;span class="math"&gt;\(g_x\)&lt;/span&gt; doesn't
necessarily get small near &lt;span class="math"&gt;\(x \triangleq x^{*}\)&lt;/span&gt;. Instead, a fixed number of
iterations is typically used.&lt;/p&gt;
&lt;h1&gt;&lt;a name="references" href="#references"&gt;References&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Proof of Convergence&lt;/strong&gt; The proof of convergence for Subgradient Descent is
taken nearly verbatim from Stephen Boyd's &lt;a href="http://www.stanford.edu/class/ee392o/subgrad_method.pdf"&gt;lecture notes for
EE392o&lt;/a&gt; course in 2003.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Polyak Step Size&lt;/strong&gt; The algorithm for the Polyak step size was taken from
page 23 of Stephen Boyd's &lt;a href="http://www.stanford.edu/class/ee364b/lectures/subgrad_method_slides.pdf"&gt;lecture slides for EE364b&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a name="reference-impl" href="#reference-impl"&gt;Reference Implementation&lt;/a&gt;&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;subgradient_descent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;subgradient&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_iterations&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Subgradient Descent&lt;/span&gt;

&lt;span class="sd"&gt;  Parameters&lt;/span&gt;
&lt;span class="sd"&gt;  ----------&lt;/span&gt;
&lt;span class="sd"&gt;  function : function&lt;/span&gt;
&lt;span class="sd"&gt;      Computes the objective function&lt;/span&gt;
&lt;span class="sd"&gt;  subgradient : function&lt;/span&gt;
&lt;span class="sd"&gt;      Computes a gradient for the objective function at x&lt;/span&gt;
&lt;span class="sd"&gt;  x0 : array&lt;/span&gt;
&lt;span class="sd"&gt;      initial value for x&lt;/span&gt;
&lt;span class="sd"&gt;  alpha : function&lt;/span&gt;
&lt;span class="sd"&gt;      function computing step sizes&lt;/span&gt;
&lt;span class="sd"&gt;  n_iterations : int, optional&lt;/span&gt;
&lt;span class="sd"&gt;      number of iterations to perform&lt;/span&gt;

&lt;span class="sd"&gt;  Returns&lt;/span&gt;
&lt;span class="sd"&gt;  -------&lt;/span&gt;
&lt;span class="sd"&gt;  xs : list&lt;/span&gt;
&lt;span class="sd"&gt;      intermediate values for x&lt;/span&gt;
&lt;span class="sd"&gt;  &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
  &lt;span class="n"&gt;xs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="n"&gt;x_best&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x0&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_iterations&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subgradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;x_plus&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_best&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;
    &lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_plus&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_plus&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_best&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
      &lt;span class="n"&gt;x_best&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x_plus&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;xs&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;polyak&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f_x_best&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f_x&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;f_x_best&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;


&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;

  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pylab&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pl&lt;/span&gt;
  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;yannopt.plotting&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plotting&lt;/span&gt;

  &lt;span class="c1"&gt;### SUBGRADIENT DESCENT ###&lt;/span&gt;

  &lt;span class="n"&gt;function&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;abs&lt;/span&gt;
  &lt;span class="n"&gt;subgradient&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sign&lt;/span&gt;
  &lt;span class="n"&gt;x0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.75&lt;/span&gt;
  &lt;span class="n"&gt;n_iterations&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;

  &lt;span class="n"&gt;iterates&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subgradient_descent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;subgradient&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;polyak&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_iterations&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;n_iterations&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;iterates&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;asarray&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iterates&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="c1"&gt;### PLOTTING ###&lt;/span&gt;

  &lt;span class="n"&gt;plotting&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot_iterates_vs_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iterates&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                     &lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;figures/iterates.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_star&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;plotting&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot_iteration_vs_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iterates&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                      &lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;figures/convergence.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_star&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="optimization"></category><category term="optimization"></category><category term="first-order"></category><category term="subgradient"></category></entry><entry><title>Gradient Descent</title><link href="https://stronglyconvex.com/blog/gradient-descent.html" rel="alternate"></link><published>2013-04-10T00:00:00-07:00</published><updated>2013-04-10T00:00:00-07:00</updated><author><name>Daniel Duckworth</name></author><id>tag:stronglyconvex.com,2013-04-10:/blog/gradient-descent.html</id><summary type="html">&lt;p&gt;Gradient Descent is perhaps the most intuitive of all optimization
algorithms. Imagine you're standing on the side of a mountain and want to reach
the bottom. You'd probably do something like this,&lt;/p&gt;
&lt;div class="pseudocode"&gt;
&lt;ol&gt;
&lt;li&gt;Look around you and see which way points the most downwards&lt;/li&gt;
&lt;li&gt;Take a step in that direction, then …&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;Gradient Descent is perhaps the most intuitive of all optimization
algorithms. Imagine you're standing on the side of a mountain and want to reach
the bottom. You'd probably do something like this,&lt;/p&gt;
&lt;div class="pseudocode"&gt;
&lt;ol&gt;
&lt;li&gt;Look around you and see which way points the most downwards&lt;/li&gt;
&lt;li&gt;Take a step in that direction, then repeat&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;p&gt;Well that's Gradient Descent!&lt;/p&gt;
&lt;h1&gt;&lt;a name="implementation" href="#implementation"&gt;How does it work?&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;So how do we frame Gradient Descent mathematically? As usual, we define our
problem in terms of minimizing a function,&lt;/p&gt;
&lt;div class="math"&gt;$$
  \min_{x} \, f(x)
$$&lt;/div&gt;
&lt;p&gt;We assume that &lt;span class="math"&gt;\(f\)&lt;/span&gt; is differentiable. That is, we can easily compute,&lt;/p&gt;
&lt;div class="math"&gt;$$
  \nabla_x \, f(x) = \begin{pmatrix}
    \frac{d f(x)}{d x_1} \\
    \frac{d f(x)}{d x_2} \\
    \vdots \\
  \end{pmatrix}
$$&lt;/div&gt;
&lt;p&gt;Given this, Gradient Descent is simply the following,&lt;/p&gt;
&lt;!-- TODO Replace well with something more contextually meaningful --&gt;
&lt;div class="pseudocode"&gt;
&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt;: initial iterate &lt;span class="math"&gt;\(x^{(0)}\)&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;For &lt;span class="math"&gt;\(t = 0, 1, \ldots\)&lt;/span&gt;&lt;ol&gt;
&lt;li&gt;if converged, return &lt;span class="math"&gt;\(x^{(t)}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Compute the &lt;a href="http://en.wikipedia.org/wiki/Gradient"&gt;gradient&lt;/a&gt; of &lt;span class="math"&gt;\(f\)&lt;/span&gt; at &lt;span class="math"&gt;\(x^{(t)}\)&lt;/span&gt;, &lt;span class="math"&gt;\(g^{(t)}
   \triangleq \nabla f(x^{(t)})\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(x^{(t+1)} = x^{(t)} - \alpha^{(t)} g^{(t)}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;p&gt;The initial iterate &lt;span class="math"&gt;\(x^{(0)}\)&lt;/span&gt; can be selected arbitrarily, and step size
&lt;span class="math"&gt;\(\alpha^{(t)}\)&lt;/span&gt; can be selected by &lt;a href="#line_search"&gt;Line Search&lt;/a&gt;, a small constant, or
simply &lt;span class="math"&gt;\(\frac{1}{t}\)&lt;/span&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a name="example" href="#example"&gt;A Small Example&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Let's look at Gradient Descent in action. We'll use the objective function
&lt;span class="math"&gt;\(f(x) = x^4\)&lt;/span&gt;, meaning that &lt;span class="math"&gt;\(\nabla_x f(x) = 4 x^3\)&lt;/span&gt;. For a step size, we'll
choose a constant step size &lt;span class="math"&gt;\(\alpha_t = 0.05\)&lt;/span&gt;. Finally, we'll start at &lt;span class="math"&gt;\(x^{(0)}
= 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="img-center"&gt;
  &lt;img src="/assets/img/gradient_descent/animation.gif"&gt;&lt;/img&gt;
  &lt;span class="caption"&gt;
    Gradient Descent in action. The curved line is the $f(x)$, and the flat
    line is its linear approximation, $\hat{f}(y) = f(x) + \nabla_x f(x)^T
    (y-x)$, which is what Gradient Descent follows.
  &lt;/span&gt;
&lt;/div&gt;

&lt;div class="img-center"&gt;
  &lt;img src="/assets/img/gradient_descent/convergence.png"&gt;&lt;/img&gt;
  &lt;span class="caption"&gt;
    This plot shows how quickly the objective function decreases as the
    number of iterations increases.
  &lt;/span&gt;
&lt;/div&gt;

&lt;div class="img-center"&gt;
  &lt;img src="/assets/img/gradient_descent/iterates.png"&gt;&lt;/img&gt;
  &lt;span class="caption"&gt;
    This plot shows the actual iterates and the objective function evaluated at
    those points. More red indicates a higher iteration number.
  &lt;/span&gt;
&lt;/div&gt;

&lt;h1&gt;&lt;a name="proof" href="#proof"&gt;Why does it work?&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Gradient Descent works, but it isn't guaranteed to find the optimal solution
to our problem (that is, &lt;span class="math"&gt;\(x^{*} = \arg\min_{x} f(x)\)&lt;/span&gt;) without a few assumptions.
In particular,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;span class="math"&gt;\(f\)&lt;/span&gt; is convex and finite for all &lt;span class="math"&gt;\(x\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;a finite solution &lt;span class="math"&gt;\(x^{*}\)&lt;/span&gt; exists&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\nabla f(x)\)&lt;/span&gt; is Lipschitz continuous with constant &lt;span class="math"&gt;\(L\)&lt;/span&gt;. If &lt;span class="math"&gt;\(f\)&lt;/span&gt; is twice
   differentiable, this means that the largest eigenvalue of the Hessian is
   bounded by &lt;span class="math"&gt;\(L\)&lt;/span&gt; (&lt;span class="math"&gt;\(\nabla^2 f(x) \preceq LI\)&lt;/span&gt;). But more directly, there must
   be an &lt;span class="math"&gt;\(L\)&lt;/span&gt; such that,&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="math"&gt;$$
  || \nabla f(x) - \nabla f(y) ||_2 \le L || x - y ||_2 \qquad \forall x,y
$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Assumptions&lt;/strong&gt; So what do these assumptions give us?  Assumption 1 tells us
that &lt;span class="math"&gt;\(f\)&lt;/span&gt; is lower bounded by an affine function,&lt;/p&gt;
&lt;div class="math"&gt;$$
  f(y) \ge f(x) + \nabla f(x)^T (y - x)  \qquad \forall x,y
$$&lt;/div&gt;
&lt;p&gt;Assumption 3 also tells us that &lt;span class="math"&gt;\(f\)&lt;/span&gt; is upper bounded by a quadratic (this is
not obvious),&lt;/p&gt;
&lt;div class="math"&gt;$$
  f(y) \le f(x) + \nabla f(x)^T (y - x) + \frac{L}{2} || y - x ||_2^2
$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Proof Outline&lt;/strong&gt; Now let's dive into the proof. Our plan of attack is as
follows. First, we upper bound the error &lt;span class="math"&gt;\(f(x^{(t+1)}) - f(x^{*})\)&lt;/span&gt; in terms of
&lt;span class="math"&gt;\(||x^{(t)} - x^{*}||_2^2\)&lt;/span&gt; and &lt;span class="math"&gt;\(||x^{(t+1)} - x^{*}||_2^2\)&lt;/span&gt;.  We then sum these upper
bounds across &lt;span class="math"&gt;\(t\)&lt;/span&gt; to upper bound the sum of errors in terms of &lt;span class="math"&gt;\(||x^{(0)} -
x^{*}||_2^2\)&lt;/span&gt;. Finally, we use the fact that &lt;span class="math"&gt;\(f(x^{(t)})\)&lt;/span&gt; is decreasing in &lt;span class="math"&gt;\(t\)&lt;/span&gt; to
take an average of that sum to bound &lt;span class="math"&gt;\(f(x^{(t+1)}) - f(x^{*})\)&lt;/span&gt; in terms of &lt;span class="math"&gt;\(||x^{(0)}
- x^{*}||_2^2\)&lt;/span&gt; and &lt;span class="math"&gt;\(t\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1&lt;/strong&gt;: upper bounding &lt;span class="math"&gt;\(f(x^{(t+1)}) - f(x^{*})\)&lt;/span&gt;.  Let &lt;span class="math"&gt;\(x^{+} \triangleq
x^{(t+1)}\)&lt;/span&gt;, &lt;span class="math"&gt;\(x \triangleq x^{(t)}\)&lt;/span&gt;, and &lt;span class="math"&gt;\(\alpha \triangleq \alpha^{(t)}\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  f(x^{+})
  \le &amp;amp; f(x) + \nabla f(x)^T (x^{+} - x) + \frac{L}{2}||x^{+} - x||_2^2 &amp;amp;&amp;amp; \text{# Quadratic upper bound} \\
  = &amp;amp; f(x) + \nabla f(x)^T (- \alpha \nabla f(x)) + \frac{L}{2}||- \alpha \nabla f(x)||_2^2 &amp;amp;&amp;amp; \text{# Definition of $x^{+}$} \\
  = &amp;amp; f(x) - \alpha || \nabla f(x) ||_2^2 + \frac{\alpha^2 L}{2} ||\nabla f(x)||_2^2 \\
  = &amp;amp; f(x) - \alpha\left( 1 - \frac{\alpha L}{2} \right) || \nabla f(x) ||_2^2  \\
  \le &amp;amp; f(x) - \frac{\alpha}{2} || \nabla f(x) ||_2^2  &amp;amp;&amp;amp; \text{# Assuming $\frac{\alpha L}{2} \leq \frac{1}{2}$} \\
  \le &amp;amp; f(x^{*}) + \nabla f(x)^T (x - x^{*}) - \frac{\alpha}{2} || \nabla f(x) ||_2^2  &amp;amp;&amp;amp; \text{# Linear lower bound on $f(x)$} \\
  = &amp;amp; f(x^{*}) + \nabla f(x)^T (x - x^{*}) - \frac{\alpha}{2} || \nabla f(x) ||_2^2 \\
    &amp;amp; \quad \pm \frac{1}{2 \alpha} \left( ||x||_2^2 + ||x^{*}||_2^2 + x^T x^{*} \right)\\
  = &amp;amp; f(x^{*}) + \frac{1}{2 \alpha} \left(
      ||x - x^{*}||_2^2 - ||(x - \alpha \nabla f(x)) - x^{*}||_2^2
    \right) \\
  = &amp;amp; f(x^{*}) + \frac{1}{2 \alpha} \left(
      ||x - x^{*}||_2^2 - ||x^{+} - x^{*}||_2^2
    \right) \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Step 2&lt;/strong&gt;: Upper bound &lt;span class="math"&gt;\(\sum_{t=1}^{T} f(x^{(t)}) - f(x^{*})\)&lt;/span&gt; by summing across
all &lt;span class="math"&gt;\(t\)&lt;/span&gt;. At this point we'll assume that &lt;span class="math"&gt;\(\alpha^{(t)}\)&lt;/span&gt; is the same for all
&lt;span class="math"&gt;\(t\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  f(x^{(t)}) - f(x^{*})
  &amp;amp; \le \frac{1}{2 \alpha^{(t)}} \left(
    ||x^{(t)} - x^{*}||_2^2 - ||x^{(t+1)} - x^{*}||_2^2
  \right) \\
  \sum_{t=1}^{T} f(x^{(t)}) - f(x^{*})
  &amp;amp; \le \frac{1}{2 \alpha} \sum_{t=1}^{T} \left(
    ||x^{(t)} - x^{*}||_2^2 - ||x^{(t+1)} - x^{*}||_2^2
  \right) \\
  &amp;amp; = \frac{1}{2 \alpha} \left(
    ||x^{(0)} - x^{*}||_2^2 - ||x_1 - x^{*}||_2^2 + ||x_1 - x^{*}||_2^2 - ||x_2 - x^{*}||_2^2 + \ldots
  \right) \\
  &amp;amp; = \frac{1}{2 \alpha} \left( ||x^{(0)} - x^{*}||_2^2 - ||x^{(t)} - x^{*}||_2^2
  \right) \\
  &amp;amp; \le \frac{1}{2 \alpha} ||x^{(0)} - x^{*}||_2^2 \\
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Step 3&lt;/strong&gt;: Upper bound &lt;span class="math"&gt;\(f(x^{(t+1)}) - f(x^{*})\)&lt;/span&gt; by using the fact that
&lt;span class="math"&gt;\(f(x^{(t+1)}) &amp;lt; f(x^{(t)})\)&lt;/span&gt;&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
  f(x^{(T)}) - f(x^{*})
  &amp;amp; \le \frac{1}{T} \sum_{t=1}^{T} ( f(x^{(t)}) - f(x^{*}) ) \\
  &amp;amp; \le \frac{1}{2 \alpha T} ||x^{(0)} - x^{*}||_2^2
\end{align*}
$$&lt;/div&gt;
&lt;p&gt;Thus, we can conclude that if we want to reach an error tolerance &lt;span class="math"&gt;\(f(x^{T}) -
f(x^{*}) \le \epsilon\)&lt;/span&gt;, we need &lt;span class="math"&gt;\(O(\frac{1}{\epsilon})\)&lt;/span&gt; iterations.  In other
words, Gradient Descent has a "convergence rate" of &lt;span class="math"&gt;\(O(\frac{1}{T})\)&lt;/span&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a name="usage" href="#usage"&gt;When should I use it?&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Because it's so easy to implement, Gradient Descent should be the first thing
to try if you need to implement an optimization from scratch. So long as you
calculate the gradient right, it's practically impossible to make a mistake.
If you have access to an &lt;a href="http://justindomke.wordpress.com/2009/02/17/automatic-differentiation-the-most-criminally-underused-tool-in-the-potential-machine-learning-toolbox/"&gt;automatic differentiation library&lt;/a&gt; to do
the gradient computation for you, even better!  In addition, Gradient Descent
requires a minimal memory footprint, making it ideal for problems where &lt;span class="math"&gt;\(x\)&lt;/span&gt; is
very high dimensional.&lt;/p&gt;
&lt;p&gt;As we'll see in later posts, Gradient Descent trades memory for speed. The
number of iterations required to reach a desired accuracy is actually quite
large if you want accuracy on the order of &lt;span class="math"&gt;\(10^{-8}\)&lt;/span&gt;, and there are algorithms
that are much faster if computation of the &lt;a href="http://en.wikipedia.org/wiki/Hessian_matrix"&gt;Hessian&lt;/a&gt; is feasible.
Even when considering the same memory requirements, there is another
gradient-based method with better convergence rates. &lt;/p&gt;
&lt;h1&gt;&lt;a name="extensions" href="#extensions"&gt;Extensions&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Step Size&lt;/strong&gt; The proof above relies on a constant step size, but quicker
convergence can be obtained when using &lt;a href="#line_search"&gt;Line Search&lt;/a&gt;, wherein
&lt;span class="math"&gt;\(\alpha^{(t)}\)&lt;/span&gt; is chosen to (approximately) find &lt;span class="math"&gt;\(\alpha^{(t)} = \arg\min_{\alpha}
f(x^{(t)} - \alpha \nabla f(x^{(t)}))\)&lt;/span&gt;. Keep in mind that unless &lt;span class="math"&gt;\(0 \le t \le
\frac{1}{L}\)&lt;/span&gt;, &lt;em&gt;Gradient Descent will not converge!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Checking Convergence&lt;/strong&gt; We have shown that the algorithm's error at iteration
&lt;span class="math"&gt;\(T\)&lt;/span&gt; relies on &lt;span class="math"&gt;\(T\)&lt;/span&gt; and the distance between &lt;span class="math"&gt;\(x^{(0)}\)&lt;/span&gt; and &lt;span class="math"&gt;\(x^{*}\)&lt;/span&gt;, the latter of
which is unknown.  How then can we check if we're "close enough"? A typical
choice is simply to stop after a fixed number of iterations, but another common
alternative is to quit when &lt;span class="math"&gt;\(||\nabla f(x^{(t)})||_2 &amp;lt; \epsilon_{g}\)&lt;/span&gt; for a
chosen &lt;span class="math"&gt;\(\epsilon_{g}\)&lt;/span&gt;.  The intuition for this comes from the assumption that
&lt;span class="math"&gt;\(f\)&lt;/span&gt; is "strongly convex" with constant &lt;span class="math"&gt;\(m\)&lt;/span&gt;, which then implies that &lt;span class="math"&gt;\(||x -
x^{*}||_2 \le \frac{2}{m}||\nabla f(x)||_2\)&lt;/span&gt; (see &lt;a href="http://www.stanford.edu/~boyd/cvxbook/"&gt;Convex
Optimization&lt;/a&gt;, page 460, equation 9.10).&lt;/p&gt;
&lt;h1&gt;&lt;a name="references" href="#references"&gt;References&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Proof of Convergence&lt;/strong&gt; The proof of convergence for Gradient Descent is
adapted from slide 1-18 of of UCLA's &lt;a href="http://www.ee.ucla.edu/~vandenbe/236C/lectures/gradient.pdf"&gt;EE236C lecture on Gradient
Methods&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a id="line_search"&gt;&lt;/a&gt;
  &lt;strong&gt;Line Search&lt;/strong&gt; The algorithm for Backtracking Line Search, a smart method
for choosing step sizes, can be found on slide 10-6 of UCLA's &lt;a href="http://www.ee.ucla.edu/ee236b/lectures/unconstrained.pdf"&gt;EE236b lecture
on unconstrained optimization&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a name="reference-impl" href="#reference-impl"&gt;Reference Implementation&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Here's a quick implementation of gradient descent,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;gradient_descent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_iterations&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Gradient Descent&lt;/span&gt;

&lt;span class="sd"&gt;  Parameters&lt;/span&gt;
&lt;span class="sd"&gt;  ----------&lt;/span&gt;
&lt;span class="sd"&gt;  gradient : function&lt;/span&gt;
&lt;span class="sd"&gt;      Computes the gradient of the objective function at x&lt;/span&gt;
&lt;span class="sd"&gt;  x0 : array&lt;/span&gt;
&lt;span class="sd"&gt;      initial value for x&lt;/span&gt;
&lt;span class="sd"&gt;  alpha : function&lt;/span&gt;
&lt;span class="sd"&gt;      function computing step sizes&lt;/span&gt;
&lt;span class="sd"&gt;  n_iterations : int, optional&lt;/span&gt;
&lt;span class="sd"&gt;      number of iterations to perform&lt;/span&gt;

&lt;span class="sd"&gt;  Returns&lt;/span&gt;
&lt;span class="sd"&gt;  -------&lt;/span&gt;
&lt;span class="sd"&gt;  xs : list&lt;/span&gt;
&lt;span class="sd"&gt;      intermediate values for x&lt;/span&gt;
&lt;span class="sd"&gt;  &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
  &lt;span class="n"&gt;xs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_iterations&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;x_plus&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;
    &lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_plus&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;xs&lt;/span&gt;

&lt;span class="c1"&gt;# This generates the plots that appear above&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;

  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pylab&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pl&lt;/span&gt;
  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;yannopt.plotting&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plotting&lt;/span&gt;

  &lt;span class="c1"&gt;### GRADIENT DESCENT ###&lt;/span&gt;

  &lt;span class="c1"&gt;# problem definition&lt;/span&gt;
  &lt;span class="n"&gt;function&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;  &lt;span class="c1"&gt;# the function to minimize&lt;/span&gt;
  &lt;span class="n"&gt;gradient&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;  &lt;span class="c1"&gt;# its gradient&lt;/span&gt;
  &lt;span class="n"&gt;step_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.05&lt;/span&gt;
  &lt;span class="n"&gt;x0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;
  &lt;span class="n"&gt;n_iterations&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;

  &lt;span class="c1"&gt;# run gradient descent&lt;/span&gt;
  &lt;span class="n"&gt;iterates&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gradient_descent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;step_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_iterations&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;n_iterations&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="c1"&gt;### PLOTTING ###&lt;/span&gt;

  &lt;span class="n"&gt;plotting&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot_iterates_vs_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iterates&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                     &lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;figures/iterates.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_star&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;plotting&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot_iteration_vs_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iterates&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                      &lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;figures/convergence.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_star&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="c1"&gt;# make animation&lt;/span&gt;
  &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;makedirs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;figures/animation&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;OSError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;pass&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_iterations&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;iterates&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;x_plus&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;iterates&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;
    &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gradient&lt;/span&gt;
    &lt;span class="n"&gt;f_hat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;x_min&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;
    &lt;span class="n"&gt;x_max&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;

    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;x&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;f(x)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;x_min&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_max&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;f_hat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_min&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;f_hat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_max&lt;/span&gt;&lt;span class="p"&gt;)],&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;--&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_plus&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_plus&lt;/span&gt;&lt;span class="p"&gt;)],&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;figures/animation/&lt;/span&gt;&lt;span class="si"&gt;%02d&lt;/span&gt;&lt;span class="s1"&gt;.png&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="optimization"></category><category term="gradient"></category><category term="descent"></category><category term="first-order"></category><category term="optimization"></category></entry><entry><title>Topic Models aren't hard</title><link href="https://stronglyconvex.com/blog/topic-models-arent-hard.html" rel="alternate"></link><published>2013-01-21T00:00:00-08:00</published><updated>2013-01-21T00:00:00-08:00</updated><author><name>Daniel Duckworth</name></author><id>tag:stronglyconvex.com,2013-01-21:/blog/topic-models-arent-hard.html</id><summary type="html">&lt;p&gt;In 2002, &lt;a href="http://www.cs.princeton.edu/~blei/papers/BleiNgJordan2003.pdf"&gt;Latent Dirichlet Allocation&lt;/a&gt; (LDA) was published at NIPS, one
of the most highly regarded conferences for research loosely labeled as
"Artificial Intelligence". The next 5 or so years led to a flurry of
incremental model extensions and alternative inference methods, though none
have achieved the popularity of their …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In 2002, &lt;a href="http://www.cs.princeton.edu/~blei/papers/BleiNgJordan2003.pdf"&gt;Latent Dirichlet Allocation&lt;/a&gt; (LDA) was published at NIPS, one
of the most highly regarded conferences for research loosely labeled as
"Artificial Intelligence". The next 5 or so years led to a flurry of
incremental model extensions and alternative inference methods, though none
have achieved the popularity of their namesake.&lt;/p&gt;
&lt;p&gt;Latent Dirichlet Allocation -- an extremely complex name for a not-so-complex
idea. In this post, I will explain what the LDA model says, what it does &lt;em&gt;not&lt;/em&gt;
say, and how we as researchers should look at it.&lt;/p&gt;
&lt;h1&gt;&lt;a name="model" href="#model"&gt;The Model&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Let's begin by appreciating Latent Dirichlet Allocation in its most natural
form -- the graphical model.  I hope you like Greek letters...&lt;/p&gt;
&lt;div class="img-center"&gt;
  &lt;img src="/assets/img/lda/graphical-model.png"&gt;&lt;/img&gt;
&lt;/div&gt;

&lt;p&gt;About now, you should have an ephemeral feeling of happiness and
understanding beyond anything you've ever experienced before, as if your eyes
had just opened for the first time.  Do you feel it? No? Yeah, I didn't think
so.&lt;/p&gt;
&lt;p&gt;Let's break it down a little, without the math.  Take a look at the following
4 plots.  Each subplot contains samples drawn from 1 of 3 clusters, and each
plot contains samples from the same clusters.  The difference between each
subplot is that the &lt;em&gt;number of samples&lt;/em&gt; from each cluster is different.&lt;/p&gt;
&lt;div class="img-center"&gt;
  &lt;img src="/assets/img/lda/gaussians-nocolor.jpg"&gt;&lt;/img&gt;
&lt;/div&gt;

&lt;p&gt;Having trouble?  It's a rather difficult problem, especially with only 4
subplots. What if you had a 100,000 subplots instead? Do you think you could
figure it out then?  Here's a plot of the same data with points colored
according to their cluster,&lt;/p&gt;
&lt;div class="img-center"&gt;
  &lt;img src="/assets/img/lda/gaussians-color.jpg"&gt;&lt;/img&gt;
&lt;/div&gt;

&lt;p&gt;Even if you don't realize it yet, you now understand Latent Dirichlet
Allocation. In fact, Latent Dirichlet Allocation is just an extension of the
lowly Mixture Model.  "How so?", you ask?  Well let's look at how we might
generate data from a Mixture Model.&lt;/p&gt;
&lt;p&gt;In a mixture model, each data point is sampled independently. The algorithm
for generating a sample given the model's parameters is given by the following
python snippet.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sample_mixture_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_data_points&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cluster_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cluster_parameters&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_data_points&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;cluster&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sample_categorical&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cluster_weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;variance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cluster_parameters&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;cluster&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;sample_normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;variance&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Simple, right?  First, a cluster is chosen for this data point. Each cluster
has some probability of being chosen, given by &lt;code&gt;cluster_weights[i]&lt;/code&gt;.  Once a
cluster has been chosen, the data point is generated from a Normal distribution
with mean and covariance specific to the cluster.  The idea is that each
cluster has its own mean and covariance, so with enough samples we'll be able
to tell the clusters apart.&lt;/p&gt;
&lt;p&gt;So how does this relate to LDA?  In LDA, each "document" (in our case,
subplot) is nothing more than a Mixture Model. The novel part of LDA is that
there isn't just one document that we see a ton of samples from, but many
documents that we only see a few samples from.  Furthermore, each document has
its own version of &lt;code&gt;cluster_weights&lt;/code&gt; -- our only boon is that all documents
share the same &lt;code&gt;cluster_parameters&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To make that concrete, let's look at how we would generate samples from LDA.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sample_lda&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_data_points_per_document&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;all_cluster_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cluster_parameters&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;n_documents&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;all_cluster_weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# number of documents&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_documents&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;sample&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sample_mixture_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_data_points_per_document&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                       &lt;span class="n"&gt;all_cluster_weights&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                                       &lt;span class="n"&gt;cluster_parameters&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
      &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;document_number&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;data_point&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;sample&lt;/span&gt;
      &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Notice that here we don't just return the data point by itself.  In LDA, we
know which "document" each data point comes from, which is just a little bit
more information than we have in a regular old Mixture Model.&lt;/p&gt;
&lt;p&gt;Finally, I have to admit that I lied a little.  What I've described so far
isn't &lt;em&gt;quite&lt;/em&gt; LDA, but it's pretty damn close.  In the above pseudocode, I
assumed that the model parameters were already given, but LDA actually
assumes the parameters are unknown and defines a probability distribution over
them (a &lt;a href="http://en.wikipedia.org/wiki/Dirichlet_distribution"&gt;Dirichlet distribution&lt;/a&gt;, in fact).  Secondly, the examples
above generate data points from Normal distributions where as LDA generates
samples from the &lt;a href="http://en.wikipedia.org/wiki/Multinomial_distribution"&gt;Multinomial distribution&lt;/a&gt;. Other than that, you
now understand Latent Dirichlet Allocation, the core of nearly every Topic
Model in existence.&lt;/p&gt;
&lt;h1&gt;&lt;a name="appendix" href="#appendix"&gt;Appendix&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Here's the MATLAB code for generating the two plots above.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c"&gt;%% parameters&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;n_clusters&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;n_documents&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="c"&gt;%% reset ye olde random seed&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;RandStream&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;mcg16807&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Seed&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nb"&gt;RandStream&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setDefaultStream&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="c"&gt;%% generate parameters for each cluster&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;i&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;n_clusters&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="p"&gt;(:,&lt;/span&gt;&lt;span class="nb"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;(:,:,&lt;/span&gt;&lt;span class="nb"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;eye&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;(:,:,&lt;/span&gt;&lt;span class="nb"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;(:,:,&lt;/span&gt;&lt;span class="nb"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;(:,:,&lt;/span&gt;&lt;span class="nb"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;(:,:,&lt;/span&gt;&lt;span class="nb"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;(:,:,&lt;/span&gt;&lt;span class="nb"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;250&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nb"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;hold&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;on&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;n_documents&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c"&gt;%% generate document-specific weights&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_clusters&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c"&gt;%% generate samples for this document&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;i&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:(&lt;/span&gt;&lt;span class="n"&gt;n_samples&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(:,&lt;/span&gt;&lt;span class="nb"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mnrnd&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(:,&lt;/span&gt;&lt;span class="nb"&gt;i&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;(:,&lt;/span&gt;&lt;span class="nb"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mvnrnd&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="p"&gt;(:,&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;(:,:,&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)));&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;end&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c"&gt;%% plotting! yay!&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nb"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c"&gt;% without color&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nb"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,:),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,:));&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c"&gt;% with color&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c"&gt;% scatter(x(1,:), x(2,:), &amp;#39;CData&amp;#39;, c&amp;#39;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content><category term="topic-models"></category><category term="topic-models"></category><category term="bayesian"></category><category term="lda"></category></entry><entry><title>ADMM: parallelizing convex optimization</title><link href="https://stronglyconvex.com/blog/admm.html" rel="alternate"></link><published>2012-06-24T00:00:00-07:00</published><updated>2012-06-24T00:00:00-07:00</updated><author><name>Daniel Duckworth</name></author><id>tag:stronglyconvex.com,2012-06-24:/blog/admm.html</id><summary type="html">&lt;p&gt;In the previous post, we considered Stochastic Gradient Descent, a popular method for optimizing "separable" functions (that is, functions that are purely sums of other functions) in a large, distributed environment. However, Stochastic Gradient Descent is not the only algorithm out there.&lt;/p&gt;
&lt;p&gt;So why consider anything else? First of all …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In the previous post, we considered Stochastic Gradient Descent, a popular method for optimizing "separable" functions (that is, functions that are purely sums of other functions) in a large, distributed environment. However, Stochastic Gradient Descent is not the only algorithm out there.&lt;/p&gt;
&lt;p&gt;So why consider anything else? First of all, we have to choose step sizes &lt;span class="math"&gt;\(\alpha_{t,i}\)&lt;/span&gt;. While there are theoretical constraints on how it must behave (e.g. &lt;span class="math"&gt;\(\alpha_t = \frac{1}{t^k}\)&lt;/span&gt; is guaranteed to converge), there is a lot of freedom in the constants, and finding just the right one can be painful. It often ends up that even though Stochastic Gradient Descent guarantees an asymptotic convergence rate, you only have enough time to make a handful of passes over the dataset, far too little time for the asymptotics to kick in.&lt;/p&gt;
&lt;p&gt;Secondly, Stochastic Gradient Descent is naturally &lt;em&gt;sequential&lt;/em&gt;. You have to update &lt;span class="math"&gt;\(w_{t,i}\)&lt;/span&gt; before you can update &lt;span class="math"&gt;\(w_{t,i+1}\)&lt;/span&gt; (well, not quite. See &lt;a href="http://arxiv.org/abs/1106.5730"&gt;HOGWILD!&lt;/a&gt;). This means that Stochastic Gradient Descent is great for data streaming in one-by-one, but isn't of much help in MapReduce-style frameworks.&lt;/p&gt;
&lt;p&gt;Alternating Direction Method of Multipliers (ADMM) is an entirely different method of distributed optimization that is far better oriented for MapReduce and which only requires a single parameter to specify the learning rate. However, using it requires quite a bit more mathematical preparation.&lt;/p&gt;
&lt;p&gt;The basic idea is that if we have an optimization problem specified as follows,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align}
  &amp;amp; \min_{x,z} f(x) + g(z)  \\
  &amp;amp; \text{s.t. } A x + B z = c
\end{align}
$$&lt;/div&gt;
&lt;p&gt;Then we can derive the Lagrangian and add a quadratic penalty for violating the constraint,&lt;/p&gt;
&lt;div class="math"&gt;$$
L_{\rho}(x,z,y) = f(x) + g(z) + y^T (Ax + Bz -c) + \frac{\rho}{2} || Ax + Bz - c ||_2^2
$$&lt;/div&gt;
&lt;p&gt;Finally we apply the following algorithm&lt;/p&gt;
&lt;div class="pseudocode"&gt;
&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt; Initial primal and dual iterates &lt;span class="math"&gt;\(x_{0}\)&lt;/span&gt;, &lt;span class="math"&gt;\(z_{0}\)&lt;/span&gt;, and &lt;span class="math"&gt;\(y_{0}\)&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Optimize over the first primal variable,&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$
  x_{t+1} = \text{argmin}_x L_{\rho}(x,z_t, y_t)
$$&lt;/div&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Optimize over the second primal variable,&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$
  z_{t+1} = \text{argmin}_x L_{\rho}(x_{t+1},z, y_t)
$$&lt;/div&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Take a gradient step for the dual variable&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$
  y_{t+1} = y_t + \rho (A x_{t+1} + B z_{t+1} - c)
$$&lt;/div&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;p&gt;Notice the choice of step size for updating &lt;span class="math"&gt;\(y_t\)&lt;/span&gt; and the addition of a quadratic term to the Lagrangian; these are the critical addition of ADMM.&lt;/p&gt;
&lt;p&gt;The question now becomes, how can we apply this seemingly restricted method to make a distributed algorithm? Suppose we want to minimize our usual separable function&lt;/p&gt;
&lt;div class="math"&gt;$$
\min_x \sum_i f_i(x)
$$&lt;/div&gt;
&lt;p&gt;We can reformulate this problem by giving each &lt;span class="math"&gt;\(f_i\)&lt;/span&gt; its own &lt;span class="math"&gt;\(x_i\)&lt;/span&gt;, and requiring that &lt;span class="math"&gt;\(x_i = z\)&lt;/span&gt; at the very end.&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align}
  &amp;amp; \min_{x_i, z} \sum_i f_i(x_i)   \\
  &amp;amp; \text{s.t.} \quad \forall i \quad x_i = z
\end{align}
$$&lt;/div&gt;
&lt;p&gt;This means that we can optimize each &lt;span class="math"&gt;\(x_i\)&lt;/span&gt; independently, then aggregate their solutions to update &lt;span class="math"&gt;\(z\)&lt;/span&gt; (the one true &lt;span class="math"&gt;\(x\)&lt;/span&gt;), and finally use both of those to update &lt;span class="math"&gt;\(y\)&lt;/span&gt;. Let's see how this works out exactly. The augmented Lagrangian would be,&lt;/p&gt;
&lt;div class="math"&gt;$$
L_{\rho}(x,z,y) = \sum_{i} \left( 
    f_i(x_i) + y^T (x_i - z) + \frac{\rho}{2} || x_i - z ||_2^2
  \right)
$$&lt;/div&gt;
&lt;div class="pseudocode"&gt;
&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt; Initial primal and dual iterates &lt;span class="math"&gt;\(x_{0}\)&lt;/span&gt;, and &lt;span class="math"&gt;\(y_{0}\)&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;For each machine &lt;span class="math"&gt;\(i\)&lt;/span&gt; in parallel, optimize the local variable &lt;span class="math"&gt;\(x_i\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$
\begin{align}
  x_{t+1, i} &amp;amp; = \text{argmin}_x f_i(x) 
    + y_{t,i}^T (x - z_t) 
    + \frac{\rho}{2} (x-z)^T (x-z) \\
\end{align}
$$&lt;/div&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Aggregate the resulting &lt;span class="math"&gt;\(x_{t,i+1}\)&lt;/span&gt; and optimize the global variable &lt;span class="math"&gt;\(z\)&lt;/span&gt;,&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$
\begin{align}
  z_{t+1} &amp;amp;= \text{argmin}_z y_{t,i}^T (x_{t+1, i} - z) 
    + \frac{\rho}{2} (x_{t+1, i} - z)^T (x_{t+1, i} - z)  \\
  &amp;amp;= \frac{1}{N} \sum_{i=1}^{N} \left( 
    x_{t+1, i} + \frac{1}{\rho} y_{t, i}
  \right)
\end{align}
$$&lt;/div&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Update the dual variables &lt;span class="math"&gt;\(y_{t,i}\)&lt;/span&gt;,&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$
  y_{t+1, i} = y_{t, i} + \rho ( x_{t+1,i} - z_{t+1} )
$$&lt;/div&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;p&gt;This is already pretty cool, but there's even more. It ends up that ADMM works splendidly even when we add a regularization penalty to the primal problem, such as the &lt;span class="math"&gt;\(L_2\)&lt;/span&gt; or &lt;span class="math"&gt;\(L_1\)&lt;/span&gt; norm. You can find out all of these cool things and more in the Stephen Boyd's &lt;a href="http://www.stanford.edu/~boyd/papers/pdf/admm_distr_stats.pdf"&gt;paper&lt;/a&gt; and &lt;a href="http://videolectures.net/nipsworkshops2011_boyd_multipliers/"&gt;lecture&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;On a final note, the proofs on convergence for ADMM are currently not as complete as those for other methods like Stochastic Gradient Descent. While it is known that the dual variable &lt;span class="math"&gt;\(y_t\)&lt;/span&gt; will converge as long as &lt;span class="math"&gt;\(f\)&lt;/span&gt; and &lt;span class="math"&gt;\(g\)&lt;/span&gt; are convex and a solution exists, we can only prove convergence of the primal variables &lt;span class="math"&gt;\(x_t\)&lt;/span&gt; and &lt;span class="math"&gt;\(z_t\)&lt;/span&gt; if they are constrained to lie in a polyhedron at this point in time.&lt;/p&gt;
&lt;h1&gt;&lt;a name="references" href="#references"&gt;References&lt;/a&gt;&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.stanford.edu/~boyd/papers/pdf/admm_distr_stats.pdf"&gt;Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/pdf/1112.2295.pdf"&gt;A Proof of Convergence For the Alternating Direction Method of Multipliers Applied to Polyhedral-Constrained Functions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1106.5730"&gt;HOGWILD!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://videolectures.net/nipsworkshops2011_boyd_multipliers/"&gt;Alternating Direction Method of Multipliers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="optimization"></category><category term="admm"></category><category term="optimization"></category><category term="distributed"></category></entry><entry><title>Stochastic Gradient Descent and Sparse $L_2$ regularization</title><link href="https://stronglyconvex.com/blog/sparse-l2.html" rel="alternate"></link><published>2012-05-10T00:00:00-07:00</published><updated>2012-05-10T00:00:00-07:00</updated><author><name>Daniel Duckworth</name></author><id>tag:stronglyconvex.com,2012-05-10:/blog/sparse-l2.html</id><summary type="html">&lt;p&gt;Suppose you’re doing some typical supervised learning on a gigantic dataset where the total loss over all samples for parameter &lt;span class="math"&gt;\(w\)&lt;/span&gt; is simply the sum of the losses of each sample &lt;span class="math"&gt;\(i\)&lt;/span&gt;, i.e.,&lt;/p&gt;
&lt;div class="math"&gt;$$
  L(w) = \sum_{i} l(x_i, y_i, w)
$$&lt;/div&gt;
&lt;p&gt;Basically any loss function you can think …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Suppose you’re doing some typical supervised learning on a gigantic dataset where the total loss over all samples for parameter &lt;span class="math"&gt;\(w\)&lt;/span&gt; is simply the sum of the losses of each sample &lt;span class="math"&gt;\(i\)&lt;/span&gt;, i.e.,&lt;/p&gt;
&lt;div class="math"&gt;$$
  L(w) = \sum_{i} l(x_i, y_i, w)
$$&lt;/div&gt;
&lt;p&gt;Basically any loss function you can think of in the i.i.d sample regime can be composed this way. Since we assumed that your dataset was huge, there's no way you’re going to be able to load it all into memory for BFGS, so you choose to use Stochastic Gradient Descent. The update for sample &lt;span class="math"&gt;\(i\)&lt;/span&gt; with step size &lt;span class="math"&gt;\(\eta_t\)&lt;/span&gt; would then be,&lt;/p&gt;
&lt;div class="math"&gt;$$
  w_{t+1} = w_t - \eta_t \nabla_w l(x_i, y_i, w_t)
$$&lt;/div&gt;
&lt;p&gt;So far, so good. If &lt;span class="math"&gt;\(\nabla_w l(x_i, y_i, w)\)&lt;/span&gt; is sparse, then you only need to change a handful of &lt;span class="math"&gt;\(w\)&lt;/span&gt;'s components. Of course, being the astute Machine Learning expert that you are, you know that you’re going to need some regularization. Let's redefine the total loss and take a look at our new update equation,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{aligned}
  L(w) &amp;amp; = \sum_{i} l(x_i, y_i, w) + \frac{\lambda}{2}||w||_2^2  \\
  w_{t+1} &amp;amp; = w_t - \eta_t \left( \nabla_w l(x_i, y_i, w_t) + \lambda w_t \right)
\end{aligned}
$$&lt;/div&gt;
&lt;p&gt;Uh oh. Now that &lt;span class="math"&gt;\(w\)&lt;/span&gt; appears in our Stochastic Gradient Descent update equation, you’re going to have change every non-zero element of &lt;span class="math"&gt;\(w\)&lt;/span&gt; at every iteration, even if &lt;span class="math"&gt;\(\nabla_w l(x_i, y_i, w)\)&lt;/span&gt; is sparse! Whatever shall you do?&lt;/p&gt;
&lt;p&gt;The answer isn't as scary as you might think. Let’s do some algebraic manipulation from &lt;span class="math"&gt;\(t = 0\)&lt;/span&gt;,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{aligned}
  w_{1}
  &amp;amp; = w_0 - \eta_0 \left( \nabla_w l(x_i, y_i, w_0) + \lambda w_0 \right) \\
  &amp;amp; = w_0 - \eta_0 \nabla_w l(x_i, y_i, w_0) - \eta_0 \lambda w_0 \\
  &amp;amp; = (1 - \eta_0 \lambda ) w_0 - \eta_0 \nabla_w l(x_i, y_i, w_0) \\
  &amp;amp; = (1 - \eta_0 \lambda ) \left(
      w_0 - \frac{\eta_0}{1-\eta_0 \lambda } \nabla_w l(x_i, y_i, w_0)
    \right) \\
\end{aligned}
$$&lt;/div&gt;
&lt;p&gt;Do you see it now? &lt;span class="math"&gt;\(L_2\)&lt;/span&gt; regularization is really just a rescaling of &lt;span class="math"&gt;\(w_t\)&lt;/span&gt; at every iteration. Thus instead of keeping &lt;span class="math"&gt;\(w_t\)&lt;/span&gt;, let’s keep track of,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{aligned}
  c_t &amp;amp; = \prod_{\tau=0}^t (1-\eta_{\tau} \lambda )  \\
  \bar{w}_t &amp;amp; = \frac{w_t}{c_t}
\end{aligned}
$$&lt;/div&gt;
&lt;p&gt;where you update &lt;span class="math"&gt;\(\bar{w}_t\)&lt;/span&gt; and &lt;span class="math"&gt;\(c_t\)&lt;/span&gt; by,&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{aligned}
  \bar{w}_{t+1}
  &amp;amp; = \bar{w}_t - \frac{\eta_t}{(1 - \eta_t) c_t} \nabla_w l(x_i, w_i, c_t \bar{w}_t) \\
  c_{t+1}
  &amp;amp; = (1 - \eta_t \lambda) c_t
\end{aligned}
$$&lt;/div&gt;
&lt;p&gt;And that’s it! As a final note, depending what value you choose for &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt;, &lt;span class="math"&gt;\(c_t\)&lt;/span&gt; is going to get really big or really small pretty fast. The usual "take the log" tricks aren't going to fly, either, as &lt;span class="math"&gt;\(c_t\)&lt;/span&gt; need not be positive. The only way around it I’ve found is to check every iteration if &lt;span class="math"&gt;\(c_t\)&lt;/span&gt; is getting out of hand, then transform &lt;span class="math"&gt;\(\bar{w}_{t} \leftarrow \bar{w}_t c_t\)&lt;/span&gt; and &lt;span class="math"&gt;\(c_t \leftarrow 1\)&lt;/span&gt; if it is.&lt;/p&gt;
&lt;p&gt;Finally, credit should be given where credit is due. This is a slightly more detailed explanation of &lt;a href="http://blog.smola.org/post/940672544/fast-quadratic-regularization-for-online-learning&amp;gt;"&gt;Alex Smola&lt;/a&gt; blog post from about a year ago, which in turn is accredited to Leon Bottou.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="optimization"></category><category term="regularization"></category><category term="sparsity"></category></entry></feed>